{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('StructuredBooks/neuromancer.json') as f:\n",
    "\tdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed(lst):\n",
    "\tnewlst = []\n",
    "\tctext = \"\"\n",
    "\tfor txt in lst:\n",
    "\t\tctext += txt\n",
    "\t\t\t\n",
    "\t\tif ctext!=\"\" and ctext[-1] == '.':\n",
    "\t\t\tnewlst.append(ctext)\n",
    "\t\t\tctext = \"\"\n",
    "\tif ctext != \"\":\n",
    "\t\tnewlst.append(ctext)\n",
    "\treturn newlst\n",
    "\n",
    "new_data = {}\n",
    "new_data['contents'] = {}\n",
    "for key in data['contents']:\n",
    "\tnew_data['contents'][key] = processed(data['contents'][key])\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import ebooklib\n",
    "\n",
    "book = epub.read_epub(\"ExamplesBooks\\prideandprejudice.epub\")\n",
    "\n",
    "text = \"\"\n",
    "# Print metadata (title, author, etc.)\n",
    "title = book.get_metadata('DC', 'title')\n",
    "author = book.get_metadata('DC', 'creator')\n",
    "print(f\"Title: {title[0] if title else 'Unknown'}\")\n",
    "print(f\"Author: {author[0] if author else 'Unknown'}\")\n",
    "\n",
    "len(list(book.get_items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('StructuredBooks/prideandprejudice.json') as f:\n",
    "\tout = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['contents'][\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def gettextfromhtml(html):\n",
    "\tsoup = BeautifulSoup(html, 'html.parser')\n",
    "\ttext = soup.get_text()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"temp/llmpaper.pdf\") as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('StructuredBooks/llmpaper.json') as f:\n",
    "\tdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Software Testing with Large Language Models:\n",
      "Survey, Landscape, and Vision\n",
      "Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang\n",
      "Abstract—Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language\n",
      "processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide\n",
      "range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability\n",
      "of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing\n",
      "techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides\n",
      "a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software\n",
      "testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for\n",
      "which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes\n",
      "the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs.\n",
      "It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research\n",
      "in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in\n",
      "software testing.\n",
      "Index Terms—Pre-trained Large Language Model, Software Testing, LLM, GPT\n",
      "✦\n",
      "1 I NTRODUCTION\n",
      "Software testing is a crucial undertaking that serves as\n",
      "a cornerstone for ensuring the quality and reliability of\n",
      "software products. Without the rigorous process of software\n",
      "testing, software enterprises would be reluctant to release\n",
      "their products into the market, knowing the potential\n",
      "consequences of delivering flawed software to end-users.\n",
      "By conducting thorough and meticulous testing procedures,\n",
      "software enterprises can minimize the occurrence of critical\n",
      "software failures, usability issues, or security breaches\n",
      "that could potentially lead to financial losses or jeopardize\n",
      "user trust. Additionally, software testing helps to reduce\n",
      "maintenance costs by identifying and resolving issues early\n",
      "in the development lifecycle, preventing more significant\n",
      "complications down the line [1], [2].\n",
      "The significance of software testing has garnered sub-\n",
      "stantial attention within the research and industrial com-\n",
      "munities. In the field of software engineering, it stands as\n",
      "an immensely popular and vibrant research area. One can\n",
      "observe the undeniable prominence of software testing by\n",
      "simply examining the landscape of conferences and sym-\n",
      "posiums focused on software engineering. Amongst these\n",
      "events, topics related to software testing consistently domi-\n",
      "nate the submission numbers and are frequently selected for\n",
      "publication.\n",
      "● J. Wang,Y. Huang, Z. Liu, Q. Wang are with State Key Laboratory of\n",
      "Intelligent Game, Institute of Software Chinese Academy of Sciences, and\n",
      "University of Chinese Academy of Sciences, Beijing, China. J. Wang and\n",
      "Q. Wang are corresponding authors.\n",
      "E-mail: {junjie, yuchao2019, liuzhe2020, wq}@iscas.ac.cn\n",
      "● C. Chen is with Monash University, Melbourne, Australia\n",
      "E-mail: chunyang.chen@monash.edu\n",
      "● S. Wang is with York University, Toronto, Canada.\n",
      "E-mail: wangsong@yorku.ca\n",
      "While the field of software testing has gained signifi-\n",
      "cant popularity, there remain dozens of challenges that have\n",
      "not been effectively addressed. For example, one such chal-\n",
      "lenge is automated unit test case generation. Although var-\n",
      "ious approaches, including search-based [3], [4], constraint-\n",
      "based [5] or random-based [6] techniques to generate a suite\n",
      "of unit tests, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory [7], [8]. Simi-\n",
      "larly, when it comes to mobile GUI testing, existing studies\n",
      "with random-/rule-based methods [9], [10], model-based\n",
      "methods [11], [12], and learning-based methods [13] are un-\n",
      "able to understand the semantic information of the GUI\n",
      "page and often fall short in achieving comprehensive cov-\n",
      "erage [14], [15]. Considering these limitations, numerous re-\n",
      "search efforts are currently underway to explore innovative\n",
      "techniques that can enhance the efficacy of software testing\n",
      "tasks, among which large language models are the most\n",
      "promising ones.\n",
      "Large language models (LLMs) such as T5 and GPT-3\n",
      "have revolutionized the field of natural language processing\n",
      "(NLP) and artificial intelligence (AI). These models, initially\n",
      "pre-trained on extensive corpora, have exhibited remarkable\n",
      "performance across a wide range of NLP tasks including\n",
      "question-answering, machine translation, and text genera-\n",
      "tion [16]–[19]. In recent years, there has been a significant\n",
      "advancement in LLMs with the emergence of models capa-\n",
      "ble of handling even larger-scale datasets. This expansion\n",
      "in model size has not only led to improved performance\n",
      "but also opened up new possibilities for applying LLMs\n",
      "as Artificial General Intelligence. Among these advanced\n",
      "LLMs, models like ChatGPT 1 and LLaMA 2 boast billions\n",
      "1. https://openai.com/blog/chatgpt\n",
      "2. https://ai.meta.com/blog/large-language-model-llama-meta-ai/\n",
      "arXiv:2307.07221v3  [cs.SE]  4 Mar 2024\n"
     ]
    }
   ],
   "source": [
    "print(data['contents'][\"0\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1\\nSoftware Testing with Large Language Models:\\nSurvey, Landscape, and Vision\\nJunjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang\\nAbstract—Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language\\nprocessing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide\\nrange of tasks.', 'Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability\\nof software products.', 'As the scope and complexity of software systems continue to grow, the need for more effective software testing\\ntechniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs.', 'This paper provides\\na comprehensive review of the utilization of LLMs in software testing.', 'It analyzes 102 relevant studies that have used LLMs for software\\ntesting, from both the software testing and LLMs perspectives.', 'The paper presents a detailed discussion of the software testing tasks for\\nwhich LLMs are commonly used, among which test case preparation and program repair are the most representative.', 'It also analyzes\\nthe commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs.', 'It also summarizes the key challenges and potential opportunities in this direction.', 'This work can serve as a roadmap for future research\\nin this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in\\nsoftware testing.', 'Index Terms—Pre-trained Large Language Model, Software Testing, LLM, GPT\\n✦\\n1 I NTRODUCTION\\nSoftware testing is a crucial undertaking that serves as\\na cornerstone for ensuring the quality and reliability of\\nsoftware products.', 'Without the rigorous process of software\\ntesting, software enterprises would be reluctant to release\\ntheir products into the market, knowing the potential\\nconsequences of delivering flawed software to end-users.', 'By conducting thorough and meticulous testing procedures,\\nsoftware enterprises can minimize the occurrence of critical\\nsoftware failures, usability issues, or security breaches\\nthat could potentially lead to financial losses or jeopardize\\nuser trust.', 'Additionally, software testing helps to reduce\\nmaintenance costs by identifying and resolving issues early\\nin the development lifecycle, preventing more significant\\ncomplications down the line [1], [2].', 'The significance of software testing has garnered sub-\\nstantial attention within the research and industrial com-\\nmunities.', 'In the field of software engineering, it stands as\\nan immensely popular and vibrant research area.', 'One can\\nobserve the undeniable prominence of software testing by\\nsimply examining the landscape of conferences and sym-\\nposiums focused on software engineering.', 'Amongst these\\nevents, topics related to software testing consistently domi-\\nnate the submission numbers and are frequently selected for\\npublication.', '● J. Wang,Y.', 'Huang, Z. Liu, Q. Wang are with State Key Laboratory of\\nIntelligent Game, Institute of Software Chinese Academy of Sciences, and\\nUniversity of Chinese Academy of Sciences, Beijing, China.', 'J. Wang and\\nQ. Wang are corresponding authors.', 'E-mail: {junjie, yuchao2019, liuzhe2020, wq}@iscas.ac.cn\\n● C. Chen is with Monash University, Melbourne, Australia\\nE-mail: chunyang.chen@monash.edu\\n● S. Wang is with York University, Toronto, Canada.', 'E-mail: wangsong@yorku.ca\\nWhile the field of software testing has gained signifi-\\ncant popularity, there remain dozens of challenges that have\\nnot been effectively addressed.', 'For example, one such chal-\\nlenge is automated unit test case generation.', 'Although var-\\nious approaches, including search-based [3], [4], constraint-\\nbased [5] or random-based [6] techniques to generate a suite\\nof unit tests, the coverage and the meaningfulness of the\\ngenerated tests are still far from satisfactory [7], [8].', 'Simi-\\nlarly, when it comes to mobile GUI testing, existing studies\\nwith random-/rule-based methods [9], [10], model-based\\nmethods [11], [12], and learning-based methods [13] are un-\\nable to understand the semantic information of the GUI\\npage and often fall short in achieving comprehensive cov-\\nerage [14], [15].', 'Considering these limitations, numerous re-\\nsearch efforts are currently underway to explore innovative\\ntechniques that can enhance the efficacy of software testing\\ntasks, among which large language models are the most\\npromising ones.', 'Large language models (LLMs) such as T5 and GPT-3\\nhave revolutionized the field of natural language processing\\n(NLP) and artificial intelligence (AI).', 'These models, initially\\npre-trained on extensive corpora, have exhibited remarkable\\nperformance across a wide range of NLP tasks including\\nquestion-answering, machine translation, and text genera-\\ntion [16]–[19].', 'In recent years, there has been a significant\\nadvancement in LLMs with the emergence of models capa-\\nble of handling even larger-scale datasets.', 'This expansion\\nin model size has not only led to improved performance\\nbut also opened up new possibilities for applying LLMs\\nas Artificial General Intelligence.', 'Among these advanced\\nLLMs, models like ChatGPT 1 and LLaMA 2 boast billions\\n1. https://openai.com/blog/chatgpt\\n2. https://ai.meta.com/blog/large-language-model-llama-meta-ai/\\narXiv:2307.07221v3  [cs.SE]  4 Mar 2024']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(sent_tokenize(data['contents'][\"0\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
