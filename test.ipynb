{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('StructuredBooks/neuromancer.json') as f:\n",
    "\tdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed(lst):\n",
    "\tnewlst = []\n",
    "\tctext = \"\"\n",
    "\tfor txt in lst:\n",
    "\t\tctext += txt\n",
    "\t\t\t\n",
    "\t\tif ctext!=\"\" and ctext[-1] == '.':\n",
    "\t\t\tnewlst.append(ctext)\n",
    "\t\t\tctext = \"\"\n",
    "\tif ctext != \"\":\n",
    "\t\tnewlst.append(ctext)\n",
    "\treturn newlst\n",
    "\n",
    "new_data = {}\n",
    "new_data['contents'] = {}\n",
    "for key in data['contents']:\n",
    "\tnew_data['contents'][key] = processed(data['contents'][key])\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from ebooklib import epub\n",
    "import markdownify\n",
    "import ebooklib\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "book = epub.read_epub(\"ExamplesBooks/design.epub\")\n",
    "\n",
    "\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "\n",
    "# Print metadata (title, author, etc.)\n",
    "\n",
    "\n",
    "title = book.get_metadata('DC', 'title')\n",
    "\n",
    "\n",
    "author = book.get_metadata('DC', 'creator')\n",
    "\n",
    "\n",
    "print(f\"Title: {title[0] if title else 'Unknown'}\")\n",
    "\n",
    "\n",
    "print(f\"Author: {author[0] if author else 'Unknown'}\")\n",
    "\n",
    "\n",
    "soup= BeautifulSoup(book.items[7].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book.get_item_with_href(\"Images\\\\00001.jpeg\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(io.BytesIO(list(book.get_items())[22].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(book.get_items())[6].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('StructuredBooks/prideandprejudice.json') as f:\n",
    "\tout = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['contents'][\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def gettextfromhtml(html):\n",
    "\tsoup = BeautifulSoup(html, 'html.parser')\n",
    "\ttext = soup.get_text()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"temp/llmpaper.pdf\") as pdf:\n",
    "    first_page = pdf.pages[0]\n",
    "    print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('StructuredBooks/llmpaper.json') as f:\n",
    "\tdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['contents'][\"0\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(sent_tokenize(data['contents'][\"0\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from IPython import display\n",
    "reader = PdfReader('temp/llmpaper.pdf')\n",
    "\n",
    "reader.pages[14].images[0].image.save('./test.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "reader = PdfReader('temp/llmpaper.pdf')\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "\ttext += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Software Testing with Large Language Models:\n",
      "Survey, Landscape, and Vision\n",
      "Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang\n",
      "Abstract—Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language\n",
      "processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide\n",
      "range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability\n",
      "of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing\n",
      "techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides\n",
      "a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software\n",
      "testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for\n",
      "which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes\n",
      "the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs.\n",
      "It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research\n",
      "in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in\n",
      "software testing.\n",
      "Index Terms—Pre-trained Large Language Model, Software Testing, LLM, GPT\n",
      "✦\n",
      "1 I NTRODUCTION\n",
      "Software testing is a crucial undertaking that serves as\n",
      "a cornerstone for ensuring the quality and reliability of\n",
      "software products. Without the rigorous process of software\n",
      "testing, software enterprises would be reluctant to release\n",
      "their products into the market, knowing the potential\n",
      "consequences of delivering flawed software to end-users.\n",
      "By conducting thorough and meticulous testing procedures,\n",
      "software enterprises can minimize the occurrence of critical\n",
      "software failures, usability issues, or security breaches\n",
      "that could potentially lead to financial losses or jeopardize\n",
      "user trust. Additionally, software testing helps to reduce\n",
      "maintenance costs by identifying and resolving issues early\n",
      "in the development lifecycle, preventing more significant\n",
      "complications down the line [1], [2].\n",
      "The significance of software testing has garnered sub-\n",
      "stantial attention within the research and industrial com-\n",
      "munities. In the field of software engineering, it stands as\n",
      "an immensely popular and vibrant research area. One can\n",
      "observe the undeniable prominence of software testing by\n",
      "simply examining the landscape of conferences and sym-\n",
      "posiums focused on software engineering. Amongst these\n",
      "events, topics related to software testing consistently domi-\n",
      "nate the submission numbers and are frequently selected for\n",
      "publication.\n",
      "● J. Wang,Y. Huang, Z. Liu, Q. Wang are with State Key Laboratory of\n",
      "Intelligent Game, Institute of Software Chinese Academy of Sciences, and\n",
      "University of Chinese Academy of Sciences, Beijing, China. J. Wang and\n",
      "Q. Wang are corresponding authors.\n",
      "E-mail: {junjie, yuchao2019, liuzhe2020, wq}@iscas.ac.cn\n",
      "● C. Chen is with Monash University, Melbourne, Australia\n",
      "E-mail: chunyang.chen@monash.edu\n",
      "● S. Wang is with York University, Toronto, Canada.\n",
      "E-mail: wangsong@yorku.ca\n",
      "While the field of software testing has gained signifi-\n",
      "cant popularity, there remain dozens of challenges that have\n",
      "not been effectively addressed. For example, one such chal-\n",
      "lenge is automated unit test case generation. Although var-\n",
      "ious approaches, including search-based [3], [4], constraint-\n",
      "based [5] or random-based [6] techniques to generate a suite\n",
      "of unit tests, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory [7], [8]. Simi-\n",
      "larly, when it comes to mobile GUI testing, existing studies\n",
      "with random-/rule-based methods [9], [10], model-based\n",
      "methods [11], [12], and learning-based methods [13] are un-\n",
      "able to understand the semantic information of the GUI\n",
      "page and often fall short in achieving comprehensive cov-\n",
      "erage [14], [15]. Considering these limitations, numerous re-\n",
      "search efforts are currently underway to explore innovative\n",
      "techniques that can enhance the efficacy of software testing\n",
      "tasks, among which large language models are the most\n",
      "promising ones.\n",
      "Large language models (LLMs) such as T5 and GPT-3\n",
      "have revolutionized the field of natural language processing\n",
      "(NLP) and artificial intelligence (AI). These models, initially\n",
      "pre-trained on extensive corpora, have exhibited remarkable\n",
      "performance across a wide range of NLP tasks including\n",
      "question-answering, machine translation, and text genera-\n",
      "tion [16]–[19]. In recent years, there has been a significant\n",
      "advancement in LLMs with the emergence of models capa-\n",
      "ble of handling even larger-scale datasets. This expansion\n",
      "in model size has not only led to improved performance\n",
      "but also opened up new possibilities for applying LLMs\n",
      "as Artificial General Intelligence. Among these advanced\n",
      "LLMs, models like ChatGPT 1 and LLaMA 2 boast billions\n",
      "1. https://openai.com/blog/chatgpt\n",
      "2. https://ai.meta.com/blog/large-language-model-llama-meta-ai/\n",
      "arXiv:2307.07221v3  [cs.SE]  4 Mar 20242\n",
      "of parameters. Such models hold tremendous potential for\n",
      "tackling complex practical tasks in domains like code gener-\n",
      "ation and artistic creation. With their expanded capacity and\n",
      "enhanced capabilities, LLMs have become game-changers in\n",
      "NLP and AI, and are driving advancements in other fields\n",
      "like coding and software testing.\n",
      "LLMs have been used for various coding-related tasks\n",
      "including code generation and code recommendation [20]–\n",
      "[23]. On one hand, in software testing, there are many tasks\n",
      "related to code generation, such as unit test generation [7],\n",
      "where the utilization of LLMs is expected to yield good\n",
      "performance. On the other hand, software testing possesses\n",
      "unique characteristics that differentiate it from code gener-\n",
      "ation. For example, code generation primarily focuses on\n",
      "producing a single, correct code snippet, whereas software\n",
      "testing often requires generating diverse test inputs to en-\n",
      "sure better coverage of the software under test [1]. The ex-\n",
      "istence of these differences introduces new challenges and\n",
      "opportunities when employing LLMs for software testing.\n",
      "Moreover, people have benefited from the excellent perfor-\n",
      "mance of LLMs in generation and inference tasks, leading\n",
      "to the emergence of dozens of new practices that use LLMs\n",
      "for software testing.\n",
      "This article presents a comprehensive review of the uti-\n",
      "lization of LLMs in software testing. We collect 102 relevant\n",
      "papers and conduct a thorough analysis from both software\n",
      "testing and LLMs perspectives, as roughly summarized in\n",
      "Figure 1.\n",
      "From the viewpoint of software testing, our analysis in-\n",
      "volves an examination of the specific software testing tasks\n",
      "for which LLMs are employed. Results show that LLMs are\n",
      "commonly used for test case preparation (including unit test\n",
      "case generation, test oracle generation, and system test input\n",
      "generation), program debugging, and bug repair, while we\n",
      "do not find the practices for applying LLMs in the tasks of\n",
      "early testing life-cycle (such as test requirement, test plan,\n",
      "etc). For each test task, we would provide detailed illustra-\n",
      "tions showcasing the utilization of LLMs in addressing the\n",
      "task, highlighting commonly-used practices, tracking tech-\n",
      "nology evolution trends, and summarizing achieved per-\n",
      "formance, so as to facilitate readers in gaining a thorough\n",
      "overview of how LLMs are employed across various testing\n",
      "tasks.\n",
      "From the viewpoint of LLMs, our analysis includes\n",
      "the commonly used LLMs in these studies, the types of\n",
      "prompt engineering, the input of the LLMs, as well as\n",
      "the accompanied techniques with these LLMs. Results\n",
      "show that about one-third of the studies utilize the LLMs\n",
      "through pre-training or fine-tuning schema, while the others\n",
      "employ prompt engineering to communicate with LLMs\n",
      "to steer their behavior for desired outcomes. For prompt\n",
      "engineering, the zero-shot learning and few-shot learning\n",
      "strategies are most commonly used, while other advances\n",
      "like chain-of-thought promoting and self-consistency are\n",
      "rarely utilized. Results also show that traditional testing\n",
      "techniques like differential testing and mutation testing\n",
      "are usually accompanied by LLMs to help generate more\n",
      "diversified tests.\n",
      "Furthermore, we summarize the key challenges and po-\n",
      "tential opportunities in this direction. Although software\n",
      "testing with LLMs has undergone significant growth in the\n",
      "Fig. 1: Structure of the contents in this paper (the numbers\n",
      "in bracket indicates the number of involved papers, and a\n",
      "paper might involve zero or multiple items)\n",
      "past two years, there are still challenges in achieving high\n",
      "coverage of the testing, test oracle problem, rigorous evalu-\n",
      "ations, and real-world application of LLMs in software test-\n",
      "ing. Since it is a new emerging field, there are many research\n",
      "opportunities, including exploring LLMs in an early stage of\n",
      "testing, exploring LLMs for more types of software and non-\n",
      "functional testing, exploring advanced prompt engineering,\n",
      "as well as incorporating LLMs with traditional techniques.\n",
      "This paper makes the following contributions:\n",
      "● We thoroughly analyze 102 relevant studies that used\n",
      "LLMs for software testing, regarding publication\n",
      "trends, distribution of publication venues, etc.\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of software testing to understand the distribution of\n",
      "software testing tasks with LLM and present a thorough\n",
      "discussion about how these tasks are solved with LLM.\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of LLMs, and uncover the commonly-used LLMs,\n",
      "the types of prompt engineering, input of the LLMs, as\n",
      "well as the accompanied techniques with these LLMs.\n",
      "● We highlight the challenges in existing studies and\n",
      "present potential opportunities for further studies.\n",
      "We believe that this work will be valuable to both re-\n",
      "searchers and practitioners in the field of software engineer-\n",
      "ing, as it provides a comprehensive overview of the current\n",
      "state and future vision of using LLMs for software testing.\n",
      "For researchers, this work can serve as a roadmap for future\n",
      "research in this area, highlighting potential avenues for ex-\n",
      "ploration and identifying gaps in our current understanding\n",
      "of the use of LLMs in software testing. For practitioners, this\n",
      "work can provide insights into the potential benefits and\n",
      "limitations of using LLMs for software testing, as well as\n",
      "practical guidance on how to effectively integrate them into3\n",
      "existing testing processes. By providing a detailed landscape\n",
      "of the current state and future vision of using LLMs for\n",
      "software testing, this work can help accelerate the adoption\n",
      "of this technology in the software engineering community\n",
      "and ultimately contribute to improving the quality and reli-\n",
      "ability of software systems.\n",
      "2 B ACKGROUND\n",
      "2.1 Large Language Model (LLM)\n",
      "Recently, pre-trained language models (PLMs) have been\n",
      "proposed by pretraining Transformer-based models over\n",
      "large-scale corpora, showing strong capabilities in solving\n",
      "various natural language processing (NLP) tasks [16]–[19].\n",
      "Studies have shown that model scaling can lead to improved\n",
      "model capacity, prompting researchers to investigate the\n",
      "scaling effect through further parameter size increases.\n",
      "Interestingly, when the parameter scale exceeds a certain\n",
      "threshold, these larger language models demonstrate not\n",
      "only significant performance improvements but also special\n",
      "abilities such as in-context learning, which are absent in\n",
      "smaller models such as BERT.\n",
      "To discriminate the language models in different\n",
      "parameter scales, the research community has coined\n",
      "the term large language models (LLM) for the PLMs of\n",
      "significant size. LLMs typically refer to language models\n",
      "that have hundreds of billions (or more) of parameters and\n",
      "are trained on massive text data such as GPT-3, PaLM,\n",
      "Codex, and LLaMA. LLMs are built using the Transformer\n",
      "architecture, which stacks multi-head attention layers\n",
      "in a very deep neural network. Existing LLMs adopt\n",
      "similar model architectures (Transformer) and pre-training\n",
      "objectives (language modeling) as small language models,\n",
      "but largely scale up the model size, pre-training data,\n",
      "and total compute power. This enables LLMs to better\n",
      "understand natural language and generate high-quality text\n",
      "based on given context or prompts.\n",
      "Note that, in existing literature, there is no formal con-\n",
      "sensus on the minimum parameter scale for LLMs, since\n",
      "the model capacity is also related to data size and total\n",
      "compute. In a recent survey of LLMs [17], the authors focus\n",
      "on discussing the language models with a model size larger\n",
      "than 10B. Under their criteria, the first LLM is T5 released\n",
      "by Google in 2019, followed by GPT-3 released by OpenAI\n",
      "in 2020, and there are more than thirty LLMs released be-\n",
      "tween 2021 and 2023 indicating its popularity. In another\n",
      "survey of unifying LLMs and knowledge graphs [24], the\n",
      "authors categorize the LLMs into three types: encoder-only\n",
      "(e.g., BERT), encoder-decoder (e.g., T5), and decoder-only\n",
      "network architecture (e.g., GPT-3). In our review, we take\n",
      "into account the categorization criteria of the two surveys\n",
      "and only consider the encoder-decoder and decoder-only\n",
      "network architecture of pre-training language models, since\n",
      "they can both support generative tasks. We do not consider\n",
      "the encoder-only network architecture because they cannot\n",
      "handle generative tasks, were proposed relatively early (e.g.,\n",
      "BERT in 2018), and there are almost no models using this\n",
      "architecture after 2021. In other words, the LLMs discussed\n",
      "in this paper not only include models with parameters of\n",
      "over 10B (as mentioned in [17]) but also include other mod-\n",
      "els that use the encoder-decoder and decoder-only network\n",
      "architecture (as mentioned in [24]), such as BART with 140M\n",
      "parameters and GPT-2 with parameter sizes ranging from\n",
      "117M to 1.5B. This is also to potentially include more studies\n",
      "to demonstrate the landscape of this topic.\n",
      "2.2 Software Testing\n",
      "Software testing is a crucial process in software develop-\n",
      "ment that involves evaluating the quality of a software prod-\n",
      "uct. The primary goal of software testing is to identify de-\n",
      "fects or errors in the software system that could potentially\n",
      "lead to incorrect or unexpected behavior. The whole life\n",
      "cycle of software testing typically includes the following\n",
      "tasks (demonstrated in Figure 4):\n",
      "● Requirement Analysis: analyze the software require-\n",
      "ments and identify the testing objectives, scope, and\n",
      "criteria.\n",
      "● Test Plan: develop a test plan that outlines the testing\n",
      "strategy, test objectives, and schedule.\n",
      "● Test Design and Review: develop and review the test\n",
      "cases and test suites that align with the test plan and\n",
      "the requirements of the software application.\n",
      "● Test Case Preparation: the actual test cases are prepared\n",
      "based on the designs created in the previous stage.\n",
      "● Test Execution: execute the tests that were designed in\n",
      "the previous stage. The software system is executed\n",
      "with the test cases and the results are recorded.\n",
      "● Test Reporting: analyze the results of the tests and gen-\n",
      "erate reports that summarize the testing process and\n",
      "identify any defects or issues that were discovered.\n",
      "● Bug Fixing and Regression Testing: defects or issues\n",
      "identified during testing are reported to the develop-\n",
      "ment team for fixing. Once the defects are fixed, regres-\n",
      "sion testing is performed to ensure that the changes\n",
      "have not introduced new defects or issues.\n",
      "● Software Release: once the software system has passed\n",
      "all of the testing stages and the defects have been fixed,\n",
      "the software can be released to the customer or end\n",
      "user.\n",
      "The testing process is iterative and may involve multiple\n",
      "cycles of the above stages, depending on the complexity of\n",
      "the software system and the testing requirements.\n",
      "During the testing phase, various types of tests may be\n",
      "performed, including unit tests, integration tests, system\n",
      "tests, and acceptance tests.\n",
      "● Unit Testing involves testing individual units or com-\n",
      "ponents of the software application to ensure that they\n",
      "function correctly.\n",
      "● Integration Testing involves testing different modules\n",
      "or components of the software application together to\n",
      "ensure that they work correctly as a system.\n",
      "● System Testing involves testing the entire software sys-\n",
      "tem as a whole, including all the integrated components\n",
      "and external dependencies.\n",
      "● Acceptance Testing involves testing the software appli-\n",
      "cation to ensure that it meets the business requirements\n",
      "and is ready for deployment.\n",
      "In addition, there can be functional testing, performance\n",
      "testing, unit testing, security testing, accessibility testing,\n",
      "etc, which explores various aspects of the software under\n",
      "test [25].4\n",
      "3.1.1 Automatic \n",
      "Search\n",
      "3.1.1 Automatic \n",
      "Filtering\n",
      "3.1.4 Quality \n",
      "Assessment3.1.5 Snowballing\n",
      "14,623 \n",
      "Papers\n",
      "102\n",
      "Papers\n",
      "1,239 \n",
      "Papers\n",
      "109 \n",
      "Papers\n",
      "START\n",
      "102 \n",
      "Papers\n",
      "Major SE Venues\n",
      "& AI Venues\n",
      "3.1.2 Manual Search\n",
      "1,278 \n",
      "Papers\n",
      "3.1.3 Inclusion and \n",
      "Exclusion Criteria\n",
      "Fig. 2: Overview of the paper collection process\n",
      "3 P APER SELECTION AND REVIEW SCHEMA\n",
      "3.1 Paper Collection Methodology\n",
      "Figure 2 shows our paper search and selection process. To\n",
      "collect as much relevant literature as possible, we use both\n",
      "automatic search (from paper repository database) and man-\n",
      "ual search (from major software engineering and artificial\n",
      "intelligence venues). We searched papers from Jan. 2019 to\n",
      "Jun. 2023 and further conducted the second round of search\n",
      "to include the papers from Jul. 2023 to Oct. 2023.\n",
      "3.1.1 Automatic Search\n",
      "To ensure that we collect papers from diverse research areas,\n",
      "we conduct an extensive search using four popular scientific\n",
      "databases: ACM digital library, IEEE Xplore digital library,\n",
      "arXiv, and DBLP .\n",
      "We search for papers whose title contains keywords re-\n",
      "lated to software testing tasks and testing techniques (as shown\n",
      "below) in the first three databases. In the case of DBLP , we\n",
      "use additional keywords related to LLMs (as shown below)\n",
      "to filter out irrelevant studies, as relying solely on testing-\n",
      "related keywords would result in a large number of can-\n",
      "didate studies. While using two sets of keywords for DBLP\n",
      "may result in overlooking certain related studies, we believe\n",
      "it is still a feasible strategy. This is due to the fact that a\n",
      "substantial number of studies present in this database can\n",
      "already be found in the first three databases, and the fourth\n",
      "database only serves as a supplementary source for collect-\n",
      "ing additional papers.\n",
      "● Keywords related with software testing tasks and tech-\n",
      "niques: test OR bug OR issue OR defect OR fault OR\n",
      "error OR failure OR crash OR debug OR debugger OR\n",
      "repair OR fix OR assert OR verification OR validation\n",
      "OR fuzz OR fuzzer OR mutation.\n",
      "● Keywords related with LLMs: LLMOR language model\n",
      "OR generative model OR large model OR GPT-3 OR\n",
      "ChatGPT OR GPT-4 OR LLaMA OR PaLM2 OR CodeT5\n",
      "OR CodeX OR CodeGen OR Bard OR InstructGPT. Note\n",
      "that, we only list the top ten most popular LLMs (based\n",
      "on Google search), since they are the search keywords\n",
      "for matching paper titles, rather than matching the pa-\n",
      "per content.\n",
      "The above search strategy based on the paper title can\n",
      "recall a large number of papers, and we further conduct the\n",
      "automatic filtering based on the paper content. Specifically,\n",
      "we filter the paper whose content contains “LLM” or “lan-\n",
      "guage model” or “generative model” or “large model” or\n",
      "the name of the LLMs (using the LLMs in [17], [24] except\n",
      "those in our exclusion criteria). This can help eliminate the\n",
      "papers that do not involve the neural models.\n",
      "3.1.2 Manual Search\n",
      "To compensate for the potential omissions that may result\n",
      "from automated searches, we also conduct manual searches.\n",
      "In order to make sure we collect highly relevant papers,\n",
      "we conduct a manual search within the conference proceed-\n",
      "ings and journal articles from top-tier software engineering\n",
      "venues (listed in Table 2).\n",
      "In addition, given the interdisciplinary nature of this\n",
      "work, we also include the conference proceedings of the\n",
      "artificial intelligence field. We select the top ten venues\n",
      "based on the h5 index from Google Scholar, and exclude\n",
      "three computer vision venues, i.e., CVPR, ICCV , ECCV , as\n",
      "listed in Table 2.\n",
      "3.1.3 Inclusion and Exclusion Criteria\n",
      "The search conducted on the databases and venue is, by de-\n",
      "sign, very inclusive. This allows us to collect as many papers\n",
      "as possible in our pool. However, this generous inclusivity\n",
      "results in having papers that are not directly related to the\n",
      "scope of this survey. Accordingly, we define a set of specific\n",
      "inclusion and exclusion criteria and then we apply them to\n",
      "each paper in the pool and remove papers not meeting the\n",
      "criteria. This ensures that each collected paper aligns with\n",
      "our scope and research questions.\n",
      "Inclusion Criteria. We define the following criteria for\n",
      "including papers:\n",
      "● The paper proposes or improves an approach, study, or\n",
      "tool/framework that targets testing specific software or\n",
      "systems with LLMs.\n",
      "● The paper applies LLMs to software testing practice,\n",
      "including all tasks within the software testing lifecycle\n",
      "as demonstrated in Section 2.2.\n",
      "● The paper presents an empirical or experimental study\n",
      "about utilizing LLMs in software testing practice.\n",
      "● The paper involves specific testing techniques (e.g.,\n",
      "fuzz testing) employing LLMs.\n",
      "If a paper satisfies any of the following criteria, we will\n",
      "include it.\n",
      "Exclusion Criteria. The following studies would be ex-\n",
      "cluded during study selection:\n",
      "● The paper does not involve software testing tasks, e.g.,\n",
      "code comment generation.\n",
      "● The paper does not utilize LLMs, e.g., using recurrent\n",
      "neural networks.\n",
      "● The paper mentions LLMs only in future work or dis-\n",
      "cussions rather than using LLMs in the approach.\n",
      "● The paper utilizes language models with encoder-only\n",
      "architecture, e.g., BERT, which can not directly be uti-\n",
      "lized for generation tasks (as demonstrated in Section\n",
      "2.1).\n",
      "● The paper focuses on testing the performance of LLMs,\n",
      "such as fairness, stability, security, etc. [125]–[127].\n",
      "● The paper focuses on evaluating the performance of\n",
      "LLM-enabled tools, e.g., evaluating the code quality of\n",
      "the code generation tool Copilot [128]–[130].\n",
      "For the papers collected through automatic search and\n",
      "manual search, we conduct a manual inspection to check\n",
      "whether they satisfy our inclusion criteria and filter those\n",
      "following our exclusion criteria. Specifically, the first two\n",
      "authors read each paper to carefully determine whether it5\n",
      "TABLE 1: Details of the collected papers\n",
      "ID Topic Paper title Year Reference\n",
      "1 Unit test case generation Unit Test Case Generation with Transformers and Focal Context 2020 [26]\n",
      "2 Unit test case generation Codet: Code Generation with Generated Tests 2022 [27]\n",
      "3 Unit test case generation Interactive Code Generation via Test-Driven User-Intent Formalization 2022 [28]\n",
      "4 Unit test case generation A3Test: Assertion-Augmented Automated Test Case Generation 2023 [29]\n",
      "5 Unit test case generation An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation 2023 [30]\n",
      "6 Unit test case generation An Initial Investigation of ChatGPT Unit Test Generation Capability 2023 [31]\n",
      "7 Unit test case generation Automated Test Case Generation Using Code Models and Domain Adaptation 2023 [32]\n",
      "8 Unit test case generation Automatic Generation of Test Cases based on Bug Reports: a Feasibility Study with Large Language Models 2023 [33]\n",
      "9 Unit test case generation Can Large Language Models Write Good Property-Based Tests? 2023 [34]\n",
      "10 Unit test case generation CAT-LM Training Language Models on Aligned Code And Tests 2023 [35]\n",
      "11 Unit test case generation ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation 2023 [8]\n",
      "12 Unit test case generation ChatUniTest: a ChatGPT-based Automated Unit Test Generation Tool 2023 [36]\n",
      "13 Unit test case generation CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models 2023 [37]\n",
      "14 Unit test case generation Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing 2023 [38]\n",
      "15 Unit test case generation Exploring the Effectiveness of Large Language Models in Generating Unit Tests 2023 [39]\n",
      "16 Unit test case generation How Well does LLM Generate Security Tests? 2023 [40]\n",
      "17 Unit test case generation No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation 2023 [7]\n",
      "18 Unit test case generation Prompting Code Interpreter to Write Better Unit Tests on Quixbugs Functions 2023 [41]\n",
      "19 Unit test case generation Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation 2023 [42]\n",
      "20 Unit test case generation Unit Test Generation using Generative AI: A Comparative Performance Analysis of Autogeneration Tools 2023 [43]\n",
      "21 Test oracle generation Generating Accurate Assert Statements for Unit Test Cases Using Pretrained Transformers 2022 [44]\n",
      "22 Test oracle generation Learning Deep Semantics for Test Completion 2023 [45]\n",
      "23 Test oracle generation; Program repairUsing Transfer Learning for Code-Related Tasks 2023 [46]\n",
      "24 Test oracle generation; Program repairRetrieval-Based Prompt Selection for Code-Related Few-Shot Learning 2023 [47]\n",
      "25 System test input generation Automated Conformance Testing for JavaScript Engines via Deep Compiler Fuzzing 2021 [48]\n",
      "26 System test input generation Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing 2022 [49]\n",
      "27 System test input generation Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors 2022 [50]\n",
      "28 System test input generation Slgpt: Using Transfer Learning to Directly Generate Simulink Model Files and Find Bugs in the Simulink Toolchain2021 [51]\n",
      "29 System test input generation Augmenting Greybox Fuzzing with Generative AI 2023 [52]\n",
      "30 System test input generation Automated Test Case Generation Using T5 and GPT-3 2023 [53]\n",
      "31 System test input generation Automating GUI-based Software Testing with GPT-3 2023 [54]\n",
      "32 System test input generation AXNav: Replaying Accessibility Tests from Natural Language 2023 [55]\n",
      "33 System test input generation Can ChatGPT Advance Software Testing Intelligence? An Experience Report on Metamorphic Testing 2023 [56]\n",
      "34 System test input generation Efficient Mutation Testing via Pre-Trained Language Models 2023 [57]\n",
      "35 System test input generation Large Language Models are Edge-Case Generators:Crafting Unusual Programs for Fuzzing Deep Learning Libraries2023 [58]\n",
      "36 System test input generation Large Language Models are Zero Shot Fuzzers: Fuzzing Deep Learning Libraries via Large Language Models2023 [59]\n",
      "37 System test input generation Large Language Models for Fuzzing Parsers (Registered Report) 2023 [60]\n",
      "38 System test input generation LLM for Test Script Generation and Migration: Challenges, Capabilities, and Opportunities 2023 [61]\n",
      "39 System test input generation Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions2023 [14]\n",
      "40 System test input generation PentestGPT: An LLM-empowered Automatic Penetration Testing Tool 2023 [62]\n",
      "41 System test input generation SMT Solver Validation Empowered by Large Pre-Trained Language Models 2023 [63]\n",
      "42 System test input generation TARGET: Automated Scenario Generation from Traffic Rules for Testing Autonomous Vehicles 2023 [64]\n",
      "43 System test input generation Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model2023 [65]\n",
      "44 System test input generation Understanding Large Language Model Based Fuzz Driver Generation 2023 [66]\n",
      "45 System test input generation Universal Fuzzing via Large Language Models 2023 [67]\n",
      "46 System test input generation Variable Discovery with Large Language Models for Metamorphic Testing of Scientific Software 2023 [68]\n",
      "47 System test input generation White-box Compiler Fuzzing Empowered by Large Language Models 2023 [69]\n",
      "48 Bug analysis Itiger: an Automatic Issue Title Generation Tool 2022 [70]\n",
      "49 Bug analysis CrashTranslator: Automatically Reproducing Mobile Application Crashes Directly from Stack Trace 2023 [71]\n",
      "50 Bug analysis Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report Detection 2023 [72]\n",
      "51 Bug analysis Employing Deep Learning and Structured Information Retrieval to Answer Clarification Questions on Bug Reports2023 [73]\n",
      "52 Bug analysis Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation 2022 [74]\n",
      "53 Bug analysis Prompting Is All Your Need: Automated Android Bug Replay with Large Language Models 2023 [75]\n",
      "54 Bug analysis Still Confusing for Bug-Component Triaging? Deep Feature Learning and Ensemble Setting to Rescue 2023 [76]\n",
      "55 Debug Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5 2022 [77]\n",
      "56 Debug Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction 2022 [78]\n",
      "57 Debug A Preliminary Evaluation of LLM-Based Fault Localization 2023 [79]\n",
      "58 Debug Addressing Compiler Errors: Stack Overflow or Large Language Models? 2023 [80]\n",
      "59 Debug Can LLMs Demystify Bug Reports? 2023 [81]\n",
      "60 Debug Dcc –help: Generating Context-Aware Compiler Error Explanations with Large Language Models 2023 [82]\n",
      "61 Debug Explainable Automated Debugging via Large Language Model-driven Scientific Debugging 2023 [83]\n",
      "62 Debug Large Language Models for Test-Free Fault Localization 2023 [84]\n",
      "63 Debug Large Language Models in Fault Localisation 2023 [85]\n",
      "64 Debug LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation 2023 [86]\n",
      "65 Debug Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting 2023 [87]\n",
      "66 Debug Teaching Large Language Models to Self-Debug 2023 [88]\n",
      "67 Debug; Program repair A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair 2023 [89]\n",
      "68 Program repair Examining Zero-Shot Vulnerability Repair with Large Language Models 2022 [90]\n",
      "69 Program repair Automated Repair of Programs from Large Language Models 2022 [91]\n",
      "70 Program repair Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar 2022 [92]\n",
      "71 Program repair Practical Program Repair in the Era of Large Pre-trained Language Models 2022 [93]\n",
      "72 Program repair Repairing Bugs in Python Assignments Using Large Language Models 2022 [94]\n",
      "73 Program repair Towards JavaScript Program Repair with Generative Pre-trained Transformer (GPT-2) 2022 [95]\n",
      "74 Program repair An Analysis of the Automatic Bug Fixing Performance of ChatGPT 2023 [96]\n",
      "75 Program repair An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair 2023 [97]\n",
      "76 Program repair An Evaluation of the Effectiveness of OpenAI’s ChatGPT for Automated Python Program Bug Fixing using QuixBugs2023 [98]\n",
      "77 Program repair An Extensive Study on Model Architecture and Program Representation in the Domain of Learning-based Automated Program Repair2023 [99]\n",
      "78 Program repair Can OpenAI’s Codex Fix Bugs? An Evaluation on QuixBugs 2022 [100]\n",
      "79 Program repair CIRCLE: Continual Repair Across Programming Languages 2022 [101]\n",
      "80 Program repair Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback 2023 [102]\n",
      "81 Program repair Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair2023 [103]\n",
      "82 Program repair Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors 2023 [104]\n",
      "83 Program repair Enhancing Genetic Improvement Mutations Using Large Language Models 2023 [105]\n",
      "84 Program repair FixEval: Execution-based Evaluation of Program Fixes for Programming Problems 2023 [106]\n",
      "85 Program repair Fixing Hardware Security Bugs with Large Language Models 2023 [107]\n",
      "86 Program repair Fixing Rust Compilation Errors using LLMs 2023 [108]\n",
      "87 Program repair Framing Program Repair as Code Completion 2022 [109]\n",
      "88 Program repair Frustrated with Code Quality Issues? LLMs can Help! 2023 [110]\n",
      "89 Program repair GPT-3-Powered Type Error Debugging: Investigating the Use of Large Language Models for Code Repair 2023 [111]\n",
      "90 Program repair How Effective Are Neural Networks for Fixing Security Vulnerabilities 2023 [112]\n",
      "91 Program repair Impact of Code Language Models on Automated Program Repair 2023 [113]\n",
      "92 Program repair Inferfix: End-to-end Program Repair with LLMs 2023 [114]\n",
      "93 Program repair Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT 2023 [115]\n",
      "94 Program repair Neural Program Repair with Program Dependence Analysis and Effective Filter Mechanism 2023 [116]\n",
      "95 Program repair Out of Context: How important is Local Context in Neural Program Repair? 2023 [117]\n",
      "96 Program repair Pre-trained Model-based Automated Software Vulnerability Repair: How Far are We? 2023 [118]\n",
      "97 Program repair RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot 2023 [119]\n",
      "98 Program repair RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic Program Repair 2023 [120]\n",
      "99 Program repair STEAM: Simulating the InTeractive BEhavior of ProgrAMmers for Automatic Bug Fixing 2023 [121]\n",
      "100 Program repair Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions 2023 [122]\n",
      "101 Program repair VulRepair: a T5-based Automated Software Vulnerability Repair 2022 [123]\n",
      "102 Program repair What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs? 2023 [124]6\n",
      "TABLE 2: Conference proceedings and journals considered\n",
      "for manual search\n",
      "Acronym Venue\n",
      "SE Conference\n",
      "ICSE International Conference on Software EngineeringESEC/FSE Joint European Software Engineering Conference and Symposium on theFoundations of Software EngineeringASE International Conference on Automated Software EngineeringISSTA International Symposium on Software Testing and AnalysisICST International Conference on Software Testing, Verification and ValidationESEM International Symposium on Empirical Software Engineering and Mea-surementMSR International Conference on Mining Software RepositoriesQRS International Conference on Software Quality, Reliability and SecurityICSME International Conference on Software Maintenance and EvolutionISSRE International Symposium on Software Reliability Engineering\n",
      "SE Journal\n",
      "TSE Transactions on Software EngineeringTOSEM Transactions on Software Engineering and MethodologyEMSE Empirical Software EngineeringASE Automated Software EngineeringJSS Journal of Systems and SoftwareJSEP Journal of Software: Evolution and ProcessSTVR Software Testing, Verification and ReliabilityIEEE SOFTW. IEEE SoftwareIET SOFTW. IET SoftwareIST Information and Software TechnologySQJ Software Quality Journal\n",
      "AI Venues\n",
      "ICLR International Conference on Learning RepresentationsNeurIPS Conference on Neural Information Processing SystemsICML International Conference on Machine LearningAAAI AAAI Conference on Artificial IntelligenceEMNLP Conference on Empirical Methods in Natural Language ProcessingACL Annual Meeting of the Association for Computational LinguisticsIJCAI International Joint Conference on Artificial Intelligence\n",
      "should be included based on the inclusion criteria and exclu-\n",
      "sion criteria, and any paper with different decisions will be\n",
      "handed over to the third author to make the final decision.\n",
      "3.1.4 Quality Assessment\n",
      "In addition, we establish quality assessment criteria to ex-\n",
      "clude low-quality studies as shown below. For each ques-\n",
      "tion, the study’s quality is rated as “yes”, “partial” or “no”\n",
      "which are assigned values of 1, 0.5, and 0, respectively. Pa-\n",
      "pers with a score of less than eight will be excluded from\n",
      "our study.\n",
      "● Is there a clearly stated research goal related to software\n",
      "testing?\n",
      "● Is there a defined and repeatable technique?\n",
      "● Is there any explicit contribution to software testing?\n",
      "● Is there an explicit description of which LLMs are uti-\n",
      "lized?\n",
      "● Is there an explicit explanation about how the LLMs are\n",
      "utilized?\n",
      "● Is there a clear methodology for validating the tech-\n",
      "nique?\n",
      "● Are the subject projects selected for validation suitable\n",
      "for the research goals?\n",
      "● Are there control techniques or baselines to demon-\n",
      "strate the effectiveness of the proposed technique?\n",
      "● Are the evaluation metrics relevant (e.g., evaluate the\n",
      "effectiveness of the proposed technique) to the research\n",
      "objectives?\n",
      "● Do the results presented in the study align with the\n",
      "research objectives and are they presented in a clear\n",
      "and relevant manner?\n",
      "3.1.5 Snowballing\n",
      "At the end of searching database repositories and confer-\n",
      "ence proceedings and journals, and applying inclusion/ex-\n",
      "clusion criteria and quality assessment, we obtain the initial\n",
      "set of papers. Next, to mitigate the risk of omitting rele-\n",
      "vant literature from this survey, we also perform backward\n",
      "/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000014/uni00000015/uni00000013/uni00000015/uni00000015/uni00000015/uni00000013/uni00000015/uni00000016/uni00000003\n",
      "/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000003c/uni00000048/uni00000044/uni00000055\n",
      "/uni00000013\n",
      "/uni00000018/uni00000013\n",
      "/uni00000014/uni00000013/uni00000013\n",
      "/uni00000014/uni00000018/uni00000013\n",
      "/uni00000015/uni00000013/uni00000013/uni00000006/uni00000003/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\n",
      "/uni00000014/uni00000015\n",
      "/uni00000014/uni0000001c\n",
      "/uni0000001b/uni00000015\n",
      "Fig. 3: Trend in the number of papers with year\n",
      "snowballing [131] by inspecting the references cited by the\n",
      "collected papers so far. Note that, this procedure did not in-\n",
      "clude new studies, which might because the surveyed topic\n",
      "is quite new and the reference studies tend to published pre-\n",
      "viously, and we already include a relatively comprehensive\n",
      "automatic and manual search.\n",
      "3.2 Collection Results\n",
      "As shown in Figure 2, the collection process started\n",
      "with a total of 14,623 papers retrieved from four\n",
      "academic databases employing keyword searching.\n",
      "Then after automated filtering, manual search, applying\n",
      "inclusion/exclusion criteria, and quality assessment, we\n",
      "finally collected a total of 102 papers involving software\n",
      "testing with LLMs. Table 1 shows the details of the collected\n",
      "papers. Besides, we also use Table 5 (at the end of the\n",
      "paper) to provide a more comprehensive overview of these\n",
      "papers regarding the specific characteristics which will be\n",
      "illustrated in Section 4 and Section 5.\n",
      "Note that, there are two studies which are respectively\n",
      "the extension of a previously published paper by the same\n",
      "authors ( [46] and [132], [68] and [133]), and we only keep\n",
      "the extended version to avoid duplicate.\n",
      "3.3 General Overview of Collected Paper\n",
      "Among the papers, 47% papers are published in software\n",
      "engineering venues, among which 19 papers are from ICSE,\n",
      "5 papers are from FSE, 5 papers are from ASE, and 3 pa-\n",
      "pers are from ISSTA. 2% papers are published in artificial\n",
      "intelligence venues such as EMNLP and ICLR, and 5% pa-\n",
      "pers are published in program analysis or security venues\n",
      "like PLDI and S&P . Besides, 46% of the papers have not\n",
      "yet been published via peer-reviewed venues, i.e., they are\n",
      "disclosed on arXiv. This is understandable because this field\n",
      "is emerging and many works are just completed and in\n",
      "the process of submission. Although these papers did not\n",
      "undergo peer review, we have a quality assessment process\n",
      "that eliminates papers with low quality, which potentially\n",
      "ensures the quality of this survey.\n",
      "Figure 3 demonstrates the trend of our collected papers\n",
      "per year. We can see that as the years go by, the number of\n",
      "papers in this field is growing almost exponentially. In 2020\n",
      "and 2021, there were only 1 and 2 papers, respectively. In\n",
      "2022, there were 19 papers, and in 2023, there have been 827\n",
      "Fig. 4: Distribution of testing tasks with LLMs (aligned with software testing life cycle [134]–[136], the number in bracket\n",
      "indicates the number of collected studies per task, and one paper might involve multiple tasks)\n",
      "papers. It is conceivable that there will be even more papers\n",
      "in the future, which indicates the popularity and attention\n",
      "that this field is receiving.\n",
      "4 A NALYSIS FROM SOFTWARE TESTING PER-\n",
      "SPECTIVE\n",
      "This section presents our analysis from the viewpoint of\n",
      "software testing and organizes the collected studies in terms\n",
      "of testing tasks. Figure 4 lists the distribution of each in-\n",
      "volved testing task, aligned with the software testing life\n",
      "cycle. We first provide a general overview of the distribu-\n",
      "tion, followed by further analysis for each task. Note that,\n",
      "for each following subsection, the cumulative total of sub-\n",
      "categories may not always match the total number of papers\n",
      "since a paper might belong to more than one subcategory.\n",
      "We can see that LLMs have been effectively used in both\n",
      "the mid to late stages of the software testing lifecycle. In\n",
      "the test case preparation phase, LLMs have been utilized for\n",
      "tasks such as generating unit test cases, test oracle genera-\n",
      "tion, and system test input generation. These tasks are cru-\n",
      "cial in the mid-phase of software testing to help catch issues\n",
      "and prevent further development until issues are resolved.\n",
      "Furthermore, in later phases such as the test report/bug re-\n",
      "ports and bug fix phase, LLMs have been employed for tasks\n",
      "such as bug analysis, debugging, and repair. These tasks are\n",
      "critical towards the end of the testing phase when software\n",
      "bugs need to be resolved to prepare for the product’s release.\n",
      "4.1 Unit Test Case Generation\n",
      "Unit test case generation involves writing unit test cases to\n",
      "check individual units/components of the software inde-\n",
      "pendently and ensure that they work correctly. For a method\n",
      "under test (i.e., often called the focal method), its corre-\n",
      "sponding unit test consists of a test prefix and a test oracle.\n",
      "In particular, the test prefix is typically a series of method\n",
      "invocation statements or assignment statements, which aims\n",
      "at driving the focal method to a testable state; and then the\n",
      "test oracle serves as the specification to check whether the\n",
      "current behavior of the focal method satisfies the expected\n",
      "one, e.g., the test assertion.\n",
      "To alleviate manual efforts in writing unit tests,\n",
      "researchers have proposed various techniques to facilitate\n",
      "automated unit test generation. Traditional unit test\n",
      "generation techniques leverage search-based [3], [4],\n",
      "constraint-based [5] or random-based strategies [6] to\n",
      "generate a suite of unit tests with the main goal of\n",
      "maximizing the coverage in the software under test.\n",
      "Nevertheless, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory.\n",
      "Since LLMs have demonstrated promising results in\n",
      "tasks such as code generation, and given that both code\n",
      "generation and unit test case generation involve generating\n",
      "source code, recent research has extended the domain of\n",
      "code generation to encompass unit test case generation.\n",
      "Despite initial success, there are nuances that set unit\n",
      "test case generation apart from general code generation,\n",
      "signaling the need for more tailored approaches.\n",
      "Pre-training or fine-tuning LLMs for unit test case\n",
      "generation. Due to the limitations of LLMs in their earlier\n",
      "stages, a majority of the earlier published studies adopt\n",
      "this pre-training or fine-tuning schema. Moreover, in some\n",
      "recent studies, this schema continues to be employed to\n",
      "increase the LLMs’ familiarity with domain knowledge.\n",
      "Alagarsamy et al. [29] first pre-trained the LLM with the\n",
      "focal method and asserted statements to enable the LLM to\n",
      "have a stronger foundation knowledge of assertions, then\n",
      "fine-tuned the LLM for the test case generation task where\n",
      "the objective is to learn the relationship between the focal\n",
      "method and the corresponding test case. Tufano et al. [26]\n",
      "utilized a similar schema by pre-training the LLM on a\n",
      "large unsupervised Java corpus, and supervised fine-tuning\n",
      "a downstream translation task for generating unit tests.\n",
      "Hashtroudi et al. [32] leveraged the existing developer-\n",
      "written tests for each project to generate a project-specific\n",
      "dataset for domain adaptation when fine-tuning the LLM,\n",
      "which can facilitate generating human-readable unit tests.\n",
      "Rao et al. [35] trained a GPT-style language model by\n",
      "utilizing a pre-training signal that explicitly considers the\n",
      "mapping between code and test files. Steenhoek et al.\n",
      "[42] utilizes reinforcement learning to optimize models by\n",
      "providing rewards based on static quality metrics that can\n",
      "be automatically computed for the generated unit test cases.\n",
      "Designing effective prompts for unit test case genera-\n",
      "tion. The advancement of LLMs has allowed them to excel\n",
      "at targeted tasks without pre-training or fine-tuning. There-\n",
      "fore most later studies typically focus on how to design\n",
      "the prompt, to make the LLM better at understanding the\n",
      "context and nuances of this task. Xie et al. [36] generated\n",
      "unit test cases by parsing the project, extracting essential\n",
      "information, and creating an adaptive focal context that in-\n",
      "cludes a focal method and its dependencies within the pre-\n",
      "defined maximum prompt token limit of the LLM, and in-\n",
      "corporating these context into a prompt to query the LLM.8\n",
      "TABLE 3: Performance of unit test case generation\n",
      "Dataset Correctness Coverage LLM Paper\n",
      "5 Java projects from Defects4J 16.21% 5%-13% (line coverage) BART [26]\n",
      "10 Jave projects 40% 89% (line coverage), 90% (branch coverage) ChatGPT [36]\n",
      "CodeSearchNet 41% N/A ChatGPT [7]\n",
      "HumanEval 78% 87% (line coverage), 92% (branch coverage) Codex [39]\n",
      "SF110 2% 2% (line coverage), 1% (branch coverage) Codex [39]\n",
      "Note that, [39] experiments with Codex, CodeGen, and ChatGPT, and the best performance was achieved by Codex.\n",
      "Dakhel et al. [38] introduced MuTAP for improving the ef-\n",
      "fectiveness of test cases generated by LLMs in terms of re-\n",
      "vealing bugs by leveraging mutation testing. They augment\n",
      "prompts with surviving mutants, as those mutants highlight\n",
      "the limitations of test cases in detecting bugs. Zhang et al.\n",
      "[40] generated security tests with vulnerable dependencies\n",
      "with LLMs.\n",
      "Yuan et al. [7] first performed an empirical study to eval-\n",
      "uate ChatGPT’s capability of unit test generation with both\n",
      "a quantitative analysis and a user study in terms of cor-\n",
      "rectness, sufficiency, readability, and usability. And results\n",
      "show that the generated tests still suffer from correctness\n",
      "issues, including diverse compilation errors and execution\n",
      "failures. They further propose an approach that leveraged\n",
      "the ChatGPT itself to improve the quality of its generated\n",
      "tests with an initial test generator and an iterative test re-\n",
      "finer. Specifically, the iterative test refiner iteratively fixed\n",
      "the compilation errors in the tests generated by the initial\n",
      "test generator, which follows a validate-and-fix paradigm to\n",
      "prompt the LLM based on the compilation error messages\n",
      "and additional code context. Guilherme et al. [31] and Li\n",
      "et al. [41] respectively evaluated the quality of the gener-\n",
      "ated unit tests by LLM using different metrics and different\n",
      "prompts.\n",
      "Test generation with additional documentation.\n",
      "Vikram et al. [34] went a step further by investigating the\n",
      "potential of using LLMs to generate property-based tests\n",
      "when provided API documentation. They believe that the\n",
      "documentation of an API method can assist the LLM in\n",
      "producing logic to generate random inputs for that method\n",
      "and deriving meaningful properties of the result to check.\n",
      "Instead of generating unit tests from the source code, Plein\n",
      "et al. [33] generated the tests based on user-written bug\n",
      "reports.\n",
      "LLM and search-based method for unit test generation.\n",
      "The aforementioned studies utilize LLMs for the whole unit\n",
      "test case generation task, while Lemieux et al. [37] focus on\n",
      "a different direction, i.e., first letting the traditional search-\n",
      "based software testing techniques (e.g., Pynguin [137]) in\n",
      "generating unit test case until its coverage improvements\n",
      "stall, then asking the LLM to provide the example test cases\n",
      "for under-covered functions. These examples can help the\n",
      "original test generation redirect its search to more useful\n",
      "areas of the search space.\n",
      "Tang et al. [8] conducts a systematic comparison of test\n",
      "suites generated by the LLM and the state-of-the-art search-\n",
      "based software testing tool EvoSuite, by considering the cor-\n",
      "rectness, readability, code coverage, and bug detection ca-\n",
      "pability. Similarly, Bhatia [43] experimentally investigates\n",
      "the quality of unit tests generated by LLM compared to a\n",
      "commonly-used test generator Pynguin.\n",
      "Performance of unit test case generation. Since the\n",
      "aforementioned studies of unit test case generation are\n",
      "based on different datasets, one can hardly derive a fair\n",
      "comparison and we present the details in Table 3 to let\n",
      "the readers obtain a general view. We can see that in the\n",
      "SF110 benchmark, all three evaluated LLMs have quite low\n",
      "performance, i.e., 2% coverage [39]. SF110 is an Evosuite\n",
      "(a search-based unit test case generation technique)\n",
      "benchmark consisting of 111 open-source Java projects\n",
      "retrieved from SourceForge, containing 23,886 classes, over\n",
      "800,000 bytecode-level branches, and 6.6 million lines of\n",
      "code. The authors did not present detailed reasons for the\n",
      "low performance which can be further explored in the\n",
      "future.\n",
      "4.2 Test Oracle Generation\n",
      "A test oracle is a source of information about whether the\n",
      "output of a software system (or program or function or\n",
      "method) is correct or not [138]. Most of the collected studies\n",
      "in this category target the test assertion generation, which is\n",
      "inside a unit test case. Nevertheless, we opted to treat these\n",
      "studies as separate sections to facilitate a more thorough\n",
      "analysis.\n",
      "Test assertion, which is to indicate the potential issues\n",
      "in the tested code, is an important aspect that can distin-\n",
      "guish the unit test cases from the regular code. This is why\n",
      "some studies specifically focus on the generation of effec-\n",
      "tive test assertions. Actually, before using LLMs, researchers\n",
      "have proposed RNN-based approaches that aim at learning\n",
      "from thousands of unit test methods to generate meaning-\n",
      "ful assert statements [139], yet only 17% of the generated\n",
      "asserts can exactly match with the ground truth asserts. Sub-\n",
      "sequently, to improve the performance, several researchers\n",
      "utilized the LLMs for this task.\n",
      "Mastropaolo et al. [46], [132] pre-trained a T5 model on\n",
      "a dataset composed of natural language English text and\n",
      "source code. Then, it fine-tuned such a model by reusing\n",
      "datasets used in four previous works that used deep learn-\n",
      "ing techniques (such as RNN as mentioned before) includ-\n",
      "ing test assertion generation and program repair, etc. Results\n",
      "showed that the extract match rate of the generated test\n",
      "assertion is 57%. Tufano et al. [44] proposed a similar ap-\n",
      "proach which separately pre-trained the LLM with English\n",
      "corpus and code corpus, and then fine-tuned it on the asserts\n",
      "dataset (with test methods, focal methods, and asserts). This\n",
      "further improved the performance to 62% of the exact match\n",
      "rate. Besides the syntax-level data as previous studies, Nie et\n",
      "al. [45] fine-tuned the LLMs with six kinds of code semantics\n",
      "data, including the execution result (e.g., types of the local\n",
      "variables) and execution context (e.g., the last called method\n",
      "in the test method), which enabled LLMs to learn to under-\n",
      "stand the code execution information. The exact match rate9\n",
      "is 17% (note that this paper is based on a different dataset\n",
      "from all other studies mentioned under this topic).\n",
      "The aforementioned studies utilized the pre-training and\n",
      "fine-tuning schema when using LLMs, and with the increas-\n",
      "ingly powerful capabilities of LLMs, they can perform well\n",
      "on specific tasks without these specialized pre-training or\n",
      "fine-tuning datasets. Subsequently, Nashid et al. [47] uti-\n",
      "lized prompt engineering for this task, and proposed a tech-\n",
      "nique for prompt creation that automatically retrieves code\n",
      "demonstrations similar to the task, based on embedding\n",
      "or frequency analysis. They also present evaluations about\n",
      "the few-shot learning with various numbers (e.g., zero-shot,\n",
      "one-shot, or n-shot) and forms (e.g., random vs. systematic,\n",
      "or with vs. without natural language descriptions) of the\n",
      "prompts, to investigate its feasibility on test assertion gen-\n",
      "eration. With only a few relevant code demonstrations, this\n",
      "approach can achieve an accuracy of 76% for exact matches\n",
      "in test assertion generation, which is the state-of-the-art per-\n",
      "formance for this task.\n",
      "4.3 System Test Input Generation\n",
      "This category encompasses the studies related to creating\n",
      "test input of system testing for enabling the automation of\n",
      "test execution. We employ three subsections to present the\n",
      "analysis from three different orthogonal viewpoints, and\n",
      "each of the collected studies may be analyzed in one or\n",
      "more of these subsections.\n",
      "The first subsection is input generation in terms of software\n",
      "types. The generation of system-level test inputs for software\n",
      "testing varies for specific types of software being tested. For\n",
      "example, for mobile applications, the test input generation\n",
      "requires providing a diverse range of text inputs or oper-\n",
      "ation combinations (e.g., click a button, long press a list)\n",
      "[14], [49], which is the key to testing the application’s func-\n",
      "tionality and user interface; while for Deep Learning (DL)\n",
      "libraries, the test input is a program which covers diversified\n",
      "DL APIs [58], [59]. This subsection will demonstrate how the\n",
      "LLMs are utilized to generate inputs for different types of\n",
      "software.\n",
      "The second subsection input generation in terms of testing\n",
      "techniques. We have observed that certain approaches serve\n",
      "as specific types of testing techniques. For example, dozens\n",
      "of our collected studies specifically focus on using LLMs\n",
      "for fuzz testing. Therefore, this subsection would provide\n",
      "an analysis of the collected studies in terms of testing tech-\n",
      "niques, showcasing how the LLMs are employed to enhance\n",
      "traditional testing techniques.\n",
      "The third subsection input generation in terms of input and\n",
      "output. While most of the collected studies take the source\n",
      "code or the software itself as the input and directly output\n",
      "the software’s test input, there are studies that utilize alter-\n",
      "native forms of input and output. This subsection would\n",
      "provide an analysis of such studies, highlighting different\n",
      "approaches and their input-output characteristics.\n",
      "4.3.1 Input Generation in Terms of Software Types\n",
      "Figure 5 demonstrates the types of software under test in\n",
      "our collected studies. It is evident that the most prominent\n",
      "category is mobile apps, with five studies utilizing LLMs\n",
      "for testing, possibly due to their prevalence and importance\n",
      "/uni00000013/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000030/uni00000052/uni00000045/uni0000004c/uni0000004f/uni00000048/uni00000003/uni00000044/uni00000053/uni00000053\n",
      "/uni00000027/uni00000048/uni00000048/uni00000053/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004f/uni0000004c/uni00000045/uni00000055/uni00000044/uni00000055/uni0000005c\n",
      "/uni00000026/uni00000052/uni00000050/uni00000053/uni0000004c/uni0000004f/uni00000048/uni00000055\n",
      "/uni00000036/uni00000030/uni00000037/uni00000003/uni00000056/uni00000052/uni0000004f/uni00000059/uni00000048/uni00000055\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000051/uni00000052/uni00000050/uni00000052/uni00000058/uni00000056/uni00000003/uni00000047/uni00000055/uni0000004c/uni00000059/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni00000026/uni0000005c/uni00000045/uni00000048/uni00000055/uni00000003/uni00000053/uni0000004b/uni0000005c/uni00000056/uni0000004c/uni00000046/uni00000044/uni0000004f/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni0000002a/uni00000032/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051\n",
      "/uni0000002d/uni00000044/uni00000059/uni00000044/uni00000036/uni00000046/uni00000055/uni0000004c/uni00000053/uni00000057/uni00000003/uni00000048/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048\n",
      "/uni00000034/uni00000058/uni00000044/uni00000051/uni00000057/uni00000058/uni00000050/uni00000003/uni00000046/uni00000052/uni00000050/uni00000053/uni00000058/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000049/uni00000052/uni00000055/uni00000050\n",
      "/uni00000039/uni0000004c/uni00000047/uni00000048/uni00000052/uni00000003/uni0000004a/uni00000044/uni00000050/uni00000048\n",
      "/uni00000036/uni00000052/uni00000049/uni00000057/uni0000005a/uni00000044/uni00000055/uni00000048/uni00000003/uni00000038/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000037/uni00000048/uni00000056/uni00000057\n",
      "/uni00000018\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "Fig. 5: Distribution of software under test\n",
      "in today’s business and daily life. Additionally, there are\n",
      "respectively two studies focusing on testing deep learning\n",
      "libraries, compilers, and SMT solvers. Moreover, LLM-based\n",
      "testing techniques have also been applied to domains such\n",
      "as cyber-physical systems, quantum computing platforms,\n",
      "and more. This widespread adoption of LLMs demonstrates\n",
      "their effectiveness in handling diverse test inputs and en-\n",
      "hancing testing activities across various software domains.\n",
      "A detailed analysis is provided below.\n",
      "Test input generation for mobile apps. For mobile app\n",
      "testing, one difficulty is to generate the appropriate text in-\n",
      "puts to proceed to the next page, which remains a prominent\n",
      "obstacle for testing coverage. Considering the diversity and\n",
      "semantic requirement of valid inputs (e.g., flight departure,\n",
      "movie name), traditional techniques with heuristic-based or\n",
      "constraint-based techniques [10], [140] are far from generat-\n",
      "ing meaningful text input. Liu et al. [49] employ the LLM\n",
      "to intelligently generate the semantic input text according\n",
      "to the GUI context. In detail, their proposed QTypist auto-\n",
      "matically extracts the component information related to the\n",
      "EditText for generating the prompts, and then inputs the\n",
      "prompts into the LLM to generate the input text.\n",
      "Besides the text input, there are other forms of input\n",
      "for mobile apps, i.e., operations like ‘click a button’ and\n",
      "‘select a list’. To fully test an app, it is required to cover\n",
      "more GUI pages and conduct more meaningful exploration\n",
      "traces through the GUI operations, yet existing studies with\n",
      "random-/rule-based methods [9], [10], model-based meth-\n",
      "ods [11], [12], and learning-based methods [13] are unable\n",
      "to understand the semantic information of the GUI page\n",
      "thus could not conduct the trace planning effectively. Liu et\n",
      "al. [14] formulates the test input generation of mobile GUI\n",
      "testing problem as a Q&A task, which asks LLM to chat\n",
      "with the mobile apps by passing the GUI page information\n",
      "to LLM to elicit testing scripts (i.e., GUI operation), and\n",
      "executing them to keep passing the app feedback to LLM, it-\n",
      "erating the whole process. The proposed GPTDroid extracts\n",
      "the static context of the GUI page and the dynamic context\n",
      "of the iterative testing process, and designs prompts for in-\n",
      "putting this information to LLM which enables the LLM to\n",
      "better understand the GUI page as well as the whole testing\n",
      "process. It also introduces a functionality-aware memory\n",
      "prompting mechanism that equips the LLM with the abil-\n",
      "ity to retain testing knowledge of the whole process and\n",
      "conduct long-term, functionality-based reasoning to guide\n",
      "exploration. Similarly, Zimmermann et al. utilize the LLM to10\n",
      "interpret natural language test cases and programmatically\n",
      "navigate through the application under test [54].\n",
      "Yu et al. [61] investigate the LLM’s capabilities in the\n",
      "mobile app test script generation and migration task, in-\n",
      "cluding the scenario-based test generation, and the cross-\n",
      "platform/app test migration.\n",
      "Test input generation for DL libraries. The input for\n",
      "testing DL libraries is DL programs, and the difficulty\n",
      "in generating the diversified input DL programs is that\n",
      "they need to satisfy both the input language (e.g., Python)\n",
      "syntax/semantics and the API input/shape constraints for\n",
      "tensor computations. Traditional techniques with API-level\n",
      "fuzzing [141], [142] or model-level fuzzing [143], [144]\n",
      "suffer from the following limitations: 1) lack of diverse API\n",
      "sequence thus cannot reveal bugs caused by chained API\n",
      "sequences; 2) cannot generate arbitrary code thus cannot\n",
      "explore the huge search space that exists when using the DL\n",
      "libraries. Since LLMs can include numerous code snippets\n",
      "invoking DL library APIs in their training corpora, they\n",
      "can implicitly learn both language syntax/semantics and\n",
      "intricate API constraints for valid DL program generation.\n",
      "Taken in this sense, Deng et al. [59] used both generative\n",
      "and infilling LLMs to generate and mutate valid/diverse\n",
      "input DL programs for fuzzing DL libraries. In detail, it first\n",
      "uses a generative LLM (CodeX) to generate a set of seed\n",
      "programs (i.e., code snippets that use the target DL APIs).\n",
      "Then it replaces part of the seed program with masked\n",
      "tokens using different mutation operators and leverages the\n",
      "ability of infilling LLM (InCoder) to perform code infilling\n",
      "to generate new code that replaces the masked tokens. Their\n",
      "follow-up study [58] goes a step further to prime LLMs to\n",
      "synthesize unusual programs for the fuzzing DL libraries.\n",
      "It is built on the well-known hypothesis that historical\n",
      "bug-triggering programs may include rare/valuable code\n",
      "ingredients important for bug finding and show improved\n",
      "bug detection performance.\n",
      "Test input generation for other types of software.There\n",
      "are also dozens of studies that address testing tasks in vari-\n",
      "ous other domains, due to space limitations, we will present\n",
      "a selection of representative studies in these domains.\n",
      "Finding bugs in a commercial cyber-physical system\n",
      "(CPS) development tool such as Simulink is even more\n",
      "challenging. Given the complexity of the Simulink language,\n",
      "generating valid Simulink model files for testing is an\n",
      "ambitious task for traditional machine learning or deep\n",
      "learning techniques. Shrestha et al. [51] employs a small set\n",
      "of Simulink-specific training data to fine-tune the LLM for\n",
      "generating Simulink models. Results show that it can create\n",
      "Simulink models quite similar to the open-source models,\n",
      "and can find a super-set of the bugs traditional fuzzing\n",
      "approaches found.\n",
      "Sun et al. [63] utilize LLM to generate test formulas for\n",
      "fuzzing SMT solvers. It retrains the LLMs on a large corpus\n",
      "of SMT formulas to enable them to acquire SMT-specific\n",
      "domain knowledge. Then it further fine-tunes the LLMs\n",
      "on historical bug-triggering formulas, which are known\n",
      "to involve structures that are more likely to trigger bugs\n",
      "and solver-specific behaviors. The LLM-based compiler\n",
      "fuzzer proposed by Yang et al. [69] adopts a dual-model\n",
      "framework: (1) an analysis LLM examines the low-level\n",
      "optimization source code and produces requirements on the\n",
      "high-level test programs that can trigger the optimization;\n",
      "(2) a generation LLM produces test programs based on the\n",
      "summarized requirements. Ye et al. [48] utilize the LLM\n",
      "for generating the JavaScript programs and then use the\n",
      "well-structured ECMAScript specifications to automatically\n",
      "generate test data along with the test programs, after that\n",
      "they apply differential testing to expose bugs.\n",
      "4.3.2 Input Generation in Terms of Testing Techniques\n",
      "By utilizing system test inputs generated by LLMs, the col-\n",
      "lected studies aim to enhance traditional testing techniques\n",
      "and make them more effective. Among these techniques,\n",
      "fuzz testing is the most commonly involved one. Fuzz test-\n",
      "ing, as a general concept, revolves around generating in-\n",
      "valid, unexpected, or random data as inputs to evaluate the\n",
      "behavior of software. LLMs play a crucial role in improv-\n",
      "ing traditional fuzz testing by facilitating the generation of\n",
      "diverse and realistic input data. This enables fuzz testing to\n",
      "uncover potential bugs in the software by subjecting it to a\n",
      "wide range of input scenarios. In addition to fuzz testing,\n",
      "LLMs also contribute to enhancing other testing techniques,\n",
      "which will be discussed in detail later.\n",
      "Universal fuzzing framework. Xia et al. [67] present\n",
      "Fuzz4All that can target many different input languages\n",
      "and many different features of these languages. The key\n",
      "idea behind it is to leverage LLMs as an input generation\n",
      "and mutation engine, which enables the approach to\n",
      "produce diverse and realistic inputs for any practically\n",
      "relevant language. To realize this potential, they present\n",
      "a novel auto-prompting technique, which creates LLM\n",
      "prompts that are well-suited for fuzzing, and a novel\n",
      "LLM-powered fuzzing loop, which iteratively updates the\n",
      "prompt to create new fuzzing inputs. They experiment\n",
      "with six different languages (C, C++, Go, SMT2, Java and\n",
      "Python) as inputs and demonstrate higher coverage than\n",
      "existing language-specific fuzzers. Hu et al. [52] propose a\n",
      "greybox fuzzer augmented by the LLM, which picks a seed\n",
      "in the fuzzer’s seed pool and prompts the LLM to produce\n",
      "the mutated seeds that might trigger a new code region\n",
      "of the software. They experiment with three categories of\n",
      "input formats, i.e., formatted data files (e.g., json, xml),\n",
      "source code in different programming languages (e.g., JS,\n",
      "SQL, C), text with no explicit syntax rules (e.g., HTTP\n",
      "response, md5 checksum). In addition, effective fuzzing\n",
      "relies on the effective fuzz driver, and Zhang et al. [66]\n",
      "utilize LLMs on the fuzz driver generation, in which five\n",
      "query strategies are designed and analyzed from basic to\n",
      "enhanced.\n",
      "Fuzzing techniques for specific software. There are\n",
      "studies that focus on the fuzzing techniques tailored to\n",
      "specific software, e.g., the deep learning library [58], [59],\n",
      "compiler [69], SMT solvers [63], input widget of mobile app\n",
      "[65], cyber-physical system [51], etc. One key focus of these\n",
      "fuzzing techniques is to generate diverse test inputs so as\n",
      "to achieve higher coverage. This is commonly achieved\n",
      "by combining the mutation technique with LLM-based\n",
      "generation, where the former produces various candidates\n",
      "while the latter is responsible for generating the executable\n",
      "test inputs [59], [63]. Another focus of these fuzzing\n",
      "techniques is to generate the risky test inputs that can\n",
      "trigger bugs earlier. To achieve this, a common practice is to11\n",
      "collect the historical bug-triggering programs to fine-tune\n",
      "the LLM [63] or treat them as the demonstrations when\n",
      "querying the LLM [58], [65].\n",
      "Other testing techniques. There are studies that utilize\n",
      "LLMs for enhancing GUI testing for generating meaningful\n",
      "text input [49] and functionality-oriented exploration traces\n",
      "[14], which has been introduced in Test input generation for\n",
      "mobile apps part of Section 4.3.1.\n",
      "Besides, Deng et al. [62] leverage the LLMs to carry out\n",
      "penetration testing tasks automatically. It involves setting a\n",
      "penetration testing goal for the LLM, soliciting it for the\n",
      "appropriate operation to execute, implementing it in the\n",
      "testing environment, and feeding the test outputs back to\n",
      "the LLM for next-step reasoning.\n",
      "4.3.3 Input Generation in Terms of Input and Output\n",
      "Other output format of test generation. Although most\n",
      "works use LLM to generate test cases directly, there are also\n",
      "some works generating indirect inputs like testing code, test\n",
      "scenarios, metamorphic relations, etc. Liu et al. [65] pro-\n",
      "pose InputBlaster which leverages the LLM to automati-\n",
      "cally generate unusual text inputs for fuzzing the text input\n",
      "widgets in mobile apps. It formulates the unusual inputs\n",
      "generation problem as a task of producing a set of test gen-\n",
      "erators, each of which can yield a batch of unusual text\n",
      "inputs under the same mutation rule. In detail, InputBlaster\n",
      "leverages LLM to produce the test generators together with\n",
      "the mutation rules serving as the reasoning chain and uti-\n",
      "lizes the in-context learning schema to demonstrate the LLM\n",
      "with examples for boosting the performance. Deng et al.\n",
      "[64] use LLM to extract key information related to the test\n",
      "scenario from a traffic rule, and represent the extracted in-\n",
      "formation in a test scenario schema, then synthesize the\n",
      "corresponding scenario scripts to construct the test scenario.\n",
      "Luu et al. [56] examine the effectiveness of LLM in generat-\n",
      "ing metamorphic relations (MRs) for metamorphic testing.\n",
      "Their results show that ChatGPT can be used to advance\n",
      "software testing intelligence by proposing MRs candidates\n",
      "that can be later adapted for implementing tests, but human\n",
      "intelligence should still inevitably be involved to justify and\n",
      "rectify their correctness.\n",
      "Other input format of test generation. The aforemen-\n",
      "tioned studies primarily take the source code or the software\n",
      "as the input of LLM, yet there are also studies that take\n",
      "natural language description as the input for test generation.\n",
      "Mathur et al. [53] propose to generate test cases from the\n",
      "natural language described requirements. Ackerman et al.\n",
      "[60] generate the instances from natural language described\n",
      "requirements recursively to serve as the seed examples for a\n",
      "mutation fuzzer.\n",
      "4.4 Bug Analysis\n",
      "This category involves analyzing and categorizing the iden-\n",
      "tified software bugs to enhance understanding of the bug,\n",
      "and facilitate subsequent debug and bug repair. Mukher-\n",
      "jee et al. [73] generate relevant answers to follow-up ques-\n",
      "tions for deficient bug reports to facilitate bug triage. Su et\n",
      "al. [76] transform the bug-component triaging into a multi-\n",
      "classification task and a generation task with LLM, then\n",
      "ensemble the prediction results from them to improve the\n",
      "performance of bug-component triaging further. Zhang et\n",
      "al. [72] first leverage the LLM under the zero-shot setting\n",
      "to get essential information on bug reports, then use the\n",
      "essential information as the input to detect duplicate bug re-\n",
      "ports. Mahbub et al. [74] proposes to explain software bugs\n",
      "with LLM, which generates natural language explanations\n",
      "for software bugs by learning from a large corpus of bug-fix\n",
      "commits. Zhang et al. [70] target to automatically generate\n",
      "the bug title from the descriptions of the bug, which aims\n",
      "to help developers write issue titles and facilitate the bug\n",
      "triaging and follow-up fixing process.\n",
      "4.5 Debug\n",
      "This category refers to the process of identifying and locat-\n",
      "ing the cause of a software problem (i.e., bug). It involves\n",
      "analyzing the code, tracing the execution flow, collecting\n",
      "error information to understand the root cause of the issue,\n",
      "and fixing the issue. Some studies concentrate on the com-\n",
      "prehensive debug process, while others delve into specific\n",
      "sub-activities within the process.\n",
      "Overall debug framework. Bui et al. [77] proposes a uni-\n",
      "fied Detect-Localize-Repair framework based on the LLM\n",
      "for debugging, which first determines whether a given code\n",
      "snippet is buggy or not, then identifies the buggy lines, and\n",
      "translates the buggy code to its fixed version. Kang et al.\n",
      "[83] proposes automated scientific debugging, a technique\n",
      "that given buggy code and a bug-revealing test, prompts\n",
      "LLMs to automatically generate hypotheses, uses debuggers\n",
      "to actively interact with buggy code, and thus automati-\n",
      "cally reaches conclusions prior to patch generation. Chen\n",
      "et al. [88] demonstrate that self-debugging can teach the\n",
      "LLM to perform rubber duck debugging; i.e., without any\n",
      "human feedback on the code correctness or error messages,\n",
      "the model is able to identify its mistakes by investigating the\n",
      "execution results and explaining the generated code in nat-\n",
      "ural language. Cao et al. [89] conducts a study of LLM’s de-\n",
      "bugging ability for deep learning programs, including fault\n",
      "detection, fault localization and program repair.\n",
      "Bug localization. Wu et al. [85] compare the two LLMs\n",
      "(ChatGPT and GPT-4) with the existing fault localization\n",
      "techniques, and investigate the consistency of LLMs in fault\n",
      "localization, as well as how prompt engineering and the\n",
      "length of code context affect the results. Kang et al. [79]\n",
      "propose AutoFL, an automated fault localization technique\n",
      "that only requires a single failing test, and during its fault\n",
      "localization process, it also generates an explanation about\n",
      "why the given test fails. Yang et al. [84] propose LLMAO to\n",
      "overcome the left-to-right nature of LLMs by fine-tuning a\n",
      "small set of bidirectional adapter layers on top of the rep-\n",
      "resentations learned by LLMs, which can locate buggy lines\n",
      "of code without any test coverage information. Tu et al. [86]\n",
      "propose LLM4CBI to tame LLMs to generate effective test\n",
      "programs for finding suspicious files.\n",
      "Bug reproduction. There are also studies focusing on a\n",
      "sub-phase of the debugging process. For example, Kang et\n",
      "al. [78] and Plein et al. [81] respectively propose the frame-\n",
      "work to harness the LLM to reproduce bugs, and suggest\n",
      "bug reproducing test cases to the developer for facilitating\n",
      "debugging. Li et al. [87] focus on a similar aspect of finding\n",
      "the failure-inducing test cases whose test input can trigger12\n",
      "the software’s fault. It synergistically combines LLM and\n",
      "differential testing to do that.\n",
      "There are also studies focusing on the bug reproduc-\n",
      "tion of mobile apps to produce the replay script. Feng et\n",
      "al. [75] propose AdbGPT, a new lightweight approach to\n",
      "automatically reproduce the bugs from bug reports through\n",
      "prompt engineering, without any training and hard-coding\n",
      "effort. It leverages few-shot learning and chain-of-thought\n",
      "reasoning to elicit human knowledge and logical reasoning\n",
      "from LLMs to accomplish the bug replay in a manner similar\n",
      "to a developer. Huang et al. [71] propose CrashTranslator to\n",
      "automatically reproduce bugs directly from the stack trace.\n",
      "It accomplishes this by leveraging the LLM to predict the\n",
      "exploration steps for triggering the crash, and designing a\n",
      "reinforcement learning based technique to mitigate the in-\n",
      "accurate prediction and guide the search holistically. Taeb et\n",
      "al. [55] convert the manual accessibility test instructions into\n",
      "replayable, navigable videos by using LLM and UI element\n",
      "detection models, which can also help reveal accessibility\n",
      "issues.\n",
      "Error explanation. Taylor et al. [82] integrates the LLM\n",
      "into the Debugging C Compiler to generate unique, novice-\n",
      "focused explanations tailored to each error. Widjojo et al.\n",
      "[80] study the effectiveness of Stack Overflow and LLMs at\n",
      "explaining compiler errors.\n",
      "4.6 Program Repair\n",
      "This category denotes the task of fixing the identified\n",
      "software bugs. The high frequency of repair-related studies\n",
      "can be attributed to the close relationship between this\n",
      "task and the source code. With their advanced natural\n",
      "language processing and understanding capabilities, LLM\n",
      "are well-equipped to process and analyze source code,\n",
      "making them an ideal tool for performing code-related\n",
      "tasks such as fixing bugs.\n",
      "There have been template-based [145], heuristic-based\n",
      "[146], and constraint-based [147], [148] automatic program\n",
      "repair techniques. And with the development of deep\n",
      "learning techniques in the past few years, there have been\n",
      "several studies employing deep learning techniques for\n",
      "program repair. They typically adopt deep learning models\n",
      "to take a buggy software program as input and generate a\n",
      "patched program. Based on the training data, they would\n",
      "build a neural network model that learns the relations\n",
      "between the buggy code and the corresponding fixed code.\n",
      "Nevertheless, these techniques still fail to fix a large portion\n",
      "of bugs, and they typically have to generate hundreds to\n",
      "thousands of candidate patches and take hours to validate\n",
      "these patches to fix enough bugs. Furthermore, the deep\n",
      "learning based program repair models need to be trained\n",
      "with huge amounts of labeled training data (typically\n",
      "pairs of buggy and fixed code), which is time- and effort-\n",
      "consuming to collect the high-quality dataset. Subsequently,\n",
      "with the popularity and demonstrated capability of the\n",
      "LLMs, researchers begin to explore the LLMs for program\n",
      "repair.\n",
      "Patch single-line bugs. In the early era of program re-\n",
      "pair, the focus was mainly on addressing defects related to\n",
      "single-line code errors, which are relatively simple and did\n",
      "not require the repair of complex program logic. Lajk ´o et\n",
      "al. [95] propose to fine-tune the LLM with JavaScript code\n",
      "snippets to serve as the purpose for the JavaScript program\n",
      "repair. Zhang et al. [116] employs program slicing to extract\n",
      "contextual information directly related to the given buggy\n",
      "statement as repair ingredients from the corresponding pro-\n",
      "gram dependence graph, which makes the fine-tuning more\n",
      "focused on the buggy code. Zhang et al. [121] propose a\n",
      "stage-wise framework STEAM for patching single-line bugs,\n",
      "which simulates the interactive behavior of multiple pro-\n",
      "grammers involved in bug management, e.g., bug reporting,\n",
      "bug diagnosis, patch generation, and patch verification.\n",
      "Since most real-world bugs would involve multiple lines\n",
      "of code, and later studies explore these more complex situa-\n",
      "tions (although some of them can also patch the single-line\n",
      "bugs).\n",
      "Patch multiple-lines bugs. The studies in this category\n",
      "would input a buggy function to the LLM, and the goal is to\n",
      "output the patched function, which might involve complex\n",
      "semantic understanding, code hunk modification, as well\n",
      "as program refactoring. Earlier studies typically employ the\n",
      "fine-tuning strategy to enable the LLM to better understand\n",
      "the code semantics. Fu et al. [123] fine-tune the LLM by\n",
      "employing BPE tokenization to handle Out-Of-Vocabulary\n",
      "(OOV) issues which makes the approach generate new to-\n",
      "kens that never appear in a training function but are newly\n",
      "introduced in the repair. Wang et. al. [120] train the LLM\n",
      "based on both buggy input and retrieved bug-fix examples\n",
      "which are retrieved in terms of the lexical and semantical\n",
      "similarities. The aforementioned studies (including the ones\n",
      "in patching single-line bugs) would predict the fixed pro-\n",
      "grams directly, and Hu et al. [92] utilize a different setup\n",
      "that predicts the scripts that can fix the bugs when executed\n",
      "with the delete and insert grammar. For example, it predicts\n",
      "whether an original line of code should be deleted, and what\n",
      "content should be inserted.\n",
      "Nevertheless, fine-tuning may face limitations in terms\n",
      "of its reliance on abundant high-quality labeled data,\n",
      "significant computational resources, and the possibility of\n",
      "overfitting. To approach the program repair problem more\n",
      "effectively, later studies focus on how to design an effective\n",
      "prompt for program repair. Several studies empirically\n",
      "investigate the effectiveness of prompt variants of the latest\n",
      "LLMs for program repair under different repair settings\n",
      "and commonly-used benchmarks (which will be explored\n",
      "in depth later), while other studies focus on proposing\n",
      "new techniques. Ribeiro et al. [109] take advantage of\n",
      "LLM to conduct the code completion in a buggy line for\n",
      "patch generation, and elaborate on how to circumvent the\n",
      "open-ended nature of code generation to appropriately\n",
      "fit the new code in the original program. Xia et al. [115]\n",
      "propose the conversation-driven program repair approach\n",
      "that interleaves patch generation with instant feedback\n",
      "to perform the repair in a conversational style. They first\n",
      "feed the LLM with relevant test failure information to start\n",
      "with, and then learns from both failures and successes\n",
      "of earlier patching attempts of the same bug for more\n",
      "powerful repair. For earlier patches that failed to pass\n",
      "all tests, they combine the incorrect patches with their\n",
      "corresponding relevant test failure information to construct\n",
      "a new prompt for the LLM to generate the next patch,\n",
      "in order to avoid making the same mistakes. For earlier13\n",
      "TABLE 4: Performance of program repair\n",
      "Dataset % Correct patches LLM Paper\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs,\n",
      "HumanEval-Java\n",
      "22/40 Jave bugs (QuixBugs dataset, with InCoder-6B, correct\n",
      "code infilling setting)\n",
      "PLBART, CodeT5, CodeGen, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 10 LLMs in total)\n",
      "[113]\n",
      "QuixBugs 23/40 Python bugs, 14/40 Java bugs (complete function genera-\n",
      "tion setting)\n",
      "Codex-12B [100]\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs, Many-\n",
      "Bugs\n",
      "39/40 Python bugs, 34/40 Java bugs (QuixBugs dataset, with\n",
      "Codex-12B, correct code infilling setting); 37/40 Python bugs,\n",
      "32/40 Java bugs (QuixBugs dataset, with Codex-12B, complete\n",
      "function generation setting)\n",
      "Codex, GPT-Neo, CodeT5, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 9 LLMs in total)\n",
      "[93]\n",
      "QuixBugs 31/40 Python bugs (completion function generation setting) ChatGPT-175B [96]\n",
      "DL programs from Stack-\n",
      "Overflow\n",
      "16/72 Python bugs (complete function generation setting) ChatGPT-175B [89]\n",
      "Note that, for studies with multiple datasets or LLMs, we only present the best performance or in the most commonly utilized dataset.\n",
      "patches that passed all the tests (i.e., plausible patches),\n",
      "they further ask the LLM to generate alternative variations\n",
      "of the original plausible patches. This can further build on\n",
      "and learn from earlier successes to generate more plausible\n",
      "patches to increase the chance of having correct patches.\n",
      "Zhang et al. [94] propose a similar approach design by\n",
      "leveraging multimodal prompts (e.g., natural language\n",
      "description, error message, input-output-based test cases),\n",
      "iterative querying, test-case-based few-shot selection to\n",
      "produce repairs. Moon et al. [102] propose for bug fixing\n",
      "with feedback. It consists of a critic model to generate\n",
      "feedback, an editor to edit codes based on the feedback,\n",
      "and a feedback selector to choose the best possible feedback\n",
      "from the critic.\n",
      "Wei et. al. [103] propose Repilot to copilot the AI “copi-\n",
      "lots” (i.e., LLMs) by synthesizing more valid patches during\n",
      "the repair process. Its key insight is that many LLMs pro-\n",
      "duce outputs autoregressively (i.e., token by token), and by\n",
      "resembling human writing programs, the repair can be sig-\n",
      "nificantly boosted and guided through a completion engine.\n",
      "Brownlee et al. [105] propose to use the LLM as mutation\n",
      "operators for the search-based techniques of program repair.\n",
      "Repair with static code analyzer. Most of the program\n",
      "repair studies would suppose the bug has been detected,\n",
      "while Jin et al. [114] propose a program repair framework\n",
      "paired with a static analyzer to first detect the bugs, and\n",
      "then fix them. In detail, the static analyzer first detects an\n",
      "error (e.g., null pointer dereference) and the context infor-\n",
      "mation provided by the static analyzer will be sent into the\n",
      "LLM for querying the patch for this specific error. Wadhwa\n",
      "et al. [110] focus on a similar task, and additionally employ\n",
      "an LLM as the ranker to assess the likelihood of acceptance\n",
      "of generated patches which can effectively catch plausible\n",
      "but incorrect fixes and reduce developer burden.\n",
      "Repair for specific bugs. The aforementioned studies\n",
      "all consider the buggy code as the input for the automatic\n",
      "program repair, while other studies conduct program re-\n",
      "pairing in terms of other types of bug descriptions, specific\n",
      "types of bugs, etc. Fakhoury et al. [122] focus on program\n",
      "repair from natural language issue descriptions, i.e., gen-\n",
      "erating the patch with the bug and fix-related information\n",
      "described in the issue reports. Garg et al. [119] aim at re-\n",
      "pairing performance issues, in which they first retrieve a\n",
      "prompt instruction from a pre-constructed knowledge-base\n",
      "of previous performance bug fixes and then generate a re-\n",
      "pair prompt using the retrieved instruction. There are stud-\n",
      "ies focusing on the bug fixing of Rust programs [108] or\n",
      "OCaml programs (an industrial-strength programming lan-\n",
      "guage) [111].\n",
      "Empirical study about program repair.There are several\n",
      "studies related to the empirical or experimental evaluation\n",
      "of the various LLMs on program repair, and we summa-\n",
      "rize the performance in Table 4. Jiang et al. [113], Xia et al.\n",
      "[93], and Zhang et. al. [118] respectively conduct compre-\n",
      "hensive experimental evaluations with various LLMs and\n",
      "on different automated program repair benchmarks, while\n",
      "other researchers [89], [96], [98], [100] focus on a specific\n",
      "LLM and on one dataset, e.g., QuixBugs. In addition, Gao\n",
      "et al. [124] empirically investigate the impact of in-context\n",
      "demonstrations for bug fixing, including the selection, or-\n",
      "der, and number of demonstration examples. Prenner et al.\n",
      "[117] empirically study how the local context (i.e., code that\n",
      "comes before or after the bug location) affects the repair per-\n",
      "formance. Horv ´ath et al. [99] empirically study the impact\n",
      "of program representation and model architecture on the\n",
      "repair performance.\n",
      "There are two commonly-used repair settings when us-\n",
      "ing LLMs to generate patches: 1) complete function gen-\n",
      "eration (i.e., generating the entire patch function), 2) cor-\n",
      "rect code infilling (i.e., filling in a chunk of code given the\n",
      "prefix and suffix), and different studies might utilize differ-\n",
      "ent settings which are marked in Table 4. The commonly-\n",
      "used datasets are QuixBugs, Defects4J, etc. These datasets\n",
      "only involve the fundamental functionalities such as sorting\n",
      "algorithms, each program’s average number of lines rang-\n",
      "ing from 13 to 22, implementing one functionality, and in-\n",
      "volving few dependencies. To tackle this, Cao et al. [89]\n",
      "conducts an empirical study on a more complex dataset\n",
      "with DL programs collected from StackOverflow. Every pro-\n",
      "gram contains about 46 lines of code on average, imple-\n",
      "menting several functionalities including data preprocess-\n",
      "ing, DL model construction, model training, and evaluation.\n",
      "And the dataset involves more than 6 dependencies for each\n",
      "program, including TensorFlow, Keras, and Pytorch. Their\n",
      "results demonstrate a much lower rate of correct patches\n",
      "than in other datasets, which again reveals the potential\n",
      "difficulty of this task. Similarly, Haque et al. [106] introduce\n",
      "a dataset comprising of buggy code submissions and their\n",
      "corresponding fixes collected from online judge platforms,\n",
      "in which it offers an extensive collection of unit tests to\n",
      "enable the evaluations about the correctness of fixes and fur-\n",
      "ther information regarding time, memory constraints, and\n",
      "acceptance based on a verdict.14\n",
      "ChatGPT, 36\n",
      "25%\n",
      "Codex, 23\n",
      "16%\n",
      "CodeT5, 18\n",
      "13% GPT-4, 14\n",
      "10%\n",
      "GPT-3, 7\n",
      "5%\n",
      "CodeGen, 64%\n",
      "InCoder, 54%\n",
      "PLBART, 54%\n",
      "T5, 5\n",
      "4%\n",
      "CodeGPT, 4\n",
      "3%\n",
      "GPT-2, 4\n",
      "3%\n",
      "BART, 3\n",
      "2%\n",
      "StarCoder, 3\n",
      "2%\n",
      "UniXCoder, 2\n",
      "1%\n",
      "Others, 7\n",
      "5%\n",
      "Fig. 6: LLMs used in the collected papers\n",
      "5 A NALYSIS FROM LLM PERSPECTIVE\n",
      "This section discusses the analysis based on the viewpoints\n",
      "of LLM, specifically, it’s unfolded from the viewpoints of\n",
      "utilized LLMs, types of prompt engineering, input of the\n",
      "LLMs, as well as the accompanied techniques when utilizing\n",
      "LLM.\n",
      "5.1 LLM Models\n",
      "As shown in Figure 6, the most commonly utilized LLM\n",
      "in software testing tasks is ChatGPT, which was released\n",
      "on Nov. 2022 by OpenAI. It is trained on a large corpus\n",
      "of natural language text data, and primarily designed for\n",
      "natural language processing and conversation. ChatGPT is\n",
      "the most widely recognized and popular LLM up until now,\n",
      "known for its exceptional performance across various tasks.\n",
      "Therefore, it comes as no surprise that it ranks in the top\n",
      "position in terms of our collected studies.\n",
      "Codex, an LLM based on GPT-3, is the second most com-\n",
      "monly used LLM in our collected studies. It is trained on a\n",
      "massive code corpus containing examples from many pro-\n",
      "gramming languages such as JavaScript, Python, C/C++,\n",
      "and Java. Codex was released on Sep. 2021 by OpenAI and\n",
      "powers GitHub Copilot– an AI pair programmer that gener-\n",
      "ates whole code snippets, given a natural language descrip-\n",
      "tion as a prompt. Since a large portion of our collected stud-\n",
      "ies involve the source code (e.g., repair, unit test case gen-\n",
      "eration), it is not surprising that researchers choose Codex\n",
      "as the LLM in assisting them in accomplishing the coding-\n",
      "related tasks.\n",
      "The third-ranked LLM is CodeT5, which is an open-\n",
      "sourced LLM developed by salesforce 3. Thanks to its open\n",
      "source, researchers can easily conduct the pre-training and\n",
      "fine-tuning with domain-specific data to achieve better\n",
      "performance. Similarly, CodeGen is also open-sourced and\n",
      "ranked relatively higher. Besides, for CodeT5 and CodeGen,\n",
      "there are more than half of the related studies involve the\n",
      "empirical evaluations (which employ multiple LLMs), e.g.,\n",
      "program repair [112], [113], unit test case generation [39].\n",
      "3. https://blog.salesforceairesearch.com/codet5/\n",
      "There are already 14 studies that utilize GPT-4, ranking\n",
      "at the fourth place, which is launched on March 2023. Sev-\n",
      "eral studies directly utilize this state-of-the-art LLM of Ope-\n",
      "nAI, since it demonstrates excellent performance across a\n",
      "wide range of generation and reasoning tasks. For example,\n",
      "Xie et al. utilize GPT-4 to generate fuzzing inputs [67], while\n",
      "Vikram et al. employ it to generate property-based tests with\n",
      "the assistance of API documentation [34]. In addition, some\n",
      "studies conduct experiments using both GPT-4 and Chat-\n",
      "GPT or other LLMs to provide a more comprehensive evalu-\n",
      "ation of these models’ performance. In their proposed LLM-\n",
      "empowered automatic penetration testing technique, Deng\n",
      "et al. find that GPT-4 surpasses ChatGPT and LaMDA from\n",
      "Google [62]. Similarly, Zhang et al. find that GPT-4 shows\n",
      "its performance superiority over ChatGPT when generat-\n",
      "ing the fuzz drivers with both the basic query strategies\n",
      "and enhanced query strategies [66]. Furthermore, GPT-4, as\n",
      "a multi-modal LLM, sets itself apart from the other men-\n",
      "tioned LLMs by showcasing additional capabilities such as\n",
      "generating image narratives and answering questions based\n",
      "on images [149]. Yet we have not come across any studies\n",
      "that explore the utilization of GPT-4’s image-related features\n",
      "(e.g., UI screenshots, programming screencasts) in software\n",
      "testing tasks.\n",
      "5.2 Types of Prompt Engineering\n",
      "As shown in Figure 7, among our collected studies, 38\n",
      "studies utilize the LLMs through pre-training or fine-\n",
      "tuning schema, while 64 studies employ the prompt\n",
      "engineering to communicate with LLMs to steer its\n",
      "behavior for desired outcomes without updating the model\n",
      "weights. When using the early LLMs, their performances\n",
      "might not be as impressive, so researchers often use\n",
      "pre-training or fine-tuning techniques to adjust the models\n",
      "for specific domains and tasks in order to improve their\n",
      "performance. Then with the upgrading of LLM technology,\n",
      "especially with the introduction of GPT-3 and later\n",
      "LLMs, the knowledge contained within the models and\n",
      "their understanding/inference capability has increased\n",
      "significantly. Therefore, researchers will typically rely on\n",
      "prompt engineering to consider how to design appropriate\n",
      "prompts to stimulate the model’s knowledge.\n",
      "Among the 64 studies with prompt engineering, 51 stud-\n",
      "ies involve zero-shot learning, and 25 studies involve few-\n",
      "shot learning (a study may involve multiple types). There\n",
      "are also studies involving the chain-of-though (7 studies),\n",
      "self-consistency (1 study), and automatic prompt (1 study).\n",
      "Zero-shot learning is to simply feed the task text to the\n",
      "model and ask for results. Many of the collected studies em-\n",
      "ploy the Codex, CodeT5, and CodeGen (as shown in Section\n",
      "5.1), which is already trained on source code. Hence, for the\n",
      "tasks dealing with source code like unit test case generation\n",
      "and program repair as demonstrated in previous sections,\n",
      "directly querying the LLM with prompts is the common\n",
      "practice. There are generally two types of manners of zero-\n",
      "shot learning, i.e., with and without instructions. For exam-\n",
      "ple, Xie et al. [36] would provide the LLMs with the instruc-\n",
      "tions as “please help me generate a JUnit test for a specific\n",
      "Java method ...” to facilitate the unit test case generation.\n",
      "In contrast, Siddiq et al. [39] only provide the code header15\n",
      "Fig. 7: Distribution about how LLM is used (Note that, a study can involve multiple types of prompt engineering)\n",
      "of the unit test case (e.g., “class $ {className}${suffix}Test\n",
      "{”), and the LLMs would carry out the unit test case gener-\n",
      "ation automatically. Generally speaking, prompts with clear\n",
      "instructions will yield more accurate results, while prompts\n",
      "without instructions are typically suitable for very specific\n",
      "situations.\n",
      "Few-shot learning presents a set of high-quality demon-\n",
      "strations, each consisting of both input and desired output,\n",
      "on the target task. As the model first sees the examples,\n",
      "it can better understand human intention and criteria for\n",
      "what kinds of answers are wanted, which is especially im-\n",
      "portant for tasks that are not so straightforward or intuitive\n",
      "to the LLM. For example, when conducting the automatic\n",
      "test generation from general bug reports, Kang et al. [78]\n",
      "provide examples of bug reports (questions) and the corre-\n",
      "sponding bug reproducing tests (answers) to the LLM, and\n",
      "their results show that two examples can achieve the highest\n",
      "performance than no examples or other number of exam-\n",
      "ples. Another example of test assertion generation, Nashid\n",
      "et al. [47] provide demonstrations of the focal method, the\n",
      "test method containing an <AssertPlaceholder>, and the ex-\n",
      "pected assertion, which enables the LLMs to better under-\n",
      "stand the task.\n",
      "Chain-of-thought (CoT) prompting generates a\n",
      "sequence of short sentences to describe reasoning logics\n",
      "step by step (also known as reasoning chains or rationales)\n",
      "to the LLMs for generating the final answer. For example,\n",
      "for program repair from the natural language issue\n",
      "descriptions [122], given the buggy code and issue report,\n",
      "the authors first ask the LLM to localize the bug, and then\n",
      "they ask it to explain why the localized lines are buggy,\n",
      "finally, they ask the LLM to fix the bug. Another example is\n",
      "for generating unusual programs for fuzzing deep learning\n",
      "libraries, Deng et al. [58] first generate a possible “bug” (bug\n",
      "description) before generating the actual “bug-triggering”\n",
      "code snippet that invokes the target API. The predicted\n",
      "bug description provides an additional hint to the LLM,\n",
      "indicating that the generated code should try to cover\n",
      "specific potential buggy behavior.\n",
      "Self-consistency involves evaluating the coherence and\n",
      "consistency of the LLM’s responses on the same input in\n",
      "different contexts. There is one study with this prompt\n",
      "type, and it is about debugging. Kang et al. [83] employ a\n",
      "hypothesize-observe-conclude loop, which first generates\n",
      "a hypothesis about what the bug is and constructs an\n",
      "experiment to verify, using an LLM, then decide whether\n",
      "the hypothesis is correct based on the experiment result\n",
      "(with a debugger or code execution) using an LLM, after\n",
      "that, depending on the conclusion, it either starts with a\n",
      "new hypothesis or opts to terminate the debugging process\n",
      "and generate a fix.\n",
      "Automatic prompt aims to automatically generate and\n",
      "select the appropriate instruction for the LLMs, instead of\n",
      "requiring the user to manually engineer a prompt. Xia et\n",
      "al. [67] introduce an auto-prompting step that automatically\n",
      "distils all user-provided inputs into a concise and effective\n",
      "prompt for fuzzing. Specifically, they first generate a list of\n",
      "candidate prompts by incorporating the user inputs and\n",
      "auto prompting instruction while setting the LLM at high\n",
      "temperature, then a small-scale fuzzing experiment is con-\n",
      "ducted to evaluate each candidate prompt, and the best one\n",
      "is selected.\n",
      "Note that there are fourteen studies that apply the it-\n",
      "erative prompt design when using zero-shot or few-shot\n",
      "learning, in which the approach continuously refines the\n",
      "prompts with the running information of the testing task,\n",
      "e.g., the test failure information. For example, for program\n",
      "repair, Xia et al. [115] interleave patch generation with test\n",
      "validation feedback to prompt future generation iteratively.\n",
      "In detail, they incorporate various information from a failing\n",
      "test including its name, the relevant code line(s) triggering\n",
      "the test failure, and the error message produced in the next\n",
      "round of prompting which can help the model understand\n",
      "the failure reason and provide guidance towards generating\n",
      "the correct fix. Another example is for mobile GUI testing,\n",
      "Liu et al. [14] iteratively query the LLM about the operation\n",
      "(e.g., click a button, enter a text) to be conducted in the\n",
      "mobile app, and at each iteration, they would provide the\n",
      "LLM with current context information like which GUI pages\n",
      "and widgets have just explored.\n",
      "Mapping between testing tasks and how LLMs are\n",
      "used. Figure 8 demonstrates the mapping between the test-\n",
      "ing tasks (mentioned in Section 4) and how LLMs are used\n",
      "(as introduced in this subsection). The unit test case gen-\n",
      "eration and program repair share similar patterns of com-\n",
      "municating with the LLMs, since both tasks are closely re-\n",
      "lated to the source code. Typically, researchers utilize pre-\n",
      "training and/or fine-tuning and zero-shot learning methods\n",
      "for these two tasks. Zero-shot learning is suitable because\n",
      "these tasks are relatively straightforward and can be easily\n",
      "understood by LLMs. Moreover, since the training data for\n",
      "these two tasks can be automatically collected from source\n",
      "code repositories, pre-training and/or fine-tuning methods16\n",
      "Fig. 8: Mapping between testing tasks and how LLMs are\n",
      "used\n",
      "Code, 78\n",
      "68%\n",
      "Bug description, 1210%\n",
      "Error information, 7\n",
      "6%\n",
      "View hierarchy file of UI, 6\n",
      "5%\n",
      "Others, 12\n",
      "10%\n",
      "Fig. 9: Input of LLM\n",
      "are widely employed for these two tasks, which can enhance\n",
      "LLMs’ understanding of domain-specific knowledge.\n",
      "In comparison, for system test input generation, zero-\n",
      "shot learning and few-shot learning methods are commonly\n",
      "used. This might be because this task often involves gener-\n",
      "ating specific types of inputs, and demonstrations in few-\n",
      "shot learning can assist the LLMs in better understanding\n",
      "what should be generated. Besides, for this task, the uti-\n",
      "lization of pre-training and/or fine-tuning methods are not\n",
      "as widespread as in unit test case generation and program\n",
      "repair. This might be attributed to the fact that training data\n",
      "for system testing varies across different software and is\n",
      "relatively challenging to collect automatically.\n",
      "5.3 Input of LLM\n",
      "We also find that different testing tasks or software under\n",
      "test might involve diversified input when querying the\n",
      "LLM, as demonstrated in Figure 9.\n",
      "The most commonly utilized input is the source code\n",
      "since a large portion of collected studies relate to program\n",
      "repair or unit test case generation whose input are source\n",
      "code. For unit test case generation, typical code-related in-\n",
      "formation would be (i) the complete focal method, including\n",
      "the signature and body; (ii) the name of the focal class (i.e.,\n",
      "the class that the focal method belongs to); (iii) the field in\n",
      "the focal class; and (iv) the signatures of all methods defined\n",
      "in the focal class [7], [26]. For program repair, there can be\n",
      "different setups and involve different inputs, including (i)\n",
      "inputting a buggy function with the goal of outputting the\n",
      "patched function, (ii) inputting the buggy location with the\n",
      "goal of generating the correct replacement code (can be a\n",
      "single line change) given the prefix and suffix of the buggy\n",
      "function [93]. Besides, there can be variations for the buggy\n",
      "location input, i.e., (i) does not contain the buggy lines (but\n",
      "the bug location is still known), (ii) give the buggy lines as\n",
      "lines of comments.\n",
      "There are also 12 studies taking the bug description as\n",
      "input for the LLM. For example, Kang et al. [78] take the\n",
      "bug description as input when querying LLM and let the\n",
      "LLM generate the bug-reproducing test cases. Fakhoury et\n",
      "al. [122] input the natural language descriptions of bugs to\n",
      "the LLM, and generate the correct code fixes.\n",
      "There are 7 studies that would provide the intermedi-\n",
      "ate error information , e.g., test failure information, to the\n",
      "LLM, and would conduct the iterative prompt (as described\n",
      "in Section 5.2) to enrich the context provided to the LLM.\n",
      "These studies are related to the unit test case generation\n",
      "and program repair, since in these scenarios, the running\n",
      "information can be acquired easily.\n",
      "When testing mobile apps, since the utilized LLM could\n",
      "not understand the image of the GUI page, the view hierar-\n",
      "chy file which represents the details of the GUI page usually\n",
      "acts as the input to LLMs. Nevertheless, with the emergence\n",
      "of GPT-4 which is a multimodal model and accepts both\n",
      "image and text inputs for model input, the GUI screenshots\n",
      "might be directly utilized for LLM’s input.\n",
      "5.4 Incorporating Other Techniques with LLM\n",
      "There are divided opinions on whether LLM has reached\n",
      "an all-powerful status that requires no other techniques. As\n",
      "shown in Figure 10, among our collected studies, 67 of them\n",
      "utilize LLMs to address the entire testing task, while 35 stud-\n",
      "ies incorporate additional techniques. These techniques in-\n",
      "clude mutation testing, differential testing, syntactic check-\n",
      "ing, program analysis, statistical analysis, etc. .\n",
      "The reason why researchers still choose to combine\n",
      "LLMs with other techniques might be because, despite\n",
      "exhibiting enormous potential in various tasks, LLMs still\n",
      "possess limitations such as comprehending code semantics\n",
      "and handling complex program structures. Therefore,\n",
      "combining LLMs with other techniques optimizes their\n",
      "strengths and weaknesses to achieve better outcomes in\n",
      "specific scenarios. In addition, it is important to note that\n",
      "while LLMs are capable of generating correct code, they\n",
      "may not necessarily produce sufficient test cases to check\n",
      "for edge cases or rare scenarios. This is where mutation\n",
      "and other testing techniques come into play, as they allow\n",
      "for the generation of more diverse and complex code that\n",
      "can better simulate real-world scenarios. Taken in this\n",
      "sense, a testing approach can incorporate a combination\n",
      "of different techniques, including both LLMs and other\n",
      "testing strategies, to ensure comprehensive coverage and\n",
      "effectiveness.\n",
      "LLM + statistical analysis. As LLMs can often generate\n",
      "a multitude of outputs, manually sifting through and iden-\n",
      "tifying the correct output can be overwhelmingly laborious.\n",
      "As such, researchers have turned to statistical analysis tech-\n",
      "niques like ranking and clustering [28], [45], [78], [93], [116]17\n",
      "Fig. 10: Distribution about other techniques incorporated with LLMs (Note that, a study can involve multiple types)\n",
      "to efficiently filter through LLM’s outputs and ultimately\n",
      "obtain more accurate results.\n",
      "LLM + program analysis. When utilizing LLMs to\n",
      "accomplish tasks such as generating unit test cases and\n",
      "repairing software code, it is important to consider that\n",
      "software code inherently possesses structural information,\n",
      "which may not be fully understood by LLMs. Hence,\n",
      "researchers often utilize program analysis techniques,\n",
      "including code abstract syntax trees (ASTs) [74], to\n",
      "represent the structure of code more effectively and increase\n",
      "the LLM’s ability to comprehend the code accurately.\n",
      "Researchers also perform the structure-based subsetting\n",
      "of code lines to narrow the focus for LLM [94], or extract\n",
      "additional code context from other code files [7], to enable\n",
      "the models to focus on the most task-relevant information\n",
      "in the codebase and lead to more accurate predictions.\n",
      "LLM + mutation testing. It is mainly targeting at gener-\n",
      "ating more diversified test inputs. For example, Deng et al.\n",
      "[59] first use LLM to generate the seed programs (e.g., code\n",
      "snippets using a target DL API) for fuzzing deep learning\n",
      "libraries. To enrich the pool of these test programs, they\n",
      "replace parts of the seed program with masked tokens using\n",
      "mutation operators (e.g., replaces the API call arguments\n",
      "with the span token) to produce masked inputs, and again\n",
      "utilize the LLMs to perform code infilling to generate new\n",
      "code that replaces the masked tokens.\n",
      "LLM + syntactic checking. Although LLMs have shown\n",
      "remarkable performance in various natural language pro-\n",
      "cessing tasks, the generated code from these models can\n",
      "sometimes be syntactically incorrect, leading to potential er-\n",
      "rors and reduced usability. Therefore, researchers have pro-\n",
      "posed to leverage syntax checking to identify and correct\n",
      "errors in the generated code. For example, in their work for\n",
      "unit test case generation, Alagarsamy et al. [29] addition-\n",
      "ally introduce a verification method to check and repair the\n",
      "naming consistency (i.e., revising the test method name to\n",
      "be consistent with the focal method name) and the test sig-\n",
      "natures (i.e., adding missing keywords like public, void, or\n",
      "@test annotations). Xie et al. [36] also validates the generated\n",
      "unit test case and employs rule-based repair to fix syntactic\n",
      "and simple compile errors.\n",
      "LLM + differential testing. Differential testing is well-\n",
      "suited to find semantic or logic bugs that do not exhibit\n",
      "explicit erroneous behaviors like crashes or assertion\n",
      "failures. In this category of our collected studies, the LLM\n",
      "is mainly responsible for generating valid and diversified\n",
      "inputs, while the differential testing helps to determine\n",
      "whether there is a triggered bug based on the software’s\n",
      "output. For example, Ye et al. [48] first uses LLM to\n",
      "produce random JavaScript programs, and leverages the\n",
      "language specification document to generate test data, then\n",
      "conduct the differential testing on JavaScript engines such\n",
      "as JavaScriptCore, ChakraCore, SpiderMonkey, QuickJS,\n",
      "etc. There are also studies utilizing the LLMs to generate\n",
      "test inputs and then conduct differential testing for fuzzing\n",
      "DL libraries [58], [59] and SAT solvers [63]. Li et al. [87]\n",
      "employs the LLM in finding the failure-inducing test cases.\n",
      "In detail, given a program under test, they first request the\n",
      "LLM to infer the intention of the program, then request the\n",
      "LLM to generate programs that have the same intention,\n",
      "which are alternative implementations of the program, and\n",
      "are likely free of the program’s bug. Then they perform\n",
      "the differential testing with the program under test and the\n",
      "generated programs to find the failure-inducing test cases.\n",
      "6 C HALLENGES AND OPPORTUNITIES\n",
      "Based on the above analysis from the viewpoints of soft-\n",
      "ware testing and LLM, we summarize the challenges and\n",
      "opportunities when conducting software testing with LLM.\n",
      "6.1 Challenges\n",
      "As indicated by this survey, software testing with LLMs\n",
      "has undergone significant growth in the past two years.\n",
      "However, it is still in its early stages of development, and\n",
      "numerous challenges and open questions need to be ad-\n",
      "dressed.\n",
      "6.1.1 Challenges for Achieving High Coverage\n",
      "Exploring the diverse behaviors of the software under test\n",
      "to achieve high coverage is always a significant concern\n",
      "in software testing. In this context, test generation differs\n",
      "from code generation, as code generation primarily focuses\n",
      "on producing a single, correct code snippet, whereas soft-\n",
      "ware testing requires generating diverse test inputs to en-\n",
      "sure better coverage of the software. Although setting a high\n",
      "temperature can facilitate the LLMs in generating different\n",
      "outputs, it remains challenging for LLMs to directly achieve\n",
      "the required diversity. For example, for unit test case gen-\n",
      "eration, in SF110 dataset, the line coverage is merely 2%\n",
      "and the branch coverage is merely 1% [39]. For system test\n",
      "input generation, in terms of fuzzing DL libraries, the API\n",
      "coverage for TensorFlow is reported to be 66% (2215/3316)\n",
      "[59].18\n",
      "From our collected studies, we observe that the\n",
      "researchers often utilize mutation testing together with the\n",
      "LLMs to generate more diversified outputs. For example,\n",
      "when fuzzing a DL library, instead of directly generating\n",
      "the code snippet with LLM, Deng et al. [59] replace parts\n",
      "of the selected seed (code generated by LLM) with masked\n",
      "tokens using different mutation operators to produce\n",
      "masked inputs. They then leverage the LLM to perform\n",
      "code infilling to generate new code that replaces the masked\n",
      "tokens, which can significantly increase the diversity of the\n",
      "generated tests. Liu et al. [65] leverage LLM to produce the\n",
      "test generators (each of which can yield a batch of unusual\n",
      "text inputs under the same mutation rule) together with the\n",
      "mutation rules for text-oriented fuzzing, which reduces the\n",
      "human effort required for designing mutation rules.\n",
      "A potential research direction could involve utilizing\n",
      "testing-specific data to train or fine-tune a specialized LLM\n",
      "that is specifically designed to understand the nature of\n",
      "testing. By doing so, the LLM can inherently acknowledge\n",
      "the requirements of testing and autonomously generate\n",
      "diverse outputs.\n",
      "6.1.2 Challenges in Test Oracle Problem\n",
      "The oracle problem has been a longstanding challenge in\n",
      "various testing applications, e.g., testing machine learning\n",
      "systems [150] and testing deep learning libraries [59]. To\n",
      "alleviate the oracle problem to the overall testing activities,\n",
      "a common practice in our collected studies is to transform it\n",
      "into a more easily derived form, often by utilizing differen-\n",
      "tial testing [63] or focusing on only identifying crash bugs\n",
      "[14].\n",
      "There are successful applications of differential testing\n",
      "with LLMs, as shown in Figure 10. For instance, when\n",
      "testing the SMT solvers, Sun et al. adopt differential testing\n",
      "which involves comparing the results of multiple SMT\n",
      "solvers (i.e., Z3, cvc5, and Bitwuzla) on the same generated\n",
      "test formulas by LLM [63]. However, this approach is\n",
      "limited to systems where counterpart software or running\n",
      "environment can easily be found, potentially restricting\n",
      "its applicability. Moreover, to mitigate the oracle problem,\n",
      "other studies only focus on the crash bugs which are easily\n",
      "observed automatically. This is particularly the case for\n",
      "mobile applications testing, in which the LLMs guide the\n",
      "testing in exploring more diversified pages, conducting\n",
      "more complex operational actions, and covering more\n",
      "meaningful operational sequences [14]. However, this\n",
      "significantly restricts the potential of utilizing the LLMs for\n",
      "uncovering various types of software bugs.\n",
      "Exploring the use of LLMs to derive other types of\n",
      "test oracles represents an interesting and valuable research\n",
      "direction. Specifically, metamorphic testing is also widely\n",
      "used in software testing practices to help mitigate the oracle\n",
      "problem, yet in most cases, defining metamorphic relations\n",
      "relies on human ingenuity. Luu et al. [56] have examined the\n",
      "effectiveness of LLM in generating metamorphic relations,\n",
      "yet they only experiment with straightforward prompts by\n",
      "directly querying ChatGPT. Further exploration, potentially\n",
      "incorporating human-computer interaction or domain\n",
      "knowledge, is highly encouraged. Another promising\n",
      "avenue is exploring the capability of LLMs to automatically\n",
      "generate test cases based on metamorphic relations,\n",
      "covering a wide range of inputs.\n",
      "The advancement of multi-model LLMs like GPT-4 may\n",
      "open up possibilities for exploring their ability to detect\n",
      "bugs in software user interfaces and assist in deriving test\n",
      "oracles. By leveraging the image understanding and reason-\n",
      "ing capabilities of these models, one can investigate their\n",
      "potential to automatically identify inconsistencies, errors, or\n",
      "usability issues in user interfaces.\n",
      "6.1.3 Challenges for Rigorous Evaluations\n",
      "The lack of benchmark datasets and the potential data leak-\n",
      "age issues associated with LLM-based techniques present\n",
      "challenges in conducting rigorous evaluations and compre-\n",
      "hensive comparisons of proposed methods.\n",
      "For program repair, there are only two well-known and\n",
      "commonly-used benchmarks, i.e., Defect4J and QuixBugs,\n",
      "as demonstrated in Table 4. Furthermore, these datasets are\n",
      "not specially designed for testing the LLMs. For example, as\n",
      "reported by Xia et al. [93], 39 out of 40 Python bugs in the\n",
      "QuixBugs dataset can be fixed by Codex, yet in real-world\n",
      "practice, the successful fix rate can be nowhere near as high.\n",
      "For unit test case generation, there are no widely recognized\n",
      "benchmarks, and different studies would utilize different\n",
      "datasets for performance evaluation, as demonstrated in Ta-\n",
      "ble 3. This indicates the need to build more specialized and\n",
      "diversified benchmarks.\n",
      "Furthermore, the LLMs may have seen the widely-used\n",
      "benchmarks in their pre-training data, i.e., data leakage\n",
      "issues. Jiang et al. [113] check the CodeSearchNet and\n",
      "BigQuery, which are the data sources of common LLMs,\n",
      "and the results show that four repositories used by the\n",
      "Defect4J benchmark are also in CodeSearchNet, and the\n",
      "whole Defects4J repository is included by BigQuery.\n",
      "Therefore, it is very likely that existing program repair\n",
      "benchmarks are seen by the LLMs during pre-training. This\n",
      "data leakage issue has also been investigated in machine\n",
      "learning-related studies. For example, Tu et al. [151] focus\n",
      "on the data leakage in issue tracking data, and results show\n",
      "that information leaked from the “future” makes prediction\n",
      "models misleadingly optimistic. This reminds us that the\n",
      "performance of LLMs on software testing tasks may not be\n",
      "as good as reported in previous studies. It also suggests\n",
      "that we need more specialized datasets that are not seen by\n",
      "LLMs to serve as benchmarks. One way is to collect it from\n",
      "specialized sources, e.g., user-generated content from niche\n",
      "online communities.\n",
      "6.1.4 Challenges in Real-world Application of LLMs in Soft-\n",
      "ware Testing\n",
      "As we mentioned in Section 5.2, in the early days of us-\n",
      "ing LLMs, pre-training and fine-tuning are commonly used\n",
      "practice, considering the model parameters are relatively\n",
      "few resulting in weaker model capabilities (e.g., T5). As time\n",
      "progressed, the number of model parameters increased sig-\n",
      "nificantly, leading to the emergence of models with greater\n",
      "capabilities (e.g., ChatGPT). And in recent studies, prompt\n",
      "engineering has become a common approach. However, due\n",
      "to concerns regarding data privacy, when considering real-\n",
      "world practice, most software organizations tend to avoid19\n",
      "using commercial LLMs and would prefer to adopt open-\n",
      "source ones with training or fine-tuning using organization-\n",
      "specific data. Furthermore, some companies also consider\n",
      "the current limitations in terms of computational power or\n",
      "pay close attention to energy consumption, they tend to\n",
      "fine-tune medium-sized models. It is quite challenging for\n",
      "these models to achieve similar performance to what our\n",
      "collected papers have reported. For instance, in the widely-\n",
      "used QuixBugs dataset, it has been reported that 39 out of\n",
      "40 Python bugs and 34 out of 40 Java bugs can be automat-\n",
      "ically fixed [93]. However, when it comes to DL programs\n",
      "collected from Stack Overflow, which represent real-world\n",
      "coding practice, only 16 out of 72 Python bugs can be auto-\n",
      "matically fixed [89].\n",
      "Recent research has highlighted the importance of high-\n",
      "quality training data in improving the performance of mod-\n",
      "els for code-related tasks [152], yet manually building high-\n",
      "quality organization-specific datasets for training or fine-\n",
      "tuning is time-consuming and labor-intensive. To address\n",
      "this, one is encouraged to utilize the automated techniques\n",
      "of mining software repositories to build the datasets, for\n",
      "example, techniques like key information extraction tech-\n",
      "niques from Stack Overflow [153] offer potential solutions\n",
      "for automatically gathering relevant data.\n",
      "In addition, exploring the methodology for better fine-\n",
      "tuning the LLMs with software-specific data is worth con-\n",
      "sidering because software-specific data differs from natural\n",
      "language data as it contains more structural information,\n",
      "such as data flow and control flow. Previous research on\n",
      "code representations has shown the benefits of incorporat-\n",
      "ing data flow, which captures the semantic-level structure\n",
      "of code and represents the relationship between variables in\n",
      "terms of “whether-value-comes-from” [154]. These insights\n",
      "can provide valuable guidance for effectively fine-tuning\n",
      "LLMs with software-specific data.\n",
      "6.2 Opportunities\n",
      "There are also many research opportunities in software test-\n",
      "ing with LLMs, which can greatly benefit developers, users,\n",
      "and the research community. While not necessarily chal-\n",
      "lenges, these opportunities contribute to advancements in\n",
      "software testing, benefiting practitioners and the wider re-\n",
      "search community.\n",
      "6.2.1 Exploring LLMs in the Early Stage of Testing\n",
      "As shown in Figure 4, LLMs have not been used in the early\n",
      "stage of testing, e.g., test requirements, and test planning.\n",
      "There might be two main reasons behind that. The first is\n",
      "the subjectivity in early-stage testing tasks. Many tasks in\n",
      "the early stages of testing, such as requirements gathering,\n",
      "test plan creation, and design reviews, may involve subjec-\n",
      "tive assessments that require significant input from human\n",
      "experts. This could make it less suitable for LLMs that rely\n",
      "heavily on data-driven approaches. The second might be the\n",
      "lack of open-sourced data in the early stages. Unlike in later\n",
      "stages of testing, there may be limited data available online\n",
      "during early-stage activities. This could mean that LLMs\n",
      "may not have seen much of this type of data, and therefore\n",
      "may not perform well on these tasks.\n",
      "Adopting a human-computer interaction schema for\n",
      "tackling early-stage testing tasks would harness the domain-\n",
      "specific knowledge of human developers and leverage the\n",
      "general knowledge embedded in LLMs. Additionally, it is\n",
      "highly encouraged for software development companies\n",
      "to record and provide access to early-stage testing data,\n",
      "allowing for improved training and performance of LLMs\n",
      "in these critical testing activities.\n",
      "6.2.2 Exploring LLMs in Other Testing Phases\n",
      "We have analyzed the distribution of testing phases for the\n",
      "collected studies. As shown in Fig 11, we can observe that\n",
      "LLMs are most commonly used in unit testing, followed by\n",
      "system testing. However, there is still no research on the use\n",
      "of LLMs in integration testing and acceptance testing.\n",
      "/uni00000013/uni00000018/uni00000014/uni00000013/uni00000014/uni00000018/uni00000015/uni00000013/uni00000015/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000038/uni00000051/uni0000004c/uni00000057/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni0000002c/uni00000051/uni00000057/uni00000048/uni0000004a/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000036/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000024/uni00000046/uni00000046/uni00000048/uni00000053/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057/uni00000037/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000033/uni0000004b/uni00000044/uni00000056/uni00000048/uni00000056\n",
      "/uni00000015/uni00000017\n",
      "/uni00000013\n",
      "/uni00000015/uni00000015\n",
      "/uni00000013\n",
      "Fig. 11: Distribution of testing phases (note that we omit the\n",
      "studies which do not explicitly specify the testing phases,\n",
      "e.g., program repair)\n",
      "For integration testing, it involves testing the interfaces\n",
      "between different software modules. In some software or-\n",
      "ganizations, integration testing might be merged with unit\n",
      "testing, which can be a possible reason why LLM is rarely\n",
      "utilized in integration testing. Another reason might be that\n",
      "the size and complexity of the input data in this circum-\n",
      "stance may exceed the capacity of the LLM to process and\n",
      "analyze (e.g., the source code of all involved software mod-\n",
      "ules), which can lead to errors or unreliable results. To tackle\n",
      "this, a potential reference can be found in Section 4.1, where\n",
      "Xie et al. [36] design a method to organize the necessary\n",
      "information into the pre-defined maximum prompt token\n",
      "limit of the LLM. Furthermore, integration testing requires\n",
      "diversified data to be generated to sufficiently test the in-\n",
      "terface among multiple modules. As mentioned in Section\n",
      "4.3, previous work has demonstrated the LLM’s capability\n",
      "in generating diversified test input for system testing, in\n",
      "conjunction with mutation testing techniques [48], [59]. And\n",
      "these can provide insights about generating the diversified\n",
      "interface data for integration testing.\n",
      "Acceptance testing is usually conducted by business an-\n",
      "alysts or end-users to validate the system’s functionality\n",
      "and usability, which requires more non-technical language\n",
      "and domain-specific knowledge, thus making it challenging\n",
      "to apply LLM effectively. Since acceptance testing involves\n",
      "humans, it is well-suited for the use of human-in-the-loop\n",
      "schema with LLMs. This has been studied in traditional\n",
      "machine learning [155], but has not yet been explored with\n",
      "LLMs. Specifically, the LLMs can be responsible for auto-\n",
      "matically generating test cases, evaluating test coverage, etc,\n",
      "while human testers are responsible for checking the pro-\n",
      "gram’s behavior and verifying test oracle.20\n",
      "6.2.3 Exploring LLMs for More Types of Software\n",
      "We analyze what types of software have been explored in\n",
      "the collected studies, as shown in Figure 5. Note that, since\n",
      "a large portion of studies are focused on unit testing or\n",
      "program repair, they are conducted on publicly available\n",
      "datasets and do not involve specific software types.\n",
      "From the analysis in Section 4.3, the LLM can generate\n",
      "not only the source code for testing DL libraries but also\n",
      "the textual input for testing mobile apps, even the models\n",
      "for testing CPS. Overall, the LLM provides a flexible and\n",
      "powerful framework for generating test inputs for a wide\n",
      "range of applications. Its versatility would make it useful\n",
      "for testing the software in other domains.\n",
      "From one point of view, some proposed techniques can\n",
      "be applied to other types of software. For example, in the\n",
      "paper proposed for testing deep learning libraries [58], since\n",
      "it proposes techniques for generating diversified, compli-\n",
      "cated, and human-like DL programs, the authors state that\n",
      "the approach can be easily extended to test software systems\n",
      "from other application domains, e.g., interpreters, database\n",
      "systems, and other popular libraries. More than that, there\n",
      "are already studies that focus on universal fuzzing tech-\n",
      "niques [52], [67] which are designed to be adaptable and\n",
      "applicable to different types of test inputs and software.\n",
      "From another point of view, other types of software can\n",
      "also benefit from the capabilities of LLMs to design the test-\n",
      "ing techniques that are better suited to their specific do-\n",
      "main and characteristics. For instance, the metaverse, with\n",
      "its immersive virtual environments and complex interac-\n",
      "tions, presents unique challenges for software testing. LLMs\n",
      "can be leveraged to generate diverse and realistic inputs that\n",
      "mimic user behavior and interactions within the metaverse,\n",
      "which are never explored.\n",
      "6.2.4 Exploring LLMs for Non-functional Testing\n",
      "In our collected studies, LLMs are primarily used for func-\n",
      "tional testing, and no practice in performance testing, usabil-\n",
      "ity testing or others. One possible reason for the prevalence\n",
      "of LLM-based solutions in functional testing is that they\n",
      "can convert functional testing problems into code gener-\n",
      "ation or natural language generation problems [14], [59],\n",
      "which LLMs are particularly adept at solving.\n",
      "On the other hand, performance testing and usability\n",
      "testing may require more specialized models that are de-\n",
      "signed to detect and analyze specific types of data, handle\n",
      "complex statistical analyses, or determine the buggy criteria.\n",
      "Moreover, there have been dozens of performance testing\n",
      "tools (e.g., LoadRunner [156]) that can generate a workload\n",
      "that simulates real-world usage scenarios and achieve rela-\n",
      "tively satisfactory performance.\n",
      "The potential opportunities might let the LLM integrate\n",
      "the performance testing tools and acts like the LangChain\n",
      "[157], to better simulate different types of workloads based\n",
      "on real user behavior. Furthermore, the LLMs can identify\n",
      "the parameter combinations and values that have the high-\n",
      "est potential to trigger performance problems. It is essen-\n",
      "tially a way to rank and prioritize different parameter set-\n",
      "tings based on their impact on performance and improve\n",
      "the efficiency of performance testing.\n",
      "6.2.5 Exploring Advanced Prompt Engineering\n",
      "There are a total of 11 commonly used prompt engineering\n",
      "techniques as listed in a popular prompt engineering guide\n",
      "[158], as shown in Figure 12. Currently, in our collected\n",
      "studies, only the first five techniques are being utilized. The\n",
      "more advanced techniques have not been employed yet, and\n",
      "can be explored in the future for prompt design.\n",
      "/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni0000003d/uni00000048/uni00000055/uni00000052/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000029/uni00000048/uni0000005a/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000026/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni00000036/uni00000048/uni0000004f/uni00000049/uni00000010/uni00000046/uni00000052/uni00000051/uni00000056/uni0000004c/uni00000056/uni00000057/uni00000048/uni00000051/uni00000046/uni0000005c\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000003/uni0000004e/uni00000051/uni00000052/uni0000005a/uni0000004f/uni00000048/uni00000047/uni0000004a/uni00000048/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000037/uni00000055/uni00000048/uni00000048/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057/uni00000056\n",
      "/uni00000024/uni00000046/uni00000057/uni0000004c/uni00000059/uni00000048/uni00000010/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000027/uni0000004c/uni00000055/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000056/uni00000057/uni0000004c/uni00000050/uni00000058/uni0000004f/uni00000058/uni00000056/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000035/uni00000048/uni00000024/uni00000046/uni00000057/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000050/uni00000052/uni00000047/uni00000044/uni0000004f/uni00000003/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000055/uni00000048/uni00000044/uni00000056/uni00000052/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000044/uni00000051/uni00000047/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000010/uni00000058/uni00000056/uni00000048\n",
      "/uni00000033/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057/uni00000003/uni00000028/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048/uni00000048/uni00000055/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000018/uni00000014\n",
      "/uni00000015/uni00000018\n",
      "/uni0000001a\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "Fig. 12: List of advanced prompt engineering practices and\n",
      "those utilized in the collected papers\n",
      "For instance, multimodal chain of thought prompting in-\n",
      "volves using diverse sensory and cognitive cues to stimulate\n",
      "thinking and creativity in LLMs [159]. By providing images\n",
      "(e.g., GUI screenshots) or audio recordings related to the\n",
      "software under test can help the LLM better understand\n",
      "the software’s context and potential issues. Besides, try to\n",
      "prompt the LLM to imagine itself in different roles, such\n",
      "as a developer, user, or quality assurance specialist. This\n",
      "perspective-shifting exercise enables the LLM to approach\n",
      "software testing from multiple viewpoints and uncover dif-\n",
      "ferent aspects that might require attention or investigation.\n",
      "Graph prompting [160] involves the representation of\n",
      "information using graphs or visual structures to facilitate\n",
      "understanding and problem-solving. Graph prompting can\n",
      "be a natural match with software engineering, consider\n",
      "it involves various dependencies, control flow, data flow,\n",
      "state transitions, or other relevant graph structure. Graph\n",
      "prompting can be beneficial in analyzing this structural\n",
      "information, and enabling the LLMs to comprehend the\n",
      "software under test effectively. For instance, testers can use\n",
      "graph prompts to visualize test coverage, identify untested\n",
      "areas or paths, and ensure adequate test execution.\n",
      "6.2.6 Incorporating LLMs with Traditional Techniques\n",
      "There is currently no clear consensus on the extent to which\n",
      "LLMs can solve software testing problems. From the analy-\n",
      "sis in Section 5.4, we have seen some promising results from\n",
      "studies that have combined LLMs with traditional software\n",
      "testing techniques. This implies the LLMs are not the sole\n",
      "silver bullet for software testing. Considering the availabil-\n",
      "ity of many mature software testing techniques and tools,\n",
      "and the limited capabilities of LLMs, it is necessary to ex-\n",
      "plore other better ways to combine LLMs with traditional\n",
      "testing or program analysis techniques and tools for better\n",
      "software testing.21\n",
      "Based on the collected studies, the LLMs have been suc-\n",
      "cessfully utilized together with various techniques such as\n",
      "differential testing (e.g., [63]), mutation testing (e.g., [59]),\n",
      "program analysis (e.g., [104], as shown in Figure 10. From\n",
      "one perspective, future studies can explore improved in-\n",
      "tegration of these traditional techniques with LLMs. Take\n",
      "mutation testing as an example, current practices mainly\n",
      "rely on the human-designed mutation rules to mutate the\n",
      "candidate tests, and let the LLMs re-generate new tests [38],\n",
      "[59], [67], while Liu et al. directly utilize the LLMs for pro-\n",
      "ducing the mutation rules alongside the mutated tests [65].\n",
      "Further explorations in this direction are of great interest.\n",
      "From another point of view, more traditional techniques\n",
      "can be incorporated in LLMs for software testing. For in-\n",
      "stance, besides the aforementioned traditional techniques,\n",
      "the LLMs have been combined with formal verification for\n",
      "self-healing software detection in the field of software se-\n",
      "curity [161]. More attempts are encouraged. Moreover, con-\n",
      "sidering the existence of numerous mature software testing\n",
      "tools, one can explore the integration of LLMs with these\n",
      "tools, allowing them to act as a “LangChain” to better ex-\n",
      "plore the potential of these tools.\n",
      "7 R ELATED WORK\n",
      "The systematic literature review is a crucial manner for gain-\n",
      "ing insights into the current trends and future directions\n",
      "within a particular field. It enables us to understand and\n",
      "stay updated on the developments in that domain.\n",
      "Wang et al. surveyed the machine learning and deep\n",
      "learning techniques for software engineering [162]. Yang et\n",
      "al. and Watson et al. respectively carried out surveys about\n",
      "the use of deep learning in software engineering domain\n",
      "[163], [164]. Bajammal et al. surveyed the utilization of com-\n",
      "puter vision techniques to improve software engineering\n",
      "tasks [165]. Zhang et al. provided a survey of techniques\n",
      "for testing machine learning systems [150]\n",
      "With the advancements of artificial intelligence and\n",
      "LLMs, researchers also conduct systematic literature\n",
      "reviews about LLMs, and their applications in various\n",
      "fields (e.g., software engineering). Zhao et al. [17] reviewed\n",
      "recent advances in LLMs by providing an overview of their\n",
      "background, key findings, and mainstream techniques.\n",
      "They focused on four major aspects of LLMs, namely\n",
      "pre-training, adaptation tuning, utilization, and capacity\n",
      "evaluation. Additionally, they summarized the available\n",
      "resources for developing LLMs and discuss the remaining\n",
      "issues for future directions. Hou et al. conducted a\n",
      "systematic literature review on using LLMs for software\n",
      "engineering, with a particular focus on understanding\n",
      "how LLMs can be exploited to optimize processes and\n",
      "outcomes [166]. Fan et al. conducted a survey of LLMs for\n",
      "software engineering, and set out open research challenges\n",
      "for the application of LLMs to technical problems faced by\n",
      "software engineers [167]. Zan et al. conducted a survey of\n",
      "existing LLMs for NL2Code task (i.e., generating code from\n",
      "a natural language description), and reviewed benchmarks\n",
      "and metrics [168].\n",
      "While these studies either targeted the broader software\n",
      "engineering domain (with a limited focus on software test-\n",
      "ing tasks) or focused on other software development tasks\n",
      "(excluding software testing), this paper specifically focuses\n",
      "on the use of LLMs for software testing. It surveys related\n",
      "studies, summarizes key challenges and potential opportu-\n",
      "nities, and serves as a roadmap for future research in this\n",
      "area.\n",
      "8 C ONCLUSION\n",
      "This paper provides a comprehensive review of the use\n",
      "of LLMs in software testing. We have analyzed relevant\n",
      "studies that have utilized LLMs in software testing from\n",
      "both the software testing and LLMs perspectives. This paper\n",
      "also highlights the challenges and potential opportunities\n",
      "in this direction. Results of this review demonstrate that\n",
      "LLMs have been successfully applied in a wide range\n",
      "of testing tasks, including unit test case generation, test\n",
      "oracle generation, system test input generation, program\n",
      "debugging, and program repair. However, challenges still\n",
      "exist in achieving high testing coverage, addressing the\n",
      "test oracle problem, conducting rigorous evaluations, and\n",
      "applying LLMs in real-world scenarios. Additionally, it is\n",
      "observed that LLMs are commonly used in only a subset of\n",
      "the entire testing lifecycle, for example, they are primarily\n",
      "utilized in the middle and later stages of testing, only\n",
      "serving the unit and system testing phases, and only for\n",
      "functional testing. This highlights the research opportunities\n",
      "for exploring the uncovered areas. Regarding how the LLMs\n",
      "are utilized, we find that various pre-training/fine-tuning\n",
      "and prompt engineering methods have been developed\n",
      "to enhance the capabilities of LLMs in addressing testing\n",
      "tasks. However, more advanced techniques in prompt\n",
      "design have yet to be explored and can be an avenue for\n",
      "future research.\n",
      "It can serve as a roadmap for future research in this area,\n",
      "identifying gaps in our current understanding of the use of\n",
      "LLMs in software testing and highlighting potential avenues\n",
      "for exploration. We believe that the insights provided in this\n",
      "paper will be valuable to both researchers and practition-\n",
      "ers in the field of software engineering, assisting them in\n",
      "leveraging LLMs to improve software testing practices and\n",
      "ultimately enhance the quality and reliability of software\n",
      "systems.\n",
      "REFERENCES\n",
      "[1] G. J. Myers, The art of software testing (2. ed.) . Wiley,\n",
      "2004. [Online]. Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[2] M. Pezz `e and M. Young, Software testing and analysis - process,\n",
      "principles and techniques. Wiley, 2007.\n",
      "[3] M. Harman and P . McMinn, “A theoretical and empirical study\n",
      "of search-based testing: Local, global, and hybrid search,” vol. 36,\n",
      "no. 2, 2010, pp. 226–247.\n",
      "[4] P . Delgado-P ´erez, A. Ram ´ırez, K. J. Valle-G ´omez, I. Medina-\n",
      "Bulo, and J. R. Romero, “Interevo-tr: Interactive evolutionary\n",
      "test generation with readability assessment,” IEEE Trans. Software\n",
      "Eng., vol. 49, no. 4, pp. 2580–2596, 2023.\n",
      "[5] X. Xiao, S. Li, T. Xie, and N. Tillmann, “Characteristic studies\n",
      "of loop problems for structural test generation via symbolic\n",
      "execution,” in 2013 28th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2013, Silicon Valley, CA, USA,\n",
      "November 11-15, 2013 , E. Denney, T. Bultan, and A. Zeller, Eds.\n",
      "IEEE, 2013, pp. 246–256.\n",
      "[6] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball, “Feedback-\n",
      "directed random test generation,” in 29th International Conference\n",
      "on Software Engineering (ICSE 2007), Minneapolis, MN, USA, May\n",
      "20-26, 2007. IEEE Computer Society, 2007, pp. 75–84.22\n",
      "[7] Z. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, and X. Peng,\n",
      "“No more manual tests? evaluating and improving chatgpt for\n",
      "unit test generation,” arXiv preprint arXiv:2305.04207, 2023.\n",
      "[8] Y. Tang, Z. Liu, Z. Zhou, and X. Luo, “Chatgpt vs SBST:\n",
      "A comparative assessment of unit test suite generation,”\n",
      "CoRR, vol. abs/2307.00588, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2307.00588\n",
      "[9] A. Developers, “Ui/application exerciser monkey,” 2012.\n",
      "[10] Y. Li, Z. Yang, Y. Guo, and X. Chen, “Droidbot: a lightweight ui-\n",
      "guided test input generator for android,” in ICSE. IEEE, 2017.\n",
      "[11] T. Su, G. Meng, Y. Chen, K. Wu, W. Yang, Y. Yao, G. Pu, Y. Liu, and\n",
      "Z. Su, “Guided, stochastic model-based gui testing of android\n",
      "apps,” in Proceedings of the 2017 11th Joint Meeting on Foundations\n",
      "of Software Engineering, 2017, pp. 245–256.\n",
      "[12] Z. Dong, M. B ¨ohme, L. Cojocaru, and A. Roychoudhury, “Time-\n",
      "travel testing of android apps,” in ICSE. IEEE, 2020.\n",
      "[13] M. Pan, A. Huang, G. Wang, T. Zhang, and X. Li, “Reinforcement\n",
      "learning based curiosity-driven testing of android applications,”\n",
      "in Proceedings of the 29th ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2020, pp. 153–164.\n",
      "[14] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che, D. Wang,\n",
      "and Q. Wang, “Make LLM a testing expert: Bringing human-\n",
      "like interaction to mobile GUI testing via functionality-aware\n",
      "decisions,” CoRR, vol. abs/2310.15780, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15780\n",
      "[15] T. Su, J. Wang, and Z. Su, “Benchmarking automated GUI testing\n",
      "for android against real-world bugs,” in ESEC/FSE ’21: 29th ACM\n",
      "Joint European Software Engineering Conference and Symposium on\n",
      "the Foundations of Software Engineering, Athens, Greece, August 23-\n",
      "28, 2021. ACM, 2021, pp. 119–130.\n",
      "[16] M. Shanahan, “Talking about large language models,”\n",
      "CoRR, vol. abs/2212.03551, 2022. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2212.03551\n",
      "[17] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou,\n",
      "Y. Min, B. Zhang, J. Zhang, Z. Dong, Y. Du, C. Yang,\n",
      "Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu,\n",
      "P . Liu, J. Nie, and J. Wen, “A survey of large language\n",
      "models,” CoRR, vol. abs/2303.18223, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2303.18223\n",
      "[18] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and\n",
      "Y. Iwasawa, “Large language models are zero-\n",
      "shot reasoners,” in NeurIPS, 2022. [Online]. Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html\n",
      "[19] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter,\n",
      "F. Xia, E. H. Chi, Q. V . Le, and D. Zhou,\n",
      "“Chain-of-thought prompting elicits reasoning in large\n",
      "language models,” in NeurIPS, 2022. [Online]. Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html\n",
      "[20] J. Li, G. Li, Y. Li, and Z. Jin, “Structured chain-of-thought\n",
      "prompting for code generation,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:258615421\n",
      "[21] J. Li, Y. Li, G. Li, Z. Jin, Y. Hao, and X. Hu, “Skcoder: A\n",
      "sketch-based approach for automatic code generation,” in 2023\n",
      "IEEE/ACM 45th International Conference on Software Engineering\n",
      "(ICSE), 2023, pp. 2124–2135.\n",
      "[22] J. Li, Y. Zhao, Y. Li, G. Li, and Z. Jin, “Acecoder: Utilizing existing\n",
      "code to enhance code generation,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:257901190\n",
      "[23] Y. Dong, X. Jiang, Z. Jin, and G. Li, “Self-collaboration\n",
      "code generation via chatgpt,” CoRR, vol. abs/2304.07590, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2304.07590\n",
      "[24] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu,\n",
      "“Unifying large language models and knowledge graphs: A\n",
      "roadmap,” CoRR, vol. abs/2306.08302, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2306.08302\n",
      "[25] G. J. Myers, T. Badgett, T. M. Thomas, and C. Sandler, The art of\n",
      "software testing. Wiley Online Library, 2004, vol. 2.\n",
      "[26] M. Tufano, D. Drain, A. Svyatkovskiy, S. K. Deng, and N. Sun-\n",
      "daresan, “Unit test case generation with transformers and focal\n",
      "context,” arXiv preprint arXiv:2009.05617, 2020.\n",
      "[27] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou, and\n",
      "W. Chen, “Codet: Code generation with generated tests,” arXiv\n",
      "preprint arXiv:2207.10397, 2022.\n",
      "[28] S. K. Lahiri, A. Naik, G. Sakkas, P . Choudhury, C. von Veh,\n",
      "M. Musuvathi, J. P . Inala, C. Wang, and J. Gao, “Interactive\n",
      "code generation via test-driven user-intent formalization,” arXiv\n",
      "preprint arXiv:2208.05950, 2022.\n",
      "[29] S. Alagarsamy, C. Tantithamthavorn, and A. Aleti, “A3test:\n",
      "Assertion-augmented automated test case generation,” arXiv\n",
      "preprint arXiv:2302.10352, 2023.\n",
      "[30] M. Sch ¨afer, S. Nadi, A. Eghbali, and F. Tip, “An empirical eval-\n",
      "uation of using large language models for automated unit test\n",
      "generation,” IEEE Transactions on Software Engineering , pp. 1–21,\n",
      "2023.\n",
      "[31] V . Guilherme and A. Vincenzi, “An initial investigation\n",
      "of chatgpt unit test generation capability,” in 8th Brazilian\n",
      "Symposium on Systematic and Automated Software Testing, SAST\n",
      "2023, Campo Grande, MS, Brazil, September 25-29, 2023 , A. L.\n",
      "Font˜ao, D. M. B. Paiva, H. Borges, M. I. Cagnin, P . G.\n",
      "Fernandes, V . Borges, S. M. Melo, V . H. S. Durelli, and E. D.\n",
      "Canedo, Eds. ACM, 2023, pp. 15–24. [Online]. Available:\n",
      "https://doi.org/10.1145/3624032.3624035\n",
      "[32] S. Hashtroudi, J. Shin, H. Hemmati, and S. Wang,\n",
      "“Automated test case generation using code models and\n",
      "domain adaptation,” CoRR, vol. abs/2308.08033, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2308.08033\n",
      "[33] L. Plein, W. C. Ou ´edraogo, J. Klein, and T. F. Bissyand ´e,\n",
      "“Automatic generation of test cases based on bug reports:\n",
      "a feasibility study with large language models,” CoRR, vol.\n",
      "abs/2310.06320, 2023. [Online]. Available: https://doi.org/10.\n",
      "48550/arXiv.2310.06320\n",
      "[34] V . Vikram, C. Lemieux, and R. Padhye, “Can large\n",
      "language models write good property-based tests?” CoRR,\n",
      "vol. abs/2307.04346, 2023. [Online]. Available: https://doi.org/\n",
      "10.48550/arXiv.2307.04346\n",
      "[35] N. Rao, K. Jain, U. Alon, C. L. Goues, and V . J. Hellendoorn,\n",
      "“CAT-LM training language models on aligned code and\n",
      "tests,” in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 . IEEE, 2023, pp. 409–420. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00193\n",
      "[36] Z. Xie, Y. Chen, C. Zhi, S. Deng, and J. Yin, “Chatunitest: a\n",
      "chatgpt-based automated unit test generation tool,”arXiv preprint\n",
      "arXiv:2305.04764, 2023.\n",
      "[37] C. Lemieux, J. P . Inala, S. K. Lahiri, and S. Sen, “Codamosa:\n",
      "Escaping coverage plateaus in test generation with pre-trained\n",
      "large language models,” in International conference on software\n",
      "engineering (ICSE), 2023.\n",
      "[38] A. M. Dakhel, A. Nikanjam, V . Majdinasab, F. Khomh,\n",
      "and M. C. Desmarais, “Effective test generation using\n",
      "pre-trained large language models and mutation testing,”\n",
      "CoRR, vol. abs/2308.16557, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.16557\n",
      "[39] M. L. Siddiq, J. Santos, R. H. Tanvir, N. Ulfat, F. A. Rifat, and V . C.\n",
      "Lopes, “Exploring the effectiveness of large language models in\n",
      "generating unit tests,” arXiv preprint arXiv:2305.00418, 2023.\n",
      "[40] Y. Zhang, W. Song, Z. Ji, D. Yao, and N. Meng, “How well does\n",
      "LLM generate security tests?” CoRR, vol. abs/2310.00710, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2310.00710\n",
      "[41] V . Li and N. Doiron, “Prompting code interpreter to write better\n",
      "unit tests on quixbugs functions,” CoRR, vol. abs/2310.00483,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2310.\n",
      "00483\n",
      "[42] B. Steenhoek, M. Tufano, N. Sundaresan, and A. Svyatkovskiy,\n",
      "“Reinforcement learning from automatic feedback for high-\n",
      "quality unit test generation,” 2023.\n",
      "[43] S. Bhatia, T. Gandhi, D. Kumar, and P . Jalote, “Unit test generation\n",
      "using generative ai : A comparative performance analysis of\n",
      "autogeneration tools,” 2023.\n",
      "[44] M. Tufano, D. Drain, A. Svyatkovskiy, and N. Sundaresan,\n",
      "“Generating accurate assert statements for unit test cases using\n",
      "pretrained transformers,” in Proceedings of the 3rd ACM/IEEE\n",
      "International Conference on Automation of Software Test , 2022, pp.\n",
      "54–64.\n",
      "[45] P . Nie, R. Banerjee, J. J. Li, R. J. Mooney, and M. Gligoric,\n",
      "“Learning deep semantics for test completion,” arXiv preprint\n",
      "arXiv:2302.10166, 2023.\n",
      "[46] A. Mastropaolo, N. Cooper, D. Nader-Palacio, S. Scalabrino,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Using transfer\n",
      "learning for code-related tasks,” IEEE Trans. Software Eng. ,\n",
      "vol. 49, no. 4, pp. 1580–1598, 2023. [Online]. Available:\n",
      "https://doi.org/10.1109/TSE.2022.318329723\n",
      "[47] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\n",
      "selection for code-related few-shot learning,” in Proceedings of\n",
      "the 45th International Conference on Software Engineering (ICSE’23) ,\n",
      "2023.\n",
      "[48] G. Ye, Z. Tang, S. H. Tan, S. Huang, D. Fang, X. Sun, L. Bian,\n",
      "H. Wang, and Z. Wang, “Automated conformance testing for\n",
      "javascript engines via deep compiler fuzzing,” in Proceedings of\n",
      "the 42nd ACM SIGPLAN international conference on programming\n",
      "language design and implementation, 2021, pp. 435–450.\n",
      "[49] Z. Liu, C. Chen, J. Wang, X. Che, Y. Huang, J. Hu, and Q. Wang,\n",
      "“Fill in the blank: Context-aware automated text input generation\n",
      "for mobile gui testing,” arXiv preprint arXiv:2212.04732, 2022.\n",
      "[50] M. R. Taesiri, F. Macklon, Y. Wang, H. Shen, and C.-P . Bezemer,\n",
      "“Large language models are pretty good zero-shot video game\n",
      "bug detectors,” arXiv preprint arXiv:2210.02506, 2022.\n",
      "[51] S. L. Shrestha and C. Csallner, “Slgpt: using transfer learning\n",
      "to directly generate simulink model files and find bugs in the\n",
      "simulink toolchain,” in Evaluation and Assessment in Software\n",
      "Engineering, 2021, pp. 260–265.\n",
      "[52] J. Hu, Q. Zhang, and H. Yin, “Augmenting greybox fuzzing\n",
      "with generative AI,” CoRR, vol. abs/2306.06782, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2306.06782\n",
      "[53] A. Mathur, S. Pradhan, P . Soni, D. Patel, and R. Regunathan,\n",
      "“Automated test case generation using t5 and gpt-3,” in 2023 9th\n",
      "International Conference on Advanced Computing and Communication\n",
      "Systems (ICACCS), vol. 1, 2023, pp. 1986–1992.\n",
      "[54] D. Zimmermann and A. Koziolek, “Automating gui-based soft-\n",
      "ware testing with gpt-3,” in 2023 IEEE International Conference\n",
      "on Software Testing, Verification and Validation Workshops (ICSTW),\n",
      "2023, pp. 62–65.\n",
      "[55] M. Taeb, A. Swearngin, E. Schoop, R. Cheng, Y. Jiang, and\n",
      "J. Nichols, “Axnav: Replaying accessibility tests from natural\n",
      "language,” CoRR, vol. abs/2310.02424, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.02424\n",
      "[56] Q. Luu, H. Liu, and T. Y. Chen, “Can chatgpt advance software\n",
      "testing intelligence? an experience report on metamorphic\n",
      "testing,” CoRR, vol. abs/2310.19204, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.19204\n",
      "[57] A. Khanfir, R. Degiovanni, M. Papadakis, and Y. L. Traon, “Ef-\n",
      "ficient mutation testing via pre-trained language models,” arXiv\n",
      "preprint arXiv:2301.03543, 2023.\n",
      "[58] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang,\n",
      "“Large language models are edge-case fuzzers: Testing deep\n",
      "learning libraries via fuzzgpt,” arXiv preprint arXiv:2304.02014 ,\n",
      "2023.\n",
      "[59] ——, “Large language models are zero shot fuzzers: Fuzzing\n",
      "deep learning libraries via large language models,” arXiv preprint\n",
      "arXiv:2209.11515, 2023.\n",
      "[60] J. Ackerman and G. Cybenko, “Large language models for\n",
      "fuzzing parsers (registered report),” in Proceedings of the\n",
      "2nd International Fuzzing Workshop, FUZZING 2023, Seattle,\n",
      "WA, USA, 17 July 2023 , M. B ¨ohme, Y. Noller, B. Ray, and\n",
      "L. Szekeres, Eds. ACM, 2023, pp. 31–38. [Online]. Available:\n",
      "https://doi.org/10.1145/3605157.3605173\n",
      "[61] S. Yu, C. Fang, Y. Ling, C. Wu, and Z. Chen, “LLM for\n",
      "test script generation and migration: Challenges, capabilities,\n",
      "and opportunities,” CoRR, vol. abs/2309.13574, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2309.13574\n",
      "[62] G. Deng, Y. Liu, V . M. Vilches, P . Liu, Y. Li, Y. Xu,\n",
      "T. Zhang, Y. Liu, M. Pinzger, and S. Rass, “Pentestgpt:\n",
      "An llm-empowered automatic penetration testing tool,”\n",
      "CoRR, vol. abs/2308.06782, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.06782\n",
      "[63] M. Sun, Y. Yang, Y. Wang, M. Wen, H. Jia, and Y. Zhou,\n",
      "“SMT solver validation empowered by large pre-trained\n",
      "language models,” in 38th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2023, Luxembourg, September\n",
      "11-15, 2023 . IEEE, 2023, pp. 1288–1300. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00180\n",
      "[64] Y. Deng, J. Yao, Z. Tu, X. Zheng, M. Zhang, and T. Zhang,\n",
      "“Target: Automated scenario generation from traffic rules\n",
      "for testing autonomous vehicles,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:258588387\n",
      "[65] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che,\n",
      "D. Wang, and Q. Wang, “Testing the limits: Unusual text inputs\n",
      "generation for mobile app crash detection with large language\n",
      "model,” CoRR, vol. abs/2310.15657, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15657\n",
      "[66] C. Zhang, M. Bai, Y. Zheng, Y. Li, X. Xie, Y. Li, W. Ma, L. Sun,\n",
      "and Y. Liu, “Understanding large language model based fuzz\n",
      "driver generation,” CoRR, vol. abs/2307.12469, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2307.12469\n",
      "[67] C. Xia, M. Paltenghi, J. Tian, M. Pradel, and L. Zhang,\n",
      "“Universal fuzzing via large language models,” ArXiv,\n",
      "vol. abs/2308.04748, 2023. [Online]. Available: https://api.\n",
      "semanticscholar.org/CorpusID:260735598\n",
      "[68] C. Tsigkanos, P . Rani, S. M ¨uller, and T. Kehrer, “Variable\n",
      "discovery with large language models for metamorphic testing\n",
      "of scientific software,” in Computational Science - ICCS 2023 -\n",
      "23rd International Conference, Prague, Czech Republic, July 3-5,\n",
      "2023, Proceedings, Part I , ser. Lecture Notes in Computer\n",
      "Science, J. Mikyska, C. de Mulatier, M. Paszynski, V . V .\n",
      "Krzhizhanovskaya, J. J. Dongarra, and P . M. A. Sloot, Eds.,\n",
      "vol. 14073. Springer, 2023, pp. 321–335. [Online]. Available:\n",
      "https://doi.org/10.1007/978-3-031-35995-8 23\n",
      "[69] C. Yang, Y. Deng, R. Lu, J. Yao, J. Liu, R. Jabbarvand, and\n",
      "L. Zhang, “White-box compiler fuzzing empowered by large\n",
      "language models,” CoRR, vol. abs/2310.15991, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2310.15991\n",
      "[70] T. Zhang, I. C. Irsan, F. Thung, D. Han, D. Lo, and L. Jiang,\n",
      "“itiger: an automatic issue title generation tool,” in Proceedings\n",
      "of the 30th ACM Joint European Software Engineering Conference and\n",
      "Symposium on the Foundations of Software Engineering , 2022, pp.\n",
      "1637–1641.\n",
      "[71] Y. Huang, J. Wang, Z. Liu, Y. Wang, S. Wang, C. Chen,\n",
      "Y. Hu, and Q. Wang, “Crashtranslator: Automatically\n",
      "reproducing mobile application crashes directly from stack\n",
      "trace,” CoRR, vol. abs/2310.07128, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.07128\n",
      "[72] T. Zhang, I. C. Irsan, F. Thung, and D. Lo, “Cupid:\n",
      "Leveraging chatgpt for more accurate duplicate bug report\n",
      "detection,” CoRR, vol. abs/2308.10022, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10022\n",
      "[73] U. Mukherjee and M. M. Rahman, “Employing deep\n",
      "learning and structured information retrieval to answer\n",
      "clarification questions on bug reports,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:259501524\n",
      "[74] P . Mahbub, O. Shuvo, and M. M. Rahman, “Explaining software\n",
      "bugs leveraging code structures in neural machine translation,”\n",
      "arXiv preprint arXiv:2212.04584, 2022.\n",
      "[75] S. Feng and C. Chen, “Prompting is all your need:\n",
      "Automated android bug replay with large language models,”\n",
      "CoRR, vol. abs/2306.01987, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.01987\n",
      "[76] Y. Su, Z. Han, Z. Gao, Z. Xing, Q. Lu, and X. Xu, “Still\n",
      "confusing for bug-component triaging? deep feature learning\n",
      "and ensemble setting to rescue,” in 31st IEEE/ACM International\n",
      "Conference on Program Comprehension, ICPC 2023, Melbourne,\n",
      "Australia, May 15-16, 2023 . IEEE, 2023, pp. 316–327. [Online].\n",
      "Available: https://doi.org/10.1109/ICPC58990.2023.00046\n",
      "[77] N. D. Bui, Y. Wang, and S. Hoi, “Detect-localize-repair: A unified\n",
      "framework for learning to debug with codet5,” arXiv preprint\n",
      "arXiv:2211.14875, 2022.\n",
      "[78] S. Kang, J. Yoon, and S. Yoo, “Large language models are few-shot\n",
      "testers: Exploring llm-based general bug reproduction,” arXiv\n",
      "preprint arXiv:2209.11515, 2022.\n",
      "[79] S. Kang, G. An, and S. Yoo, “A preliminary evaluation of\n",
      "llm-based fault localization,” CoRR, vol. abs/2308.05487, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.05487\n",
      "[80] P . Widjojo and C. Treude, “Addressing compiler errors: Stack\n",
      "overflow or large language models?” CoRR, vol. abs/2307.10793,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2307.\n",
      "10793\n",
      "[81] L. Plein and T. F. Bissyand ´e, “Can llms demystify bug\n",
      "reports?” CoRR, vol. abs/2310.06310, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.06310\n",
      "[82] A. Taylor, A. Vassar, J. Renzella, and H. A. Pearce, “Dcc\n",
      "–help: Generating context-aware compiler error explanations\n",
      "with large language models,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:261076439\n",
      "[83] S. Kang, B. Chen, S. Yoo, and J.-G. Lou, “Explainable automated\n",
      "debugging via large language model-driven scientific debug-\n",
      "ging,” arXiv preprint arXiv:2304.02195, 2023.24\n",
      "[84] A. Z. H. Yang, R. Martins, C. L. Goues, and V . J.\n",
      "Hellendoorn, “Large language models for test-free fault\n",
      "localization,” CoRR, vol. abs/2310.01726, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2310.01726\n",
      "[85] Y. Wu, Z. Li, J. M. Zhang, M. Papadakis, M. Harman,\n",
      "and Y. Liu, “Large language models in fault localisation,”\n",
      "CoRR, vol. abs/2308.15276, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.15276\n",
      "[86] H. Tu, Z. Zhou, H. Jiang, I. N. B. Yusuf, Y. Li, and L. Jiang,\n",
      "“LLM4CBI: taming llms to generate effective test programs\n",
      "for compiler bug isolation,” CoRR, vol. abs/2307.00593, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2307.00593\n",
      "[87] T.-O. Li, W. Zong, Y. Wang, H. Tian, Y. Wang, S.-C. Cheung,\n",
      "and J. Kramer, “Nuances are the key: Unlocking chatgpt to\n",
      "find failure-inducing tests with differential prompting,” in 2023\n",
      "38th IEEE/ACM International Conference on Automated Software\n",
      "Engineering (ASE), 2023, pp. 14–26.\n",
      "[88] X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou, “Teaching large\n",
      "language models to self-debug,”CoRR, vol. abs/2304.05128, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2304.05128\n",
      "[89] J. Cao, M. Li, M. Wen, and S.-c. Cheung, “A study on prompt\n",
      "design, advantages and limitations of chatgpt for deep learning\n",
      "program repair,” arXiv preprint arXiv:2304.08191, 2023.\n",
      "[90] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt,\n",
      "“Examining zero-shot vulnerability repair with large language\n",
      "models,” in 2023 IEEE Symposium on Security and Privacy (SP) .\n",
      "IEEE Computer Society, 2022, pp. 1–18.\n",
      "[91] Z. Fan, X. Gao, A. Roychoudhury, and S. H. Tan, “Automated\n",
      "repair of programs from large language models,” arXiv preprint\n",
      "arXiv:2205.10583, 2022.\n",
      "[92] Y. Hu, X. Shi, Q. Zhou, and L. Pike, “Fix bugs with trans-\n",
      "former through a neural-symbolic edit grammar,” arXiv preprint\n",
      "arXiv:2204.06643, 2022.\n",
      "[93] C. S. Xia, Y. Wei, and L. Zhang, “Practical program repair in\n",
      "the era of large pre-trained language models,” arXiv preprint\n",
      "arXiv:2210.14179, 2022.\n",
      "[94] J. Zhang, J. Cambronero, S. Gulwani, V . Le, R. Piskac, G. Soares,\n",
      "and G. Verbruggen, “Repairing bugs in python assignments\n",
      "using large language models,” arXiv preprint arXiv:2209.14876 ,\n",
      "2022.\n",
      "[95] M. Lajk ´o, V . Csuvik, and L. Vid´acs, “Towards javascript program\n",
      "repair with generative pre-trained transformer (gpt-2),” in Pro-\n",
      "ceedings of the Third International Workshop on Automated Program\n",
      "Repair, 2022, pp. 61–68.\n",
      "[96] D. Sobania, M. Briesch, C. Hanna, and J. Petke, “An analysis of\n",
      "the automatic bug fixing performance of chatgpt,” arXiv preprint\n",
      "arXiv:2301.08653, 2023.\n",
      "[97] K. Huang, X. Meng, J. Zhang, Y. Liu, W. Wang, S. Li,\n",
      "and Y. Zhang, “An empirical study on fine-tuning large\n",
      "language models of code for automated program repair,”\n",
      "in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 . IEEE, 2023, pp. 1162–1174. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00181\n",
      "[98] M. C. Wuisang, M. Kurniawan, K. A. Wira Santosa, A. Agung\n",
      "Santoso Gunawan, and K. E. Saputra, “An evaluation of the\n",
      "effectiveness of openai’s chatgpt for automated python program\n",
      "bug fixing using quixbugs,” in2023 International Seminar on Appli-\n",
      "cation for Technology of Information and Communication (iSemantic) ,\n",
      "2023, pp. 295–300.\n",
      "[99] D. Horv ´ath, V . Csuvik, T. Gyim ´othy, and L. Vid ´acs,\n",
      "“An extensive study on model architecture and program\n",
      "representation in the domain of learning-based automated\n",
      "program repair,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 . IEEE, 2023, pp. 31–38. [Online]. Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00013\n",
      "[100] J. A. Prenner, H. Babii, and R. Robbes, “Can openai’s codex fix\n",
      "bugs? an evaluation on quixbugs,” in Proceedings of the Third\n",
      "International Workshop on Automated Program Repair, 2022, pp. 69–\n",
      "75.\n",
      "[101] W. Yuan, Q. Zhang, T. He, C. Fang, N. Q. V . Hung, X. Hao, and\n",
      "H. Yin, “Circle: continual repair across programming languages,”\n",
      "in Proceedings of the 31st ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2022, pp. 678–690.\n",
      "[102] S. Moon, Y. Song, H. Chae, D. Kang, T. Kwon, K. T. iunn Ong,\n",
      "S. won Hwang, and J. Yeo, “Coffee: Boost your code llms by\n",
      "fixing bugs with feedback,” 2023.\n",
      "[103] Y. Wei, C. S. Xia, and L. Zhang, “Copiloting the copilots:\n",
      "Fusing large language models with completion engines for\n",
      "automated program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P . Tonella, Eds. ACM, 2023, pp. 172–184. [Online]. Available:\n",
      "https://doi.org/10.1145/3611643.3616271\n",
      "[104] Y. Peng, S. Gao, C. Gao, Y. Huo, and M. R. Lyu, “Domain\n",
      "knowledge matters: Improving prompts with fix templates for\n",
      "repairing python type errors,” CoRR, vol. abs/2306.01394, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2306.01394\n",
      "[105] A. E. I. Brownlee, J. Callan, K. Even-Mendoza, A. Geiger,\n",
      "C. Hanna, J. Petke, F. Sarro, and D. Sobania, “Enhancing\n",
      "genetic improvement mutations using large language models,”\n",
      "in Search-Based Software Engineering - 15th International\n",
      "Symposium, SSBSE 2023, San Francisco, CA, USA, December\n",
      "8, 2023, Proceedings , ser. Lecture Notes in Computer\n",
      "Science, P . Arcaini, T. Yue, and E. M. Fredericks, Eds.,\n",
      "vol. 14415. Springer, 2023, pp. 153–159. [Online]. Available:\n",
      "https://doi.org/10.1007/978-3-031-48796-5 13\n",
      "[106] M. M. A. Haque, W. U. Ahmad, I. Lourentzou, and C. Brown,\n",
      "“Fixeval: Execution-based evaluation of program fixes for\n",
      "programming problems,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 . IEEE, 2023, pp. 11–18. [Online]. Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00009\n",
      "[107] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “Fixing\n",
      "hardware security bugs with large language models,” arXiv\n",
      "preprint arXiv:2302.01215, 2023.\n",
      "[108] P . Deligiannis, A. Lal, N. Mehrotra, and A. Rastogi, “Fixing rust\n",
      "compilation errors using llms,” CoRR, vol. abs/2308.05177, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.05177\n",
      "[109] F. Ribeiro, R. Abreu, and J. Saraiva, “Framing program repair\n",
      "as code completion,” in Proceedings of the Third International\n",
      "Workshop on Automated Program Repair, 2022, pp. 38–45.\n",
      "[110] N. Wadhwa, J. Pradhan, A. Sonwane, S. P . Sahu, N. Natarajan,\n",
      "A. Kanade, S. Parthasarathy, and S. K. Rajamani, “Frustrated with\n",
      "code quality issues? llms can help!” CoRR, vol. abs/2309.12938,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2309.\n",
      "12938\n",
      "[111] F. Ribeiro, J. N. C. de Macedo, K. Tsushima, R. Abreu,\n",
      "and J. Saraiva, “Gpt-3-powered type error debugging:\n",
      "Investigating the use of large language models for code\n",
      "repair,” in Proceedings of the 16th ACM SIGPLAN International\n",
      "Conference on Software Language Engineering, SLE 2023, Cascais,\n",
      "Portugal, October 23-24, 2023 , J. Saraiva, T. Degueule, and\n",
      "E. Scott, Eds. ACM, 2023, pp. 111–124. [Online]. Available:\n",
      "https://doi.org/10.1145/3623476.3623522\n",
      "[112] Y. Wu, N. Jiang, H. V . Pham, T. Lutellier, J. Davis, L. Tan,\n",
      "P . Babkin, and S. Shah, “How effective are neural networks for\n",
      "fixing security vulnerabilities,” arXiv preprint arXiv:2305.18607 ,\n",
      "2023.\n",
      "[113] N. Jiang, K. Liu, T. Lutellier, and L. Tan, “Impact of code\n",
      "language models on automated program repair,” arXiv preprint\n",
      "arXiv:2302.05020, 2023.\n",
      "[114] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan,\n",
      "and A. Svyatkovskiy, “Inferfix: End-to-end program repair with\n",
      "llms,” arXiv preprint arXiv:2303.07263, 2023.\n",
      "[115] C. S. Xia and L. Zhang, “Keep the conversation going: Fixing\n",
      "162 out of 337 bugs for $0.42 each using chatgpt,” arXiv preprint\n",
      "arXiv:2304.00385, 2023.\n",
      "[116] Y. Zhang, G. Li, Z. Jin, and Y. Xing, “Neural program repair with\n",
      "program dependence analysis and effective filter mechanism,”\n",
      "arXiv preprint arXiv:2305.09315, 2023.\n",
      "[117] J. A. Prenner and R. Robbes, “Out of context: How important is\n",
      "local context in neural program repair?” 2023.\n",
      "[118] Q. Zhang, C. Fang, B. Yu, W. Sun, T. Zhang, and Z. Chen,\n",
      "“Pre-trained model-based automated software vulnerability\n",
      "repair: How far are we?” CoRR, vol. abs/2308.12533, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.12533\n",
      "[119] S. Garg, R. Z. Moghaddam, and N. Sundaresan, “Rapgen:\n",
      "An approach for fixing code inefficiencies in zero-shot,”25\n",
      "CoRR, vol. abs/2306.17077, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.17077\n",
      "[120] W. Wang, Y. Wang, S. Joty, and S. C. H. Hoi, “Rap-\n",
      "gen: Retrieval-augmented patch generation with codet5 for\n",
      "automatic program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P . Tonella, Eds. ACM, 2023, pp. 146–158. [Online]. Available:\n",
      "https://doi.org/10.1145/3611643.3616256\n",
      "[121] Y. Zhang, Z. Jin, Y. Xing, and G. Li, “STEAM: simulating\n",
      "the interactive behavior of programmers for automatic bug\n",
      "fixing,” CoRR, vol. abs/2308.14460, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.14460\n",
      "[122] S. Fakhoury, S. Chakraborty, M. Musuvathi, and S. K. Lahiri,\n",
      "“Towards generating functionally correct code edits from natu-\n",
      "ral language issue descriptions,” arXiv preprint arXiv:2304.03816,\n",
      "2023.\n",
      "[123] M. Fu, C. Tantithamthavorn, T. Le, V . Nguyen, and D. Phung,\n",
      "“Vulrepair: a t5-based automated software vulnerability repair,”\n",
      "in Proceedings of the 30th ACM Joint European Software Engineering\n",
      "Conference and Symposium on the Foundations of Software Engineer-\n",
      "ing, 2022, pp. 935–947.\n",
      "[124] S. Gao, X. Wen, C. Gao, W. Wang, H. Zhang, and\n",
      "M. R. Lyu, “What makes good in-context demonstrations\n",
      "for code intelligence tasks with llms?” in 38th IEEE/ACM\n",
      "International Conference on Automated Software Engineering, ASE\n",
      "2023, Luxembourg, September 11-15, 2023 . IEEE, 2023, pp. 761–\n",
      "773. [Online]. Available: https://doi.org/10.1109/ASE56229.\n",
      "2023.00109\n",
      "[125] C. Treude and H. Hata, “She elicits requirements and he\n",
      "tests: Software engineering gender bias in large language\n",
      "models,” CoRR, vol. abs/2303.10131, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2303.10131\n",
      "[126] R. Kocielnik, S. Prabhumoye, V . Zhang, R. M. Alvarez, and\n",
      "A. Anandkumar, “Autobiastest: Controllable sentence generation\n",
      "for automated and open-ended social bias testing in language\n",
      "models,” CoRR, vol. abs/2302.07371, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2302.07371\n",
      "[127] M. Ciniselli, L. Pascarella, and G. Bavota, “To what extent do\n",
      "deep learning-based code recommenders generate predictions\n",
      "by cloning code from the training set?” in 19th IEEE/ACM\n",
      "International Conference on Mining Software Repositories, MSR 2022,\n",
      "Pittsburgh, P A, USA, May 23-24, 2022. ACM, 2022, pp. 167–178.\n",
      "[Online]. Available: https://doi.org/10.1145/3524842.3528440\n",
      "[128] D. Erhabor, S. Udayashankar, M. Nagappan, and S. Al-Kiswany,\n",
      "“Measuring the runtime performance of code produced with\n",
      "github copilot,” CoRR, vol. abs/2305.06439, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2305.06439\n",
      "[129] R. Wang, R. Cheng, D. Ford, and T. Zimmermann, “Investigating\n",
      "and designing for trust in ai-powered code generation\n",
      "tools,” CoRR, vol. abs/2305.11248, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2305.11248\n",
      "[130] B. Yetistiren, I. ¨Ozsoy, M. Ayerdem, and E. T ¨uz ¨un, “Evaluating\n",
      "the code quality of ai-assisted code generation tools: An\n",
      "empirical study on github copilot, amazon codewhisperer, and\n",
      "chatgpt,” CoRR, vol. abs/2304.10778, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2304.10778\n",
      "[131] C. Wohlin, “Guidelines for snowballing in systematic literature\n",
      "studies and a replication in software engineering,” in\n",
      "18th International Conference on Evaluation and Assessment\n",
      "in Software Engineering, EASE ’14, London, England, United\n",
      "Kingdom, May 13-14, 2014 , M. J. Shepperd, T. Hall, and\n",
      "I. Myrtveit, Eds. ACM, 2014, pp. 38:1–38:10. [Online]. Available:\n",
      "https://doi.org/10.1145/2601248.2601268\n",
      "[132] A. Mastropaolo, S. Scalabrino, N. Cooper, D. Nader-Palacio,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Studying the usage\n",
      "of text-to-text transfer transformer to support code-related tasks,”\n",
      "in 43rd IEEE/ACM International Conference on Software Engineering,\n",
      "ICSE 2021, Madrid, Spain, 22-30 May 2021 . IEEE, 2021, pp. 336–\n",
      "347.\n",
      "[133] C. Tsigkanos, P . Rani, S. M ¨uller, and T. Kehrer, “Large\n",
      "language models: The next frontier for variable discovery\n",
      "within metamorphic testing?” in IEEE International Conference\n",
      "on Software Analysis, Evolution and Reengineering, SANER 2023,\n",
      "Taipa, Macao, March 21-24, 2023 , T. Zhang, X. Xia, and\n",
      "N. Novielli, Eds. IEEE, 2023, pp. 678–682. [Online]. Available:\n",
      "https://doi.org/10.1109/SANER56733.2023.00070\n",
      "[134] G. J. Myers, The art of software testing (2. ed.) . Wiley,\n",
      "2004. [Online]. Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[135] P . Farrell-Vinay,Manage software testing. Auerbach Publ., 2008.\n",
      "[136] A. Mili and F. Tchier, Software testing: Concepts and operations .\n",
      "John Wiley & Sons, 2015.\n",
      "[137] S. Lukasczyk and G. Fraser, “Pynguin: Automated unit\n",
      "test generation for python,” in 44th IEEE/ACM International\n",
      "Conference on Software Engineering: Companion Proceedings,\n",
      "ICSE Companion 2022, Pittsburgh, P A, USA, May 22-24,\n",
      "2022. ACM/IEEE, 2022, pp. 168–172. [Online]. Available:\n",
      "https://doi.org/10.1145/3510454.3516829\n",
      "[138] E. T. Barr, M. Harman, P . McMinn, M. Shahbaz, and S. Yoo, “The\n",
      "oracle problem in software testing: A survey,” IEEE transactions\n",
      "on software engineering, vol. 41, no. 5, pp. 507–525, 2014.\n",
      "[139] C. Watson, M. Tufano, K. Moran, G. Bavota, and D. Poshyvanyk,\n",
      "“On learning meaningful assert statements for unit test cases,”\n",
      "in ICSE ’20: 42nd International Conference on Software Engineering,\n",
      "Seoul, South Korea, 27 June - 19 July, 2020, G. Rothermel and D. Bae,\n",
      "Eds. ACM, 2020, pp. 1398–1409.\n",
      "[140] Y. He, L. Zhang, Z. Yang, Y. Cao, K. Lian, S. Li, W. Yang, Z. Zhang,\n",
      "M. Yang, Y. Zhang, and H. Duan, “Textexerciser: Feedback-driven\n",
      "text input exercising for android applications,” in 2020 IEEE\n",
      "Symposium on Security and Privacy, SP 2020, San Francisco, CA,\n",
      "USA, May 18-21, 2020. IEEE, 2020, pp. 1071–1087.\n",
      "[141] A. Wei, Y. Deng, C. Yang, and L. Zhang, “Free lunch for test-\n",
      "ing: Fuzzing deep-learning libraries from open source,” in 44th\n",
      "IEEE/ACM 44th International Conference on Software Engineering,\n",
      "ICSE 2022, Pittsburgh, P A, USA, May 25-27, 2022 . ACM, 2022,\n",
      "pp. 995–1007.\n",
      "[142] D. Xie, Y. Li, M. Kim, H. V . Pham, L. Tan, X. Zhang, and M. W.\n",
      "Godfrey, “Docter: documentation-guided fuzzing for testing\n",
      "deep learning API functions,” in ISSTA ’22: 31st ACM SIGSOFT\n",
      "International Symposium on Software Testing and Analysis, Virtual\n",
      "Event, South Korea, July 18 - 22, 2022 , S. Ryu and Y. Smaragdakis,\n",
      "Eds. ACM, 2022, pp. 176–188.\n",
      "[143] Q. Guo, X. Xie, Y. Li, X. Zhang, Y. Liu, X. Li, and C. Shen,\n",
      "“Audee: Automated testing for deep learning frameworks,” in\n",
      "35th IEEE/ACM International Conference on Automated Software\n",
      "Engineering, ASE 2020, Melbourne, Australia, September 21-25, 2020.\n",
      "IEEE, 2020, pp. 486–498.\n",
      "[144] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning\n",
      "library testing via effective model generation,” in ESEC/FSE\n",
      "’20: 28th ACM Joint European Software Engineering Conference\n",
      "and Symposium on the Foundations of Software Engineering, Virtual\n",
      "Event, USA, November 8-13, 2020 , P . Devanbu, M. B. Cohen, and\n",
      "T. Zimmermann, Eds. ACM, 2020, pp. 788–799.\n",
      "[145] J. Jiang, Y. Xiong, H. Zhang, Q. Gao, and X. Chen, “Shaping\n",
      "program repair space with existing patches and similar code,” in\n",
      "Proceedings of the 27th ACM SIGSOFT International Symposium on\n",
      "Software Testing and Analysis , ser. ISSTA 2018. New York, NY,\n",
      "USA: Association for Computing Machinery, 2018, p. 298–309.\n",
      "[Online]. Available: https://doi.org/10.1145/3213846.3213871\n",
      "[146] M. Wen, J. Chen, R. Wu, D. Hao, and S.-C. Cheung, “Context-\n",
      "aware patch generation for better automated program repair,”\n",
      "in Proceedings of the 40th International Conference on Software\n",
      "Engineering, ser. ICSE ’18. New York, NY, USA: Association\n",
      "for Computing Machinery, 2018, p. 1–11. [Online]. Available:\n",
      "https://doi.org/10.1145/3180155.3180233\n",
      "[147] Y. Xiong, J. Wang, R. Yan, J. Zhang, S. Han, G. Huang, and\n",
      "L. Zhang, “Precise condition synthesis for program repair,” in\n",
      "2017 IEEE/ACM 39th International Conference on Software Engineer-\n",
      "ing (ICSE), 2017, pp. 416–426.\n",
      "[148] J. Xuan, M. Martinez, F. DeMarco, M. Cl ´ement, S. L. Marcote,\n",
      "T. Durieux, D. Le Berre, and M. Monperrus, “Nopol: Automatic\n",
      "repair of conditional statement bugs in java programs,” IEEE\n",
      "Transactions on Software Engineering, vol. 43, no. 1, pp. 34–55, 2017.\n",
      "[149] S. Song, X. Li, and S. Li, “How to bridge the gap between modal-\n",
      "ities: A comprehensive survey on multimodal large language\n",
      "model,” CoRR, vol. abs/2311.07594, 2023.\n",
      "[150] J. M. Zhang, M. Harman, L. Ma, and Y. Liu, “Machine learning\n",
      "testing: Survey, landscapes and horizons,” IEEE Trans. Software\n",
      "Eng., vol. 48, no. 2, pp. 1–36, 2022.\n",
      "[151] F. Tu, J. Zhu, Q. Zheng, and M. Zhou, “Be careful of when:\n",
      "an empirical study on time-related misuse of issue tracking26\n",
      "data,” in Proceedings of the 2018 ACM Joint Meeting on European\n",
      "Software Engineering Conference and Symposium on the Foundations\n",
      "of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena\n",
      "Vista, FL, USA, November 04-09, 2018 , G. T. Leavens, A. Garcia,\n",
      "and C. S. Pasareanu, Eds. ACM, 2018, pp. 307–318. [Online].\n",
      "Available: https://doi.org/10.1145/3236024.3236054\n",
      "[152] Z. Sun, L. Li, Y. Liu, X. Du, and L. Li, “On the importance\n",
      "of building high-quality training datasets for neural code\n",
      "search,” in 44th IEEE/ACM 44th International Conference on\n",
      "Software Engineering, ICSE 2022, Pittsburgh, P A, USA, May\n",
      "25-27, 2022 . ACM, 2022, pp. 1609–1620. [Online]. Available:\n",
      "https://doi.org/10.1145/3510003.3510160\n",
      "[153] L. Shi, Z. Jiang, Y. Yang, X. Chen, Y. Zhang, F. Mu, H. Jiang, and\n",
      "Q. Wang, “ISPY: automatic issue-solution pair extraction from\n",
      "community live chats,” in 36th IEEE/ACM International Conference\n",
      "on Automated Software Engineering, ASE 2021, Melbourne, Australia,\n",
      "November 15-19, 2021 . IEEE, 2021, pp. 142–154. [Online].\n",
      "Available: https://doi.org/10.1109/ASE51524.2021.9678894\n",
      "[154] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu,\n",
      "L. Zhou, N. Duan, A. Svyatkovskiy, S. Fu, M. Tufano,\n",
      "S. K. Deng, C. B. Clement, D. Drain, N. Sundaresan, J. Yin,\n",
      "D. Jiang, and M. Zhou, “Graphcodebert: Pre-training code\n",
      "representations with data flow,” in 9th International Conference\n",
      "on Learning Representations, ICLR 2021, Virtual Event, Austria,\n",
      "May 3-7, 2021 . OpenReview.net, 2021. [Online]. Available:\n",
      "https://openreview.net/forum?id=jLoC4ez43PZ\n",
      "[155] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and\n",
      "J. Xiao, “Lsun: Construction of a large-scale image dataset us-\n",
      "ing deep learning with humans in the loop,” arXiv preprint\n",
      "arXiv:1506.03365, 2015.\n",
      "[156] LoadRunner, Inc., “Loadrunner,” 2023, microfocus.com.\n",
      "[157] LangChain, Inc., “Langchain,” 2023, https://docs.langchain.\n",
      "com/docs/.\n",
      "[158] Prompt engineering, “Prompt engineering guide,” 2023, https:\n",
      "//github.com/dair-ai/Prompt-Engineering-Guide.\n",
      "[159] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola,\n",
      "“Multimodal chain-of-thought reasoning in language models,”\n",
      "CoRR, vol. abs/2302.00923, 2023.\n",
      "[160] Z. Liu, X. Yu, Y. Fang, and X. Zhang, “Graphprompt: Unifying\n",
      "pre-training and downstream tasks for graph neural networks,”\n",
      "in Proceedings of the ACM Web Conference 2023, WWW 2023, Austin,\n",
      "TX, USA, 30 April 2023 - 4 May 2023, Y. Ding, J. Tang, J. F. Sequeda,\n",
      "L. Aroyo, C. Castillo, and G. Houben, Eds. ACM, 2023, pp. 417–\n",
      "428.\n",
      "[161] Y. Charalambous, N. Tihanyi, R. Jain, Y. Sun, M. A. Ferrag, and\n",
      "L. C. Cordeiro, “A new era in software security: Towards self-\n",
      "healing software via large language models and formal verifica-\n",
      "tion,” 2023.\n",
      "[162] S. Wang, L. Huang, A. Gao, J. Ge, T. Zhang, H. Feng, I. Satyarth,\n",
      "M. Li, H. Zhang, and V . Ng, “Machine/deep learning for\n",
      "software engineering: A systematic literature review,” IEEE\n",
      "Trans. Software Eng., vol. 49, no. 3, pp. 1188–1231, 2023. [Online].\n",
      "Available: https://doi.org/10.1109/TSE.2022.3173346\n",
      "[163] Y. Yang, X. Xia, D. Lo, and J. C. Grundy, “A survey on\n",
      "deep learning for software engineering,” ACM Comput. Surv. ,\n",
      "vol. 54, no. 10s, pp. 206:1–206:73, 2022. [Online]. Available:\n",
      "https://doi.org/10.1145/3505243\n",
      "[164] C. Watson, N. Cooper, D. Nader-Palacio, K. Moran, and\n",
      "D. Poshyvanyk, “A systematic literature review on the use of\n",
      "deep learning in software engineering research,” ACM Trans.\n",
      "Softw. Eng. Methodol., vol. 31, no. 2, pp. 32:1–32:58, 2022. [Online].\n",
      "Available: https://doi.org/10.1145/3485275\n",
      "[165] M. Bajammal, A. Stocco, D. Mazinanian, and A. Mesbah,\n",
      "“A survey on the use of computer vision to improve\n",
      "software engineering tasks,” IEEE Trans. Software Eng. ,\n",
      "vol. 48, no. 5, pp. 1722–1742, 2022. [Online]. Available:\n",
      "https://doi.org/10.1109/TSE.2020.3032986\n",
      "[166] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo,\n",
      "D. Lo, J. C. Grundy, and H. Wang, “Large language\n",
      "models for software engineering: A systematic literature\n",
      "review,” CoRR, vol. abs/2308.10620, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10620\n",
      "[167] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta,\n",
      "S. Yoo, and J. M. Zhang, “Large language models\n",
      "for software engineering: Survey and open problems,”\n",
      "CoRR, vol. abs/2310.03533, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2310.03533\n",
      "[168] D. Zan, B. Chen, F. Zhang, D. Lu, B. Wu, B. Guan,\n",
      "Y. Wang, and J. Lou, “Large language models meet nl2code:\n",
      "A survey,” in Proceedings of the 61st Annual Meeting of\n",
      "the Association for Computational Linguistics (Volume 1: Long\n",
      "Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , A. Rogers,\n",
      "J. L. Boyd-Graber, and N. Okazaki, Eds. Association for\n",
      "Computational Linguistics, 2023, pp. 7443–7464. [Online].\n",
      "Available: https://doi.org/10.18653/v1/2023.acl-long.41127\n",
      "TABLE 5: All details of the collected papers\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "1 Unit Test Case Generation with Transform-\n",
      "ers and Focal Context\n",
      "2021 Unit test case gener-\n",
      "ation\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[26]\n",
      "2 Codet: Code Generation with Generated\n",
      "Tests\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Pure LLM ICLR 2023\n",
      "[27]\n",
      "3 Interactive Code Generation via Test-Driven\n",
      "User-Intent Formalization\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Statistic analysis\n",
      "Arxiv\n",
      "[28]\n",
      "4 A3Test: Assertion-Augmented Automated\n",
      "Test Case Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[29]\n",
      "5 An Empirical Evaluation of Using Large\n",
      "Language Models for Automated Unit Test\n",
      "Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Others Syntactic repair Arxiv\n",
      "[30]\n",
      "6 An Initial Investigation of ChatGPT Unit\n",
      "Test Generation Capability\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM SAST 2023\n",
      "[31]\n",
      "7 Automated Test Case Generation Using\n",
      "Code Models and Domain Adaptation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeT5; LLaMA-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[32]\n",
      "8 Automatic Generation of Test Cases based\n",
      "on Bug Reports: a Feasibility Study with\n",
      "Large Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGPT; ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM Arxiv\n",
      "[33]\n",
      "9 Can Large Language Models Write Good\n",
      "Property-Based Tests?\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Zero-shot learning Code; Others Pure LLM Arxiv\n",
      "[34]\n",
      "10 CAT-LM Training Language Models on\n",
      "Aligned Code And Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-neox Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[35]\n",
      "11 ChatGPT vs SBST: A Comparative Assess-\n",
      "ment of Unit Test Suite Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv [8]\n",
      "12 ChatUniTest: a ChatGPT-based Automated\n",
      "Unit Test Generation Tool\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Syntactic repair Arxiv\n",
      "[36]\n",
      "13 CODAMOSA: Escaping Coverage Plateaus\n",
      "in Test Generation with Pre-trained Large\n",
      "Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Program analysis\n",
      "ICSE 2023\n",
      "[37]\n",
      "14 Effective Test Generation Using Pre-trained\n",
      "Large Language Models and Mutation Test-\n",
      "ing\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Mutation testing;\n",
      "Syntactic repair\n",
      "Arxiv\n",
      "[38]\n",
      "15 Exploring the Effectiveness of Large Lan-\n",
      "guage Models in Generating Unit Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGen; Codex;\n",
      "ChatGPT\n",
      "Zero-shot learning Code Syntactic repair Arxiv\n",
      "[39]\n",
      "16 How Well does LLM Generate Security\n",
      "Tests?\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[40]\n",
      "17 No More Manual Tests? Evaluating and Im-\n",
      "proving ChatGPT for Unit Test Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv [7]\n",
      "18 Prompting Code Interpreter to Write Better\n",
      "Unit Tests on Quixbugs Functions\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Few-shot learning Code Pure LLM Arxiv\n",
      "[41]\n",
      "19 Reinforcement Learning from Automatic\n",
      "Feedback for High-Quality Unit Test Gen-\n",
      "eration\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis,\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[42]\n",
      "20 Unit Test Generation using Generative AI: A\n",
      "Comparative Performance Analysis of Au-\n",
      "togeneration Tools\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[43]\n",
      "21 Generating Accurate Assert Statements for\n",
      "Unit Test Cases Using Pretrained Trans-\n",
      "formers\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM AST 2022\n",
      "[44]\n",
      "22 Learning Deep Semantics for Test Comple-\n",
      "tion\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[45]\n",
      "23 Using Transfer Learning for Code-Related\n",
      "Tasks\n",
      "2022 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM TSE 2022\n",
      "[46]\n",
      "24 Retrieval-Based Prompt Selection for Code-\n",
      "Related Few-Shot Learning\n",
      "2023 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "Codex Few-shot learning Code Pure LLM ICSE 2023\n",
      "[47]28\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "25 Automated Conformance Testing for\n",
      "JavaScript Engines via Deep Compiler\n",
      "Fuzzing\n",
      "2021 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing;\n",
      "Program analysis\n",
      "PLDI 2021\n",
      "[48]\n",
      "26 Fill in the Blank: Context-aware Automated\n",
      "Text Input Generation for Mobile GUI Test-\n",
      "ing\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2023\n",
      "[49]\n",
      "27 Large Language Models are Pretty Good\n",
      "Zero-Shot Video Game Bug Detectors\n",
      "2022 System test input\n",
      "generation\n",
      "InstructGPT Chain-of-Thought;\n",
      "Zero-shot learning\n",
      "Others Pure LLM Arxiv\n",
      "[50]\n",
      "28 Slgpt: Using Transfer Learning to Directly\n",
      "Generate Simulink Model Files and Find\n",
      "Bugs in the Simulink Toolchain\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Others Formal method EASE 2021\n",
      "[51]\n",
      "29 Augmenting Greybox Fuzzing with Gener-\n",
      "ative AI\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[52]\n",
      "30 Automated Test Case Generation Using T5\n",
      "and GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3; T5 Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM ICACCS\n",
      "2023 [53]\n",
      "31 Automating GUI-based Software Testing\n",
      "with GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSTW\n",
      "2023 [54]\n",
      "32 AXNav: Replaying Accessibility Tests from\n",
      "Natural Language\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Chain-of-Thought View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[55]\n",
      "33 Can ChatGPT Advance Software Testing In-\n",
      "telligence? An Experience Report on Meta-\n",
      "morphic Testing\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning Others Pure LLM Arxiv\n",
      "[56]\n",
      "34 Efficient Mutation Testing via Pre-Trained\n",
      "Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "CodeBert Zero-shot learning Code Mutation testing Arxiv\n",
      "[57]\n",
      "35 Large Language Models are Edge-Case\n",
      "Generators:Crafting Unusual Programs for\n",
      "Fuzzing Deep Learning Libraries\n",
      "2023 System test input\n",
      "generation\n",
      "Codex Chain-of-Thought; Pre-\n",
      "training and/or Fine-\n",
      "tuning; Zero-shot learn-\n",
      "ing; Few-shot learning\n",
      "Code Differential testing ICSE 2024\n",
      "[58]\n",
      "36 Large Language Models are Zero Shot\n",
      "Fuzzers: Fuzzing Deep Learning Libraries\n",
      "via Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "Codex; InCoder Zero-shot learning Code Mutation testing;\n",
      "Differential testing\n",
      "ISSTA 2023\n",
      "[59]\n",
      "37 Large Language Models for Fuzzing Parsers\n",
      "(Registered Report)\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Few-shot learning NL specifica-\n",
      "tion\n",
      "Pure LLM FUZZING\n",
      "2023 [60]\n",
      "38 LLM for Test Script Generation and Migra-\n",
      "tion: Challenges, Capabilities, and Opportu-\n",
      "nities\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[61]\n",
      "39 Make LLM a Testing Expert: Bringing\n",
      "Human-like Interaction to Mobile GUI Test-\n",
      "ing via Functionality-aware Decisions\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Natural language\n",
      "processing\n",
      "ICSE 2024\n",
      "[14]\n",
      "40 PentestGPT: An LLM-empowered Auto-\n",
      "matic Penetration Testing Tool\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4;\n",
      "LaMDA\n",
      "Chain-of-Thought;\n",
      "Few-shot learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[62]\n",
      "41 SMT Solver Validation Empowered by\n",
      "Large Pre-Trained Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing ASE 2023\n",
      "[63]\n",
      "42 TARGET: Automated Scenario Generation\n",
      "from Traffic Rules for Testing Autonomous\n",
      "Vehicles\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning Others Scenario testing Arxiv\n",
      "[64]\n",
      "43 Testing the Limits: Unusual Text Inputs\n",
      "Generation for Mobile App Crash Detection\n",
      "with Large Language Model\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2024\n",
      "[65]\n",
      "44 Understanding Large Language Model\n",
      "Based Fuzz Driver Generation\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4 Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Others Pure LLM Arxiv\n",
      "[66]\n",
      "45 Universal Fuzzing via Large Language\n",
      "Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning; Au-\n",
      "tomatic prompt\n",
      "Code Mutation testing ICSE 2024\n",
      "[67]\n",
      "46 Variable Discovery with Large Language\n",
      "Models for Metamorphic Testing of Scien-\n",
      "tific Software\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-j Zero-shot learning Others Pure LLM SANER\n",
      "2023 [68]29\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "47 White-box Compiler Fuzzing Empowered\n",
      "by Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning Code Pure LLM Arxiv\n",
      "[69]\n",
      "48 Itiger: an Automatic Issue Title Generation\n",
      "Tool\n",
      "2022 Bug analysis BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM FSE 2022\n",
      "[70]\n",
      "49 CrashTranslator: Automatically Reproduc-\n",
      "ing Mobile Application Crashes Directly\n",
      "from Stack Trace\n",
      "2023 Bug analysis ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Reinforcement\n",
      "learning\n",
      "ICSE 2024\n",
      "[71]\n",
      "50 Cupid: Leveraging ChatGPT for More Ac-\n",
      "curate Duplicate Bug Report Detection\n",
      "2023 Bug analysis ChatGPT Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[72]\n",
      "51 Employing Deep Learning and Structured\n",
      "Information Retrieval to Answer Clarifica-\n",
      "tion Questions on Bug Reports\n",
      "2023 Bug analysis CodeT5 Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[73]\n",
      "52 Explaining Software Bugs Leveraging Code\n",
      "Structures in Neural Machine Translation\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2023\n",
      "[74]\n",
      "53 Prompting Is All Your Need: Automated\n",
      "Android Bug Replay with Large Language\n",
      "Models\n",
      "2023 Bug analysis ChatGPT Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Bug description Pure LLM ICSE 2024\n",
      "[75]\n",
      "54 Still Confusing for Bug-Component Triag-\n",
      "ing? Deep Feature Learning and Ensemble\n",
      "Setting to Rescue\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Statistic analysis ICPC 2023\n",
      "[76]\n",
      "55 Detect-Localize-Repair: A Unified Frame-\n",
      "work for Learning to Debug with CodeT5\n",
      "2022 Debug CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM EMNLP\n",
      "2022 [77]\n",
      "56 Large Language Models are Few-shot\n",
      "Testers: Exploring LLM-based General Bug\n",
      "Reproduction\n",
      "2022 Debug Codex Few-shot learning Bug description Program analysis;\n",
      "Statistic analysis\n",
      "ICSE 2023\n",
      "[78]\n",
      "57 A Preliminary Evaluation of LLM-Based\n",
      "Fault Localization\n",
      "2023 Debug ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[79]\n",
      "58 Addressing Compiler Errors: Stack Over-\n",
      "flow or Large Language Models?\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Error informa-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[80]\n",
      "59 Can LLMs Demystify Bug Reports? 2023 Debug ChatGPT Zero-shot learning Bug description Pure LLM Arxiv\n",
      "[81]\n",
      "60 Dcc –help: Generating Context-Aware Com-\n",
      "piler Error Explanations with Large Lan-\n",
      "guage Models\n",
      "2023 Debug ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM SIGCSE\n",
      "2024 [82]\n",
      "61 Explainable Automated Debugging via\n",
      "Large Language Model-driven Scientific De-\n",
      "bugging\n",
      "2023 Debug CodeGen; Codex;\n",
      "ChatGPT\n",
      "Self-consistency; Zero-\n",
      "shot learning\n",
      "Code Pure LLM Arxiv\n",
      "[83]\n",
      "62 Large Language Models for Test-Free Fault\n",
      "Localization\n",
      "2023 Debug CodeGen Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[84]\n",
      "63 Large Language Models in Fault Localisa-\n",
      "tion\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[85]\n",
      "64 LLM4CBI: Taming LLMs to Generate Effec-\n",
      "tive Test Programs for Compiler Bug Isola-\n",
      "tion\n",
      "2023 Debug ChatGPT Zero-shot learning Code Mutation testing;\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[86]\n",
      "65 Nuances are the Key: Unlocking ChatGPT\n",
      "to Find Failure-Inducing Tests with Differ-\n",
      "ential Prompting\n",
      "2023 Debug ChatGPT Zero-shot learning Code Differential testing ASE 2023\n",
      "[87]\n",
      "66 Teaching Large Language Models to Self-\n",
      "Debug\n",
      "2023 Debug Codex; ChatGPT;\n",
      "GPT-4; StarCoder\n",
      "Few-shot learning Code Pure LLM Arxiv\n",
      "[88]\n",
      "67 A study on Prompt Design, Advantages and\n",
      "Limitations of ChatGPT for Deep Learning\n",
      "Program Repair\n",
      "2023 Debug; Program re-\n",
      "pair\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[89]\n",
      "68 Examining Zero-Shot Vulnerability Repair\n",
      "with Large Language Models\n",
      "2021 Program repair Codex Zero-shot learning Code; Bug de-\n",
      "scription\n",
      "Pure LLM SP 2023\n",
      "[90]\n",
      "69 Automated Repair of Programs from Large\n",
      "Language Models\n",
      "2022 Program repair Codex Zero-shot learning Code Pure LLM ICSE 2023\n",
      "[91]\n",
      "70 Fix Bugs with Transformer through a\n",
      "Neural-Symbolic Edit Grammar\n",
      "2022 Program repair CodeGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[92]\n",
      "71 Practical Program Repair in the Era of Large\n",
      "Pre-trained Language Models\n",
      "2022 Program repair GPT-3; Codex;\n",
      "CodeT5; InCoder\n",
      "Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[93]30\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "72 Repairing Bugs in Python Assignments Us-\n",
      "ing Large Language Models\n",
      "2022 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv\n",
      "[94]\n",
      "73 Towards JavaScript Program Repair with\n",
      "Generative Pre-trained Transformer (GPT-2)\n",
      "2022 Program repair GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2022\n",
      "[95]\n",
      "74 An Analysis of the Automatic Bug Fixing\n",
      "Performance of ChatGPT\n",
      "2023 Program repair ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM APR 2023\n",
      "[96]\n",
      "75 An Empirical Study on Fine-Tuning Large\n",
      "Language Models of Code for Automated\n",
      "Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "UniXCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[97]\n",
      "76 An Evaluation of the Effectiveness of Ope-\n",
      "nAI’s ChatGPT for Automated Python Pro-\n",
      "gram Bug Fixing using QuixBugs\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM iSemantic\n",
      "2023 [98]\n",
      "77 An Extensive Study on Model Architecture\n",
      "and Program Representation in the Domain\n",
      "of Learning-based Automated Program Re-\n",
      "pair\n",
      "2023 Program repair T5; CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[99]\n",
      "78 Can OpenAI’s Codex Fix Bugs? An Evalua-\n",
      "tion on QuixBugs\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Pure LLM APR 2022\n",
      "[100]\n",
      "79 CIRCLE: Continual Repair Across Program-\n",
      "ming Languages\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ISSTA 2022\n",
      "[101]\n",
      "80 Coffee: Boost Your Code LLMs by Fixing\n",
      "Bugs with Feedback\n",
      "2023 Program repair CodeLLAMA Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[102]\n",
      "81 Copiloting the Copilots: Fusing Large Lan-\n",
      "guage Models with Completion Engines for\n",
      "Automated Program Repair\n",
      "2023 Program repair CodeT5; InCoder Zero-shot learning Code Statistic analysis FSE 2023\n",
      "[103]\n",
      "82 Domain Knowledge Matters: Improving\n",
      "Prompts with Fix Templates for Repairing\n",
      "Python Type Errors\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2024\n",
      "[104]\n",
      "83 Enhancing Genetic Improvement Mutations\n",
      "Using Large Language Models\n",
      "2023 Program repair GPT-4 Zero-shot learning Code Pure LLM SSBSE 2023\n",
      "[105]\n",
      "84 FixEval: Execution-based Evaluation of Pro-\n",
      "gram Fixes for Programming Problems\n",
      "2023 Program repair CodeT5; PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[106]\n",
      "85 Fixing Hardware Security Bugs with Large\n",
      "Language Models\n",
      "2023 Program repair Codex; CodeGen Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[107]\n",
      "86 Fixing Rust Compilation Errors using LLMs 2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[108]\n",
      "87 Framing Program Repair as Code Comple-\n",
      "tion\n",
      "2023 Program repair CodeGPT Zero-shot learning Code Pure LLM ICSE 2022\n",
      "[109]\n",
      "88 Frustrated with Code Quality Issues? LLMs\n",
      "can Help!\n",
      "2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[110]\n",
      "89 GPT-3-Powered Type Error Debugging: In-\n",
      "vestigating the Use of Large Language Mod-\n",
      "els for Code Repair\n",
      "2023 Program repair GPT-3 Zero-shot learning Code Program analysis SLE 2023\n",
      "[111]\n",
      "90 How Effective Are Neural Networks for Fix-\n",
      "ing Security Vulnerabilities\n",
      "2023 Program repair Codex; CodeGen;\n",
      "CodeT5; PLBART;\n",
      "InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ISSTA 2023\n",
      "[112]\n",
      "91 Impact of Code Language Models on Auto-\n",
      "mated Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "CodeGen; InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ICSE 2023\n",
      "[113]\n",
      "92 Inferfix: End-to-end Program Repair with\n",
      "LLMs\n",
      "2023 Program repair Codex Few-shot learning; Pre-\n",
      "training and/or Fine-\n",
      "tuning\n",
      "Code Pure LLM FSE 2023\n",
      "[114]\n",
      "93 Keep the Conversation Going: Fixing 162\n",
      "out of 337 bugs for $0.42 each using Chat-\n",
      "GPT\n",
      "2023 Program repair ChatGPT Few-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[115]\n",
      "94 Neural Program Repair with Program De-\n",
      "pendence Analysis and Effective Filter\n",
      "Mechanism\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis Arxiv\n",
      "[116]31\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "95 Out of Context: How important is Local\n",
      "Context in Neural Program Repair?\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[117]\n",
      "96 Pre-trained Model-based Automated Soft-\n",
      "ware Vulnerability Repair: How Far are We?\n",
      "2023 Program repair CodeT5; UniX-\n",
      "Coder; CodeGPT\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM IEEE TDSC\n",
      "[118]\n",
      "97 RAPGen: An Approach for Fixing Code In-\n",
      "efficiencies in Zero-Shot\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Code Pure LLM Arxiv\n",
      "[119]\n",
      "98 RAP-Gen: Retrieval-Augmented Patch Gen-\n",
      "eration with CodeT5 for Automatic Pro-\n",
      "gram Repair\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis FSE 2023\n",
      "[120]\n",
      "99 STEAM: Simulating the InTeractive BEhav-\n",
      "ior of ProgrAMmers for Automatic Bug Fix-\n",
      "ing\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[121]\n",
      "100 Towards Generating Functionally Correct\n",
      "Code Edits from Natural Language Issue\n",
      "Descriptions\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning;\n",
      "Zero-shot learning;\n",
      "Chain-of-Thought\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[122]\n",
      "101 VulRepair: a T5-based Automated Software\n",
      "Vulnerability Repair\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM FSE 2022\n",
      "[123]\n",
      "102 What Makes Good In-Context Demonstra-\n",
      "tions for Code Intelligence Tasks with\n",
      "LLMs?\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning Code Pure LLM ASE 2023\n",
      "[124]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Software Testing with Large Language Models:\n",
      "Survey, Landscape, and Vision\n",
      "Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang\n",
      "Abstract—Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language\n",
      "processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide\n",
      "range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability\n",
      "of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing\n",
      "techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides\n",
      "a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software\n",
      "testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for\n",
      "which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes\n",
      "the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs.\n",
      "It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research\n",
      "in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in\n",
      "software testing.\n",
      "Index Terms—Pre-trained Large Language Model, Software Testing, LLM, GPT\n",
      "✦\n",
      "1 I NTRODUCTION\n",
      "Software testing is a crucial undertaking that serves as\n",
      "a cornerstone for ensuring the quality and reliability of\n",
      "software products. Without the rigorous process of software\n",
      "testing, software enterprises would be reluctant to release\n",
      "their products into the market, knowing the potential\n",
      "consequences of delivering flawed software to end-users.\n",
      "By conducting thorough and meticulous testing procedures,\n",
      "software enterprises can minimize the occurrence of critical\n",
      "software failures, usability issues, or security breaches\n",
      "that could potentially lead to financial losses or jeopardize\n",
      "user trust. Additionally, software testing helps to reduce\n",
      "maintenance costs by identifying and resolving issues early\n",
      "in the development lifecycle, preventing more significant\n",
      "complications down the line [1], [2].\n",
      "The significance of software testing has garnered sub-\n",
      "stantial attention within the research and industrial com-\n",
      "munities. In the field of software engineering, it stands as\n",
      "an immensely popular and vibrant research area. One can\n",
      "observe the undeniable prominence of software testing by\n",
      "simply examining the landscape of conferences and sym-\n",
      "posiums focused on software engineering. Amongst these\n",
      "events, topics related to software testing consistently domi-\n",
      "nate the submission numbers and are frequently selected for\n",
      "publication.\n",
      "● J. Wang,Y. Huang, Z. Liu, Q. Wang are with State Key Laboratory of\n",
      "Intelligent Game, Institute of Software Chinese Academy of Sciences, and\n",
      "University of Chinese Academy of Sciences, Beijing, China. J. Wang and\n",
      "Q. Wang are corresponding authors.\n",
      "E-mail: {junjie, yuchao2019, liuzhe2020, wq}@iscas.ac.cn\n",
      "● C. Chen is with Monash University, Melbourne, Australia\n",
      "E-mail: chunyang.chen@monash.edu\n",
      "● S. Wang is with York University, Toronto, Canada.\n",
      "E-mail: wangsong@yorku.ca\n",
      "While the field of software testing has gained signifi-\n",
      "cant popularity, there remain dozens of challenges that have\n",
      "not been effectively addressed. For example, one such chal-\n",
      "lenge is automated unit test case generation. Although var-\n",
      "ious approaches, including search-based [3], [4], constraint-\n",
      "based [5] or random-based [6] techniques to generate a suite\n",
      "of unit tests, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory [7], [8]. Simi-\n",
      "larly, when it comes to mobile GUI testing, existing studies\n",
      "with random-/rule-based methods [9], [10], model-based\n",
      "methods [11], [12], and learning-based methods [13] are un-\n",
      "able to understand the semantic information of the GUI\n",
      "page and often fall short in achieving comprehensive cov-\n",
      "erage [14], [15]. Considering these limitations, numerous re-\n",
      "search efforts are currently underway to explore innovative\n",
      "techniques that can enhance the efficacy of software testing\n",
      "tasks, among which large language models are the most\n",
      "promising ones.\n",
      "Large language models (LLMs) such as T5 and GPT-3\n",
      "have revolutionized the field of natural language processing\n",
      "(NLP) and artificial intelligence (AI). These models, initially\n",
      "pre-trained on extensive corpora, have exhibited remarkable\n",
      "performance across a wide range of NLP tasks including\n",
      "question-answering, machine translation, and text genera-\n",
      "tion [16]–[19]. In recent years, there has been a significant\n",
      "advancement in LLMs with the emergence of models capa-\n",
      "ble of handling even larger-scale datasets. This expansion\n",
      "in model size has not only led to improved performance\n",
      "but also opened up new possibilities for applying LLMs\n",
      "as Artificial General Intelligence. Among these advanced\n",
      "LLMs, models like ChatGPT 1 and LLaMA 2 boast billions\n",
      "1. https://openai.com/blog/chatgpt\n",
      "2. https://ai.meta.com/blog/large-language-model-llama-meta-ai/\n",
      "arXiv:2307.07221v3  [cs.SE]  4 Mar 20242\n",
      "of parameters. Such models hold tremendous potential for\n",
      "tackling complex practical tasks in domains like code gener-\n",
      "ation and artistic creation. With their expanded capacity and\n",
      "enhanced capabilities, LLMs have become game-changers in\n",
      "NLP and AI, and are driving advancements in other fields\n",
      "like coding and software testing.\n",
      "LLMs have been used for various coding-related tasks\n",
      "including code generation and code recommendation [20]–\n",
      "[23]. On one hand, in software testing, there are many tasks\n",
      "related to code generation, such as unit test generation [7],\n",
      "where the utilization of LLMs is expected to yield good\n",
      "performance. On the other hand, software testing possesses\n",
      "unique characteristics that differentiate it from code gener-\n",
      "ation. For example, code generation primarily focuses on\n",
      "producing a single, correct code snippet, whereas software\n",
      "testing often requires generating diverse test inputs to en-\n",
      "sure better coverage of the software under test [1]. The ex-\n",
      "istence of these differences introduces new challenges and\n",
      "opportunities when employing LLMs for software testing.\n",
      "Moreover, people have benefited from the excellent perfor-\n",
      "mance of LLMs in generation and inference tasks, leading\n",
      "to the emergence of dozens of new practices that use LLMs\n",
      "for software testing.\n",
      "This article presents a comprehensive review of the uti-\n",
      "lization of LLMs in software testing. We collect 102 relevant\n",
      "papers and conduct a thorough analysis from both software\n",
      "testing and LLMs perspectives, as roughly summarized in\n",
      "Figure 1.\n",
      "From the viewpoint of software testing, our analysis in-\n",
      "volves an examination of the specific software testing tasks\n",
      "for which LLMs are employed. Results show that LLMs are\n",
      "commonly used for test case preparation (including unit test\n",
      "case generation, test oracle generation, and system test input\n",
      "generation), program debugging, and bug repair, while we\n",
      "do not find the practices for applying LLMs in the tasks of\n",
      "early testing life-cycle (such as test requirement, test plan,\n",
      "etc). For each test task, we would provide detailed illustra-\n",
      "tions showcasing the utilization of LLMs in addressing the\n",
      "task, highlighting commonly-used practices, tracking tech-\n",
      "nology evolution trends, and summarizing achieved per-\n",
      "formance, so as to facilitate readers in gaining a thorough\n",
      "overview of how LLMs are employed across various testing\n",
      "tasks.\n",
      "From the viewpoint of LLMs, our analysis includes\n",
      "the commonly used LLMs in these studies, the types of\n",
      "prompt engineering, the input of the LLMs, as well as\n",
      "the accompanied techniques with these LLMs. Results\n",
      "show that about one-third of the studies utilize the LLMs\n",
      "through pre-training or fine-tuning schema, while the others\n",
      "employ prompt engineering to communicate with LLMs\n",
      "to steer their behavior for desired outcomes. For prompt\n",
      "engineering, the zero-shot learning and few-shot learning\n",
      "strategies are most commonly used, while other advances\n",
      "like chain-of-thought promoting and self-consistency are\n",
      "rarely utilized. Results also show that traditional testing\n",
      "techniques like differential testing and mutation testing\n",
      "are usually accompanied by LLMs to help generate more\n",
      "diversified tests.\n",
      "Furthermore, we summarize the key challenges and po-\n",
      "tential opportunities in this direction. Although software\n",
      "testing with LLMs has undergone significant growth in the\n",
      "Fig. 1: Structure of the contents in this paper (the numbers\n",
      "in bracket indicates the number of involved papers, and a\n",
      "paper might involve zero or multiple items)\n",
      "past two years, there are still challenges in achieving high\n",
      "coverage of the testing, test oracle problem, rigorous evalu-\n",
      "ations, and real-world application of LLMs in software test-\n",
      "ing. Since it is a new emerging field, there are many research\n",
      "opportunities, including exploring LLMs in an early stage of\n",
      "testing, exploring LLMs for more types of software and non-\n",
      "functional testing, exploring advanced prompt engineering,\n",
      "as well as incorporating LLMs with traditional techniques.\n",
      "This paper makes the following contributions:\n",
      "● We thoroughly analyze 102 relevant studies that used\n",
      "LLMs for software testing, regarding publication\n",
      "trends, distribution of publication venues, etc.\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of software testing to understand the distribution of\n",
      "software testing tasks with LLM and present a thorough\n",
      "discussion about how these tasks are solved with LLM.\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of LLMs, and uncover the commonly-used LLMs,\n",
      "the types of prompt engineering, input of the LLMs, as\n",
      "well as the accompanied techniques with these LLMs.\n",
      "● We highlight the challenges in existing studies and\n",
      "present potential opportunities for further studies.\n",
      "We believe that this work will be valuable to both re-\n",
      "searchers and practitioners in the field of software engineer-\n",
      "ing, as it provides a comprehensive overview of the current\n",
      "state and future vision of using LLMs for software testing.\n",
      "For researchers, this work can serve as a roadmap for future\n",
      "research in this area, highlighting potential avenues for ex-\n",
      "ploration and identifying gaps in our current understanding\n",
      "of the use of LLMs in software testing. For practitioners, this\n",
      "work can provide insights into the potential benefits and\n",
      "limitations of using LLMs for software testing, as well as\n",
      "practical guidance on how to effectively integrate them into3\n",
      "existing testing processes. By providing a detailed landscape\n",
      "of the current state and future vision of using LLMs for\n",
      "software testing, this work can help accelerate the adoption\n",
      "of this technology in the software engineering community\n",
      "and ultimately contribute to improving the quality and reli-\n",
      "ability of software systems.\n",
      "2 B ACKGROUND\n",
      "2.1 Large Language Model (LLM)\n",
      "Recently, pre-trained language models (PLMs) have been\n",
      "proposed by pretraining Transformer-based models over\n",
      "large-scale corpora, showing strong capabilities in solving\n",
      "various natural language processing (NLP) tasks [16]–[19].\n",
      "Studies have shown that model scaling can lead to improved\n",
      "model capacity, prompting researchers to investigate the\n",
      "scaling effect through further parameter size increases.\n",
      "Interestingly, when the parameter scale exceeds a certain\n",
      "threshold, these larger language models demonstrate not\n",
      "only significant performance improvements but also special\n",
      "abilities such as in-context learning, which are absent in\n",
      "smaller models such as BERT.\n",
      "To discriminate the language models in different\n",
      "parameter scales, the research community has coined\n",
      "the term large language models (LLM) for the PLMs of\n",
      "significant size. LLMs typically refer to language models\n",
      "that have hundreds of billions (or more) of parameters and\n",
      "are trained on massive text data such as GPT-3, PaLM,\n",
      "Codex, and LLaMA. LLMs are built using the Transformer\n",
      "architecture, which stacks multi-head attention layers\n",
      "in a very deep neural network. Existing LLMs adopt\n",
      "similar model architectures (Transformer) and pre-training\n",
      "objectives (language modeling) as small language models,\n",
      "but largely scale up the model size, pre-training data,\n",
      "and total compute power. This enables LLMs to better\n",
      "understand natural language and generate high-quality text\n",
      "based on given context or prompts.\n",
      "Note that, in existing literature, there is no formal con-\n",
      "sensus on the minimum parameter scale for LLMs, since\n",
      "the model capacity is also related to data size and total\n",
      "compute. In a recent survey of LLMs [17], the authors focus\n",
      "on discussing the language models with a model size larger\n",
      "than 10B. Under their criteria, the first LLM is T5 released\n",
      "by Google in 2019, followed by GPT-3 released by OpenAI\n",
      "in 2020, and there are more than thirty LLMs released be-\n",
      "tween 2021 and 2023 indicating its popularity. In another\n",
      "survey of unifying LLMs and knowledge graphs [24], the\n",
      "authors categorize the LLMs into three types: encoder-only\n",
      "(e.g., BERT), encoder-decoder (e.g., T5), and decoder-only\n",
      "network architecture (e.g., GPT-3). In our review, we take\n",
      "into account the categorization criteria of the two surveys\n",
      "and only consider the encoder-decoder and decoder-only\n",
      "network architecture of pre-training language models, since\n",
      "they can both support generative tasks. We do not consider\n",
      "the encoder-only network architecture because they cannot\n",
      "handle generative tasks, were proposed relatively early (e.g.,\n",
      "BERT in 2018), and there are almost no models using this\n",
      "architecture after 2021. In other words, the LLMs discussed\n",
      "in this paper not only include models with parameters of\n",
      "over 10B (as mentioned in [17]) but also include other mod-\n",
      "els that use the encoder-decoder and decoder-only network\n",
      "architecture (as mentioned in [24]), such as BART with 140M\n",
      "parameters and GPT-2 with parameter sizes ranging from\n",
      "117M to 1.5B. This is also to potentially include more studies\n",
      "to demonstrate the landscape of this topic.\n",
      "2.2 Software Testing\n",
      "Software testing is a crucial process in software develop-\n",
      "ment that involves evaluating the quality of a software prod-\n",
      "uct. The primary goal of software testing is to identify de-\n",
      "fects or errors in the software system that could potentially\n",
      "lead to incorrect or unexpected behavior. The whole life\n",
      "cycle of software testing typically includes the following\n",
      "tasks (demonstrated in Figure 4):\n",
      "● Requirement Analysis: analyze the software require-\n",
      "ments and identify the testing objectives, scope, and\n",
      "criteria.\n",
      "● Test Plan: develop a test plan that outlines the testing\n",
      "strategy, test objectives, and schedule.\n",
      "● Test Design and Review: develop and review the test\n",
      "cases and test suites that align with the test plan and\n",
      "the requirements of the software application.\n",
      "● Test Case Preparation: the actual test cases are prepared\n",
      "based on the designs created in the previous stage.\n",
      "● Test Execution: execute the tests that were designed in\n",
      "the previous stage. The software system is executed\n",
      "with the test cases and the results are recorded.\n",
      "● Test Reporting: analyze the results of the tests and gen-\n",
      "erate reports that summarize the testing process and\n",
      "identify any defects or issues that were discovered.\n",
      "● Bug Fixing and Regression Testing: defects or issues\n",
      "identified during testing are reported to the develop-\n",
      "ment team for fixing. Once the defects are fixed, regres-\n",
      "sion testing is performed to ensure that the changes\n",
      "have not introduced new defects or issues.\n",
      "● Software Release: once the software system has passed\n",
      "all of the testing stages and the defects have been fixed,\n",
      "the software can be released to the customer or end\n",
      "user.\n",
      "The testing process is iterative and may involve multiple\n",
      "cycles of the above stages, depending on the complexity of\n",
      "the software system and the testing requirements.\n",
      "During the testing phase, various types of tests may be\n",
      "performed, including unit tests, integration tests, system\n",
      "tests, and acceptance tests.\n",
      "● Unit Testing involves testing individual units or com-\n",
      "ponents of the software application to ensure that they\n",
      "function correctly.\n",
      "● Integration Testing involves testing different modules\n",
      "or components of the software application together to\n",
      "ensure that they work correctly as a system.\n",
      "● System Testing involves testing the entire software sys-\n",
      "tem as a whole, including all the integrated components\n",
      "and external dependencies.\n",
      "● Acceptance Testing involves testing the software appli-\n",
      "cation to ensure that it meets the business requirements\n",
      "and is ready for deployment.\n",
      "In addition, there can be functional testing, performance\n",
      "testing, unit testing, security testing, accessibility testing,\n",
      "etc, which explores various aspects of the software under\n",
      "test [25].4\n",
      "3.1.1 Automatic \n",
      "Search\n",
      "3.1.1 Automatic \n",
      "Filtering\n",
      "3.1.4 Quality \n",
      "Assessment3.1.5 Snowballing\n",
      "14,623 \n",
      "Papers\n",
      "102\n",
      "Papers\n",
      "1,239 \n",
      "Papers\n",
      "109 \n",
      "Papers\n",
      "START\n",
      "102 \n",
      "Papers\n",
      "Major SE Venues\n",
      "& AI Venues\n",
      "3.1.2 Manual Search\n",
      "1,278 \n",
      "Papers\n",
      "3.1.3 Inclusion and \n",
      "Exclusion Criteria\n",
      "Fig. 2: Overview of the paper collection process\n",
      "3 P APER SELECTION AND REVIEW SCHEMA\n",
      "3.1 Paper Collection Methodology\n",
      "Figure 2 shows our paper search and selection process. To\n",
      "collect as much relevant literature as possible, we use both\n",
      "automatic search (from paper repository database) and man-\n",
      "ual search (from major software engineering and artificial\n",
      "intelligence venues). We searched papers from Jan. 2019 to\n",
      "Jun. 2023 and further conducted the second round of search\n",
      "to include the papers from Jul. 2023 to Oct. 2023.\n",
      "3.1.1 Automatic Search\n",
      "To ensure that we collect papers from diverse research areas,\n",
      "we conduct an extensive search using four popular scientific\n",
      "databases: ACM digital library, IEEE Xplore digital library,\n",
      "arXiv, and DBLP .\n",
      "We search for papers whose title contains keywords re-\n",
      "lated to software testing tasks and testing techniques (as shown\n",
      "below) in the first three databases. In the case of DBLP , we\n",
      "use additional keywords related to LLMs (as shown below)\n",
      "to filter out irrelevant studies, as relying solely on testing-\n",
      "related keywords would result in a large number of can-\n",
      "didate studies. While using two sets of keywords for DBLP\n",
      "may result in overlooking certain related studies, we believe\n",
      "it is still a feasible strategy. This is due to the fact that a\n",
      "substantial number of studies present in this database can\n",
      "already be found in the first three databases, and the fourth\n",
      "database only serves as a supplementary source for collect-\n",
      "ing additional papers.\n",
      "● Keywords related with software testing tasks and tech-\n",
      "niques: test OR bug OR issue OR defect OR fault OR\n",
      "error OR failure OR crash OR debug OR debugger OR\n",
      "repair OR fix OR assert OR verification OR validation\n",
      "OR fuzz OR fuzzer OR mutation.\n",
      "● Keywords related with LLMs: LLMOR language model\n",
      "OR generative model OR large model OR GPT-3 OR\n",
      "ChatGPT OR GPT-4 OR LLaMA OR PaLM2 OR CodeT5\n",
      "OR CodeX OR CodeGen OR Bard OR InstructGPT. Note\n",
      "that, we only list the top ten most popular LLMs (based\n",
      "on Google search), since they are the search keywords\n",
      "for matching paper titles, rather than matching the pa-\n",
      "per content.\n",
      "The above search strategy based on the paper title can\n",
      "recall a large number of papers, and we further conduct the\n",
      "automatic filtering based on the paper content. Specifically,\n",
      "we filter the paper whose content contains “LLM” or “lan-\n",
      "guage model” or “generative model” or “large model” or\n",
      "the name of the LLMs (using the LLMs in [17], [24] except\n",
      "those in our exclusion criteria). This can help eliminate the\n",
      "papers that do not involve the neural models.\n",
      "3.1.2 Manual Search\n",
      "To compensate for the potential omissions that may result\n",
      "from automated searches, we also conduct manual searches.\n",
      "In order to make sure we collect highly relevant papers,\n",
      "we conduct a manual search within the conference proceed-\n",
      "ings and journal articles from top-tier software engineering\n",
      "venues (listed in Table 2).\n",
      "In addition, given the interdisciplinary nature of this\n",
      "work, we also include the conference proceedings of the\n",
      "artificial intelligence field. We select the top ten venues\n",
      "based on the h5 index from Google Scholar, and exclude\n",
      "three computer vision venues, i.e., CVPR, ICCV , ECCV , as\n",
      "listed in Table 2.\n",
      "3.1.3 Inclusion and Exclusion Criteria\n",
      "The search conducted on the databases and venue is, by de-\n",
      "sign, very inclusive. This allows us to collect as many papers\n",
      "as possible in our pool. However, this generous inclusivity\n",
      "results in having papers that are not directly related to the\n",
      "scope of this survey. Accordingly, we define a set of specific\n",
      "inclusion and exclusion criteria and then we apply them to\n",
      "each paper in the pool and remove papers not meeting the\n",
      "criteria. This ensures that each collected paper aligns with\n",
      "our scope and research questions.\n",
      "Inclusion Criteria. We define the following criteria for\n",
      "including papers:\n",
      "● The paper proposes or improves an approach, study, or\n",
      "tool/framework that targets testing specific software or\n",
      "systems with LLMs.\n",
      "● The paper applies LLMs to software testing practice,\n",
      "including all tasks within the software testing lifecycle\n",
      "as demonstrated in Section 2.2.\n",
      "● The paper presents an empirical or experimental study\n",
      "about utilizing LLMs in software testing practice.\n",
      "● The paper involves specific testing techniques (e.g.,\n",
      "fuzz testing) employing LLMs.\n",
      "If a paper satisfies any of the following criteria, we will\n",
      "include it.\n",
      "Exclusion Criteria. The following studies would be ex-\n",
      "cluded during study selection:\n",
      "● The paper does not involve software testing tasks, e.g.,\n",
      "code comment generation.\n",
      "● The paper does not utilize LLMs, e.g., using recurrent\n",
      "neural networks.\n",
      "● The paper mentions LLMs only in future work or dis-\n",
      "cussions rather than using LLMs in the approach.\n",
      "● The paper utilizes language models with encoder-only\n",
      "architecture, e.g., BERT, which can not directly be uti-\n",
      "lized for generation tasks (as demonstrated in Section\n",
      "2.1).\n",
      "● The paper focuses on testing the performance of LLMs,\n",
      "such as fairness, stability, security, etc. [125]–[127].\n",
      "● The paper focuses on evaluating the performance of\n",
      "LLM-enabled tools, e.g., evaluating the code quality of\n",
      "the code generation tool Copilot [128]–[130].\n",
      "For the papers collected through automatic search and\n",
      "manual search, we conduct a manual inspection to check\n",
      "whether they satisfy our inclusion criteria and filter those\n",
      "following our exclusion criteria. Specifically, the first two\n",
      "authors read each paper to carefully determine whether it5\n",
      "TABLE 1: Details of the collected papers\n",
      "ID Topic Paper title Year Reference\n",
      "1 Unit test case generation Unit Test Case Generation with Transformers and Focal Context 2020 [26]\n",
      "2 Unit test case generation Codet: Code Generation with Generated Tests 2022 [27]\n",
      "3 Unit test case generation Interactive Code Generation via Test-Driven User-Intent Formalization 2022 [28]\n",
      "4 Unit test case generation A3Test: Assertion-Augmented Automated Test Case Generation 2023 [29]\n",
      "5 Unit test case generation An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation 2023 [30]\n",
      "6 Unit test case generation An Initial Investigation of ChatGPT Unit Test Generation Capability 2023 [31]\n",
      "7 Unit test case generation Automated Test Case Generation Using Code Models and Domain Adaptation 2023 [32]\n",
      "8 Unit test case generation Automatic Generation of Test Cases based on Bug Reports: a Feasibility Study with Large Language Models 2023 [33]\n",
      "9 Unit test case generation Can Large Language Models Write Good Property-Based Tests? 2023 [34]\n",
      "10 Unit test case generation CAT-LM Training Language Models on Aligned Code And Tests 2023 [35]\n",
      "11 Unit test case generation ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation 2023 [8]\n",
      "12 Unit test case generation ChatUniTest: a ChatGPT-based Automated Unit Test Generation Tool 2023 [36]\n",
      "13 Unit test case generation CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models 2023 [37]\n",
      "14 Unit test case generation Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing 2023 [38]\n",
      "15 Unit test case generation Exploring the Effectiveness of Large Language Models in Generating Unit Tests 2023 [39]\n",
      "16 Unit test case generation How Well does LLM Generate Security Tests? 2023 [40]\n",
      "17 Unit test case generation No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation 2023 [7]\n",
      "18 Unit test case generation Prompting Code Interpreter to Write Better Unit Tests on Quixbugs Functions 2023 [41]\n",
      "19 Unit test case generation Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation 2023 [42]\n",
      "20 Unit test case generation Unit Test Generation using Generative AI: A Comparative Performance Analysis of Autogeneration Tools 2023 [43]\n",
      "21 Test oracle generation Generating Accurate Assert Statements for Unit Test Cases Using Pretrained Transformers 2022 [44]\n",
      "22 Test oracle generation Learning Deep Semantics for Test Completion 2023 [45]\n",
      "23 Test oracle generation; Program repairUsing Transfer Learning for Code-Related Tasks 2023 [46]\n",
      "24 Test oracle generation; Program repairRetrieval-Based Prompt Selection for Code-Related Few-Shot Learning 2023 [47]\n",
      "25 System test input generation Automated Conformance Testing for JavaScript Engines via Deep Compiler Fuzzing 2021 [48]\n",
      "26 System test input generation Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing 2022 [49]\n",
      "27 System test input generation Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors 2022 [50]\n",
      "28 System test input generation Slgpt: Using Transfer Learning to Directly Generate Simulink Model Files and Find Bugs in the Simulink Toolchain2021 [51]\n",
      "29 System test input generation Augmenting Greybox Fuzzing with Generative AI 2023 [52]\n",
      "30 System test input generation Automated Test Case Generation Using T5 and GPT-3 2023 [53]\n",
      "31 System test input generation Automating GUI-based Software Testing with GPT-3 2023 [54]\n",
      "32 System test input generation AXNav: Replaying Accessibility Tests from Natural Language 2023 [55]\n",
      "33 System test input generation Can ChatGPT Advance Software Testing Intelligence? An Experience Report on Metamorphic Testing 2023 [56]\n",
      "34 System test input generation Efficient Mutation Testing via Pre-Trained Language Models 2023 [57]\n",
      "35 System test input generation Large Language Models are Edge-Case Generators:Crafting Unusual Programs for Fuzzing Deep Learning Libraries2023 [58]\n",
      "36 System test input generation Large Language Models are Zero Shot Fuzzers: Fuzzing Deep Learning Libraries via Large Language Models2023 [59]\n",
      "37 System test input generation Large Language Models for Fuzzing Parsers (Registered Report) 2023 [60]\n",
      "38 System test input generation LLM for Test Script Generation and Migration: Challenges, Capabilities, and Opportunities 2023 [61]\n",
      "39 System test input generation Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions2023 [14]\n",
      "40 System test input generation PentestGPT: An LLM-empowered Automatic Penetration Testing Tool 2023 [62]\n",
      "41 System test input generation SMT Solver Validation Empowered by Large Pre-Trained Language Models 2023 [63]\n",
      "42 System test input generation TARGET: Automated Scenario Generation from Traffic Rules for Testing Autonomous Vehicles 2023 [64]\n",
      "43 System test input generation Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model2023 [65]\n",
      "44 System test input generation Understanding Large Language Model Based Fuzz Driver Generation 2023 [66]\n",
      "45 System test input generation Universal Fuzzing via Large Language Models 2023 [67]\n",
      "46 System test input generation Variable Discovery with Large Language Models for Metamorphic Testing of Scientific Software 2023 [68]\n",
      "47 System test input generation White-box Compiler Fuzzing Empowered by Large Language Models 2023 [69]\n",
      "48 Bug analysis Itiger: an Automatic Issue Title Generation Tool 2022 [70]\n",
      "49 Bug analysis CrashTranslator: Automatically Reproducing Mobile Application Crashes Directly from Stack Trace 2023 [71]\n",
      "50 Bug analysis Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report Detection 2023 [72]\n",
      "51 Bug analysis Employing Deep Learning and Structured Information Retrieval to Answer Clarification Questions on Bug Reports2023 [73]\n",
      "52 Bug analysis Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation 2022 [74]\n",
      "53 Bug analysis Prompting Is All Your Need: Automated Android Bug Replay with Large Language Models 2023 [75]\n",
      "54 Bug analysis Still Confusing for Bug-Component Triaging? Deep Feature Learning and Ensemble Setting to Rescue 2023 [76]\n",
      "55 Debug Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5 2022 [77]\n",
      "56 Debug Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction 2022 [78]\n",
      "57 Debug A Preliminary Evaluation of LLM-Based Fault Localization 2023 [79]\n",
      "58 Debug Addressing Compiler Errors: Stack Overflow or Large Language Models? 2023 [80]\n",
      "59 Debug Can LLMs Demystify Bug Reports? 2023 [81]\n",
      "60 Debug Dcc –help: Generating Context-Aware Compiler Error Explanations with Large Language Models 2023 [82]\n",
      "61 Debug Explainable Automated Debugging via Large Language Model-driven Scientific Debugging 2023 [83]\n",
      "62 Debug Large Language Models for Test-Free Fault Localization 2023 [84]\n",
      "63 Debug Large Language Models in Fault Localisation 2023 [85]\n",
      "64 Debug LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation 2023 [86]\n",
      "65 Debug Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting 2023 [87]\n",
      "66 Debug Teaching Large Language Models to Self-Debug 2023 [88]\n",
      "67 Debug; Program repair A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair 2023 [89]\n",
      "68 Program repair Examining Zero-Shot Vulnerability Repair with Large Language Models 2022 [90]\n",
      "69 Program repair Automated Repair of Programs from Large Language Models 2022 [91]\n",
      "70 Program repair Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar 2022 [92]\n",
      "71 Program repair Practical Program Repair in the Era of Large Pre-trained Language Models 2022 [93]\n",
      "72 Program repair Repairing Bugs in Python Assignments Using Large Language Models 2022 [94]\n",
      "73 Program repair Towards JavaScript Program Repair with Generative Pre-trained Transformer (GPT-2) 2022 [95]\n",
      "74 Program repair An Analysis of the Automatic Bug Fixing Performance of ChatGPT 2023 [96]\n",
      "75 Program repair An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair 2023 [97]\n",
      "76 Program repair An Evaluation of the Effectiveness of OpenAI’s ChatGPT for Automated Python Program Bug Fixing using QuixBugs2023 [98]\n",
      "77 Program repair An Extensive Study on Model Architecture and Program Representation in the Domain of Learning-based Automated Program Repair2023 [99]\n",
      "78 Program repair Can OpenAI’s Codex Fix Bugs? An Evaluation on QuixBugs 2022 [100]\n",
      "79 Program repair CIRCLE: Continual Repair Across Programming Languages 2022 [101]\n",
      "80 Program repair Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback 2023 [102]\n",
      "81 Program repair Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair2023 [103]\n",
      "82 Program repair Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors 2023 [104]\n",
      "83 Program repair Enhancing Genetic Improvement Mutations Using Large Language Models 2023 [105]\n",
      "84 Program repair FixEval: Execution-based Evaluation of Program Fixes for Programming Problems 2023 [106]\n",
      "85 Program repair Fixing Hardware Security Bugs with Large Language Models 2023 [107]\n",
      "86 Program repair Fixing Rust Compilation Errors using LLMs 2023 [108]\n",
      "87 Program repair Framing Program Repair as Code Completion 2022 [109]\n",
      "88 Program repair Frustrated with Code Quality Issues? LLMs can Help! 2023 [110]\n",
      "89 Program repair GPT-3-Powered Type Error Debugging: Investigating the Use of Large Language Models for Code Repair 2023 [111]\n",
      "90 Program repair How Effective Are Neural Networks for Fixing Security Vulnerabilities 2023 [112]\n",
      "91 Program repair Impact of Code Language Models on Automated Program Repair 2023 [113]\n",
      "92 Program repair Inferfix: End-to-end Program Repair with LLMs 2023 [114]\n",
      "93 Program repair Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT 2023 [115]\n",
      "94 Program repair Neural Program Repair with Program Dependence Analysis and Effective Filter Mechanism 2023 [116]\n",
      "95 Program repair Out of Context: How important is Local Context in Neural Program Repair? 2023 [117]\n",
      "96 Program repair Pre-trained Model-based Automated Software Vulnerability Repair: How Far are We? 2023 [118]\n",
      "97 Program repair RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot 2023 [119]\n",
      "98 Program repair RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic Program Repair 2023 [120]\n",
      "99 Program repair STEAM: Simulating the InTeractive BEhavior of ProgrAMmers for Automatic Bug Fixing 2023 [121]\n",
      "100 Program repair Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions 2023 [122]\n",
      "101 Program repair VulRepair: a T5-based Automated Software Vulnerability Repair 2022 [123]\n",
      "102 Program repair What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs? 2023 [124]6\n",
      "TABLE 2: Conference proceedings and journals considered\n",
      "for manual search\n",
      "Acronym Venue\n",
      "SE Conference\n",
      "ICSE International Conference on Software EngineeringESEC/FSE Joint European Software Engineering Conference and Symposium on theFoundations of Software EngineeringASE International Conference on Automated Software EngineeringISSTA International Symposium on Software Testing and AnalysisICST International Conference on Software Testing, Verification and ValidationESEM International Symposium on Empirical Software Engineering and Mea-surementMSR International Conference on Mining Software RepositoriesQRS International Conference on Software Quality, Reliability and SecurityICSME International Conference on Software Maintenance and EvolutionISSRE International Symposium on Software Reliability Engineering\n",
      "SE Journal\n",
      "TSE Transactions on Software EngineeringTOSEM Transactions on Software Engineering and MethodologyEMSE Empirical Software EngineeringASE Automated Software EngineeringJSS Journal of Systems and SoftwareJSEP Journal of Software: Evolution and ProcessSTVR Software Testing, Verification and ReliabilityIEEE SOFTW. IEEE SoftwareIET SOFTW. IET SoftwareIST Information and Software TechnologySQJ Software Quality Journal\n",
      "AI Venues\n",
      "ICLR International Conference on Learning RepresentationsNeurIPS Conference on Neural Information Processing SystemsICML International Conference on Machine LearningAAAI AAAI Conference on Artificial IntelligenceEMNLP Conference on Empirical Methods in Natural Language ProcessingACL Annual Meeting of the Association for Computational LinguisticsIJCAI International Joint Conference on Artificial Intelligence\n",
      "should be included based on the inclusion criteria and exclu-\n",
      "sion criteria, and any paper with different decisions will be\n",
      "handed over to the third author to make the final decision.\n",
      "3.1.4 Quality Assessment\n",
      "In addition, we establish quality assessment criteria to ex-\n",
      "clude low-quality studies as shown below. For each ques-\n",
      "tion, the study’s quality is rated as “yes”, “partial” or “no”\n",
      "which are assigned values of 1, 0.5, and 0, respectively. Pa-\n",
      "pers with a score of less than eight will be excluded from\n",
      "our study.\n",
      "● Is there a clearly stated research goal related to software\n",
      "testing?\n",
      "● Is there a defined and repeatable technique?\n",
      "● Is there any explicit contribution to software testing?\n",
      "● Is there an explicit description of which LLMs are uti-\n",
      "lized?\n",
      "● Is there an explicit explanation about how the LLMs are\n",
      "utilized?\n",
      "● Is there a clear methodology for validating the tech-\n",
      "nique?\n",
      "● Are the subject projects selected for validation suitable\n",
      "for the research goals?\n",
      "● Are there control techniques or baselines to demon-\n",
      "strate the effectiveness of the proposed technique?\n",
      "● Are the evaluation metrics relevant (e.g., evaluate the\n",
      "effectiveness of the proposed technique) to the research\n",
      "objectives?\n",
      "● Do the results presented in the study align with the\n",
      "research objectives and are they presented in a clear\n",
      "and relevant manner?\n",
      "3.1.5 Snowballing\n",
      "At the end of searching database repositories and confer-\n",
      "ence proceedings and journals, and applying inclusion/ex-\n",
      "clusion criteria and quality assessment, we obtain the initial\n",
      "set of papers. Next, to mitigate the risk of omitting rele-\n",
      "vant literature from this survey, we also perform backward\n",
      "/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000014/uni00000015/uni00000013/uni00000015/uni00000015/uni00000015/uni00000013/uni00000015/uni00000016/uni00000003\n",
      "/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000003c/uni00000048/uni00000044/uni00000055\n",
      "/uni00000013\n",
      "/uni00000018/uni00000013\n",
      "/uni00000014/uni00000013/uni00000013\n",
      "/uni00000014/uni00000018/uni00000013\n",
      "/uni00000015/uni00000013/uni00000013/uni00000006/uni00000003/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\n",
      "/uni00000014/uni00000015\n",
      "/uni00000014/uni0000001c\n",
      "/uni0000001b/uni00000015\n",
      "Fig. 3: Trend in the number of papers with year\n",
      "snowballing [131] by inspecting the references cited by the\n",
      "collected papers so far. Note that, this procedure did not in-\n",
      "clude new studies, which might because the surveyed topic\n",
      "is quite new and the reference studies tend to published pre-\n",
      "viously, and we already include a relatively comprehensive\n",
      "automatic and manual search.\n",
      "3.2 Collection Results\n",
      "As shown in Figure 2, the collection process started\n",
      "with a total of 14,623 papers retrieved from four\n",
      "academic databases employing keyword searching.\n",
      "Then after automated filtering, manual search, applying\n",
      "inclusion/exclusion criteria, and quality assessment, we\n",
      "finally collected a total of 102 papers involving software\n",
      "testing with LLMs. Table 1 shows the details of the collected\n",
      "papers. Besides, we also use Table 5 (at the end of the\n",
      "paper) to provide a more comprehensive overview of these\n",
      "papers regarding the specific characteristics which will be\n",
      "illustrated in Section 4 and Section 5.\n",
      "Note that, there are two studies which are respectively\n",
      "the extension of a previously published paper by the same\n",
      "authors ( [46] and [132], [68] and [133]), and we only keep\n",
      "the extended version to avoid duplicate.\n",
      "3.3 General Overview of Collected Paper\n",
      "Among the papers, 47% papers are published in software\n",
      "engineering venues, among which 19 papers are from ICSE,\n",
      "5 papers are from FSE, 5 papers are from ASE, and 3 pa-\n",
      "pers are from ISSTA. 2% papers are published in artificial\n",
      "intelligence venues such as EMNLP and ICLR, and 5% pa-\n",
      "pers are published in program analysis or security venues\n",
      "like PLDI and S&P . Besides, 46% of the papers have not\n",
      "yet been published via peer-reviewed venues, i.e., they are\n",
      "disclosed on arXiv. This is understandable because this field\n",
      "is emerging and many works are just completed and in\n",
      "the process of submission. Although these papers did not\n",
      "undergo peer review, we have a quality assessment process\n",
      "that eliminates papers with low quality, which potentially\n",
      "ensures the quality of this survey.\n",
      "Figure 3 demonstrates the trend of our collected papers\n",
      "per year. We can see that as the years go by, the number of\n",
      "papers in this field is growing almost exponentially. In 2020\n",
      "and 2021, there were only 1 and 2 papers, respectively. In\n",
      "2022, there were 19 papers, and in 2023, there have been 827\n",
      "Fig. 4: Distribution of testing tasks with LLMs (aligned with software testing life cycle [134]–[136], the number in bracket\n",
      "indicates the number of collected studies per task, and one paper might involve multiple tasks)\n",
      "papers. It is conceivable that there will be even more papers\n",
      "in the future, which indicates the popularity and attention\n",
      "that this field is receiving.\n",
      "4 A NALYSIS FROM SOFTWARE TESTING PER-\n",
      "SPECTIVE\n",
      "This section presents our analysis from the viewpoint of\n",
      "software testing and organizes the collected studies in terms\n",
      "of testing tasks. Figure 4 lists the distribution of each in-\n",
      "volved testing task, aligned with the software testing life\n",
      "cycle. We first provide a general overview of the distribu-\n",
      "tion, followed by further analysis for each task. Note that,\n",
      "for each following subsection, the cumulative total of sub-\n",
      "categories may not always match the total number of papers\n",
      "since a paper might belong to more than one subcategory.\n",
      "We can see that LLMs have been effectively used in both\n",
      "the mid to late stages of the software testing lifecycle. In\n",
      "the test case preparation phase, LLMs have been utilized for\n",
      "tasks such as generating unit test cases, test oracle genera-\n",
      "tion, and system test input generation. These tasks are cru-\n",
      "cial in the mid-phase of software testing to help catch issues\n",
      "and prevent further development until issues are resolved.\n",
      "Furthermore, in later phases such as the test report/bug re-\n",
      "ports and bug fix phase, LLMs have been employed for tasks\n",
      "such as bug analysis, debugging, and repair. These tasks are\n",
      "critical towards the end of the testing phase when software\n",
      "bugs need to be resolved to prepare for the product’s release.\n",
      "4.1 Unit Test Case Generation\n",
      "Unit test case generation involves writing unit test cases to\n",
      "check individual units/components of the software inde-\n",
      "pendently and ensure that they work correctly. For a method\n",
      "under test (i.e., often called the focal method), its corre-\n",
      "sponding unit test consists of a test prefix and a test oracle.\n",
      "In particular, the test prefix is typically a series of method\n",
      "invocation statements or assignment statements, which aims\n",
      "at driving the focal method to a testable state; and then the\n",
      "test oracle serves as the specification to check whether the\n",
      "current behavior of the focal method satisfies the expected\n",
      "one, e.g., the test assertion.\n",
      "To alleviate manual efforts in writing unit tests,\n",
      "researchers have proposed various techniques to facilitate\n",
      "automated unit test generation. Traditional unit test\n",
      "generation techniques leverage search-based [3], [4],\n",
      "constraint-based [5] or random-based strategies [6] to\n",
      "generate a suite of unit tests with the main goal of\n",
      "maximizing the coverage in the software under test.\n",
      "Nevertheless, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory.\n",
      "Since LLMs have demonstrated promising results in\n",
      "tasks such as code generation, and given that both code\n",
      "generation and unit test case generation involve generating\n",
      "source code, recent research has extended the domain of\n",
      "code generation to encompass unit test case generation.\n",
      "Despite initial success, there are nuances that set unit\n",
      "test case generation apart from general code generation,\n",
      "signaling the need for more tailored approaches.\n",
      "Pre-training or fine-tuning LLMs for unit test case\n",
      "generation. Due to the limitations of LLMs in their earlier\n",
      "stages, a majority of the earlier published studies adopt\n",
      "this pre-training or fine-tuning schema. Moreover, in some\n",
      "recent studies, this schema continues to be employed to\n",
      "increase the LLMs’ familiarity with domain knowledge.\n",
      "Alagarsamy et al. [29] first pre-trained the LLM with the\n",
      "focal method and asserted statements to enable the LLM to\n",
      "have a stronger foundation knowledge of assertions, then\n",
      "fine-tuned the LLM for the test case generation task where\n",
      "the objective is to learn the relationship between the focal\n",
      "method and the corresponding test case. Tufano et al. [26]\n",
      "utilized a similar schema by pre-training the LLM on a\n",
      "large unsupervised Java corpus, and supervised fine-tuning\n",
      "a downstream translation task for generating unit tests.\n",
      "Hashtroudi et al. [32] leveraged the existing developer-\n",
      "written tests for each project to generate a project-specific\n",
      "dataset for domain adaptation when fine-tuning the LLM,\n",
      "which can facilitate generating human-readable unit tests.\n",
      "Rao et al. [35] trained a GPT-style language model by\n",
      "utilizing a pre-training signal that explicitly considers the\n",
      "mapping between code and test files. Steenhoek et al.\n",
      "[42] utilizes reinforcement learning to optimize models by\n",
      "providing rewards based on static quality metrics that can\n",
      "be automatically computed for the generated unit test cases.\n",
      "Designing effective prompts for unit test case genera-\n",
      "tion. The advancement of LLMs has allowed them to excel\n",
      "at targeted tasks without pre-training or fine-tuning. There-\n",
      "fore most later studies typically focus on how to design\n",
      "the prompt, to make the LLM better at understanding the\n",
      "context and nuances of this task. Xie et al. [36] generated\n",
      "unit test cases by parsing the project, extracting essential\n",
      "information, and creating an adaptive focal context that in-\n",
      "cludes a focal method and its dependencies within the pre-\n",
      "defined maximum prompt token limit of the LLM, and in-\n",
      "corporating these context into a prompt to query the LLM.8\n",
      "TABLE 3: Performance of unit test case generation\n",
      "Dataset Correctness Coverage LLM Paper\n",
      "5 Java projects from Defects4J 16.21% 5%-13% (line coverage) BART [26]\n",
      "10 Jave projects 40% 89% (line coverage), 90% (branch coverage) ChatGPT [36]\n",
      "CodeSearchNet 41% N/A ChatGPT [7]\n",
      "HumanEval 78% 87% (line coverage), 92% (branch coverage) Codex [39]\n",
      "SF110 2% 2% (line coverage), 1% (branch coverage) Codex [39]\n",
      "Note that, [39] experiments with Codex, CodeGen, and ChatGPT, and the best performance was achieved by Codex.\n",
      "Dakhel et al. [38] introduced MuTAP for improving the ef-\n",
      "fectiveness of test cases generated by LLMs in terms of re-\n",
      "vealing bugs by leveraging mutation testing. They augment\n",
      "prompts with surviving mutants, as those mutants highlight\n",
      "the limitations of test cases in detecting bugs. Zhang et al.\n",
      "[40] generated security tests with vulnerable dependencies\n",
      "with LLMs.\n",
      "Yuan et al. [7] first performed an empirical study to eval-\n",
      "uate ChatGPT’s capability of unit test generation with both\n",
      "a quantitative analysis and a user study in terms of cor-\n",
      "rectness, sufficiency, readability, and usability. And results\n",
      "show that the generated tests still suffer from correctness\n",
      "issues, including diverse compilation errors and execution\n",
      "failures. They further propose an approach that leveraged\n",
      "the ChatGPT itself to improve the quality of its generated\n",
      "tests with an initial test generator and an iterative test re-\n",
      "finer. Specifically, the iterative test refiner iteratively fixed\n",
      "the compilation errors in the tests generated by the initial\n",
      "test generator, which follows a validate-and-fix paradigm to\n",
      "prompt the LLM based on the compilation error messages\n",
      "and additional code context. Guilherme et al. [31] and Li\n",
      "et al. [41] respectively evaluated the quality of the gener-\n",
      "ated unit tests by LLM using different metrics and different\n",
      "prompts.\n",
      "Test generation with additional documentation.\n",
      "Vikram et al. [34] went a step further by investigating the\n",
      "potential of using LLMs to generate property-based tests\n",
      "when provided API documentation. They believe that the\n",
      "documentation of an API method can assist the LLM in\n",
      "producing logic to generate random inputs for that method\n",
      "and deriving meaningful properties of the result to check.\n",
      "Instead of generating unit tests from the source code, Plein\n",
      "et al. [33] generated the tests based on user-written bug\n",
      "reports.\n",
      "LLM and search-based method for unit test generation.\n",
      "The aforementioned studies utilize LLMs for the whole unit\n",
      "test case generation task, while Lemieux et al. [37] focus on\n",
      "a different direction, i.e., first letting the traditional search-\n",
      "based software testing techniques (e.g., Pynguin [137]) in\n",
      "generating unit test case until its coverage improvements\n",
      "stall, then asking the LLM to provide the example test cases\n",
      "for under-covered functions. These examples can help the\n",
      "original test generation redirect its search to more useful\n",
      "areas of the search space.\n",
      "Tang et al. [8] conducts a systematic comparison of test\n",
      "suites generated by the LLM and the state-of-the-art search-\n",
      "based software testing tool EvoSuite, by considering the cor-\n",
      "rectness, readability, code coverage, and bug detection ca-\n",
      "pability. Similarly, Bhatia [43] experimentally investigates\n",
      "the quality of unit tests generated by LLM compared to a\n",
      "commonly-used test generator Pynguin.\n",
      "Performance of unit test case generation. Since the\n",
      "aforementioned studies of unit test case generation are\n",
      "based on different datasets, one can hardly derive a fair\n",
      "comparison and we present the details in Table 3 to let\n",
      "the readers obtain a general view. We can see that in the\n",
      "SF110 benchmark, all three evaluated LLMs have quite low\n",
      "performance, i.e., 2% coverage [39]. SF110 is an Evosuite\n",
      "(a search-based unit test case generation technique)\n",
      "benchmark consisting of 111 open-source Java projects\n",
      "retrieved from SourceForge, containing 23,886 classes, over\n",
      "800,000 bytecode-level branches, and 6.6 million lines of\n",
      "code. The authors did not present detailed reasons for the\n",
      "low performance which can be further explored in the\n",
      "future.\n",
      "4.2 Test Oracle Generation\n",
      "A test oracle is a source of information about whether the\n",
      "output of a software system (or program or function or\n",
      "method) is correct or not [138]. Most of the collected studies\n",
      "in this category target the test assertion generation, which is\n",
      "inside a unit test case. Nevertheless, we opted to treat these\n",
      "studies as separate sections to facilitate a more thorough\n",
      "analysis.\n",
      "Test assertion, which is to indicate the potential issues\n",
      "in the tested code, is an important aspect that can distin-\n",
      "guish the unit test cases from the regular code. This is why\n",
      "some studies specifically focus on the generation of effec-\n",
      "tive test assertions. Actually, before using LLMs, researchers\n",
      "have proposed RNN-based approaches that aim at learning\n",
      "from thousands of unit test methods to generate meaning-\n",
      "ful assert statements [139], yet only 17% of the generated\n",
      "asserts can exactly match with the ground truth asserts. Sub-\n",
      "sequently, to improve the performance, several researchers\n",
      "utilized the LLMs for this task.\n",
      "Mastropaolo et al. [46], [132] pre-trained a T5 model on\n",
      "a dataset composed of natural language English text and\n",
      "source code. Then, it fine-tuned such a model by reusing\n",
      "datasets used in four previous works that used deep learn-\n",
      "ing techniques (such as RNN as mentioned before) includ-\n",
      "ing test assertion generation and program repair, etc. Results\n",
      "showed that the extract match rate of the generated test\n",
      "assertion is 57%. Tufano et al. [44] proposed a similar ap-\n",
      "proach which separately pre-trained the LLM with English\n",
      "corpus and code corpus, and then fine-tuned it on the asserts\n",
      "dataset (with test methods, focal methods, and asserts). This\n",
      "further improved the performance to 62% of the exact match\n",
      "rate. Besides the syntax-level data as previous studies, Nie et\n",
      "al. [45] fine-tuned the LLMs with six kinds of code semantics\n",
      "data, including the execution result (e.g., types of the local\n",
      "variables) and execution context (e.g., the last called method\n",
      "in the test method), which enabled LLMs to learn to under-\n",
      "stand the code execution information. The exact match rate9\n",
      "is 17% (note that this paper is based on a different dataset\n",
      "from all other studies mentioned under this topic).\n",
      "The aforementioned studies utilized the pre-training and\n",
      "fine-tuning schema when using LLMs, and with the increas-\n",
      "ingly powerful capabilities of LLMs, they can perform well\n",
      "on specific tasks without these specialized pre-training or\n",
      "fine-tuning datasets. Subsequently, Nashid et al. [47] uti-\n",
      "lized prompt engineering for this task, and proposed a tech-\n",
      "nique for prompt creation that automatically retrieves code\n",
      "demonstrations similar to the task, based on embedding\n",
      "or frequency analysis. They also present evaluations about\n",
      "the few-shot learning with various numbers (e.g., zero-shot,\n",
      "one-shot, or n-shot) and forms (e.g., random vs. systematic,\n",
      "or with vs. without natural language descriptions) of the\n",
      "prompts, to investigate its feasibility on test assertion gen-\n",
      "eration. With only a few relevant code demonstrations, this\n",
      "approach can achieve an accuracy of 76% for exact matches\n",
      "in test assertion generation, which is the state-of-the-art per-\n",
      "formance for this task.\n",
      "4.3 System Test Input Generation\n",
      "This category encompasses the studies related to creating\n",
      "test input of system testing for enabling the automation of\n",
      "test execution. We employ three subsections to present the\n",
      "analysis from three different orthogonal viewpoints, and\n",
      "each of the collected studies may be analyzed in one or\n",
      "more of these subsections.\n",
      "The first subsection is input generation in terms of software\n",
      "types. The generation of system-level test inputs for software\n",
      "testing varies for specific types of software being tested. For\n",
      "example, for mobile applications, the test input generation\n",
      "requires providing a diverse range of text inputs or oper-\n",
      "ation combinations (e.g., click a button, long press a list)\n",
      "[14], [49], which is the key to testing the application’s func-\n",
      "tionality and user interface; while for Deep Learning (DL)\n",
      "libraries, the test input is a program which covers diversified\n",
      "DL APIs [58], [59]. This subsection will demonstrate how the\n",
      "LLMs are utilized to generate inputs for different types of\n",
      "software.\n",
      "The second subsection input generation in terms of testing\n",
      "techniques. We have observed that certain approaches serve\n",
      "as specific types of testing techniques. For example, dozens\n",
      "of our collected studies specifically focus on using LLMs\n",
      "for fuzz testing. Therefore, this subsection would provide\n",
      "an analysis of the collected studies in terms of testing tech-\n",
      "niques, showcasing how the LLMs are employed to enhance\n",
      "traditional testing techniques.\n",
      "The third subsection input generation in terms of input and\n",
      "output. While most of the collected studies take the source\n",
      "code or the software itself as the input and directly output\n",
      "the software’s test input, there are studies that utilize alter-\n",
      "native forms of input and output. This subsection would\n",
      "provide an analysis of such studies, highlighting different\n",
      "approaches and their input-output characteristics.\n",
      "4.3.1 Input Generation in Terms of Software Types\n",
      "Figure 5 demonstrates the types of software under test in\n",
      "our collected studies. It is evident that the most prominent\n",
      "category is mobile apps, with five studies utilizing LLMs\n",
      "for testing, possibly due to their prevalence and importance\n",
      "/uni00000013/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000030/uni00000052/uni00000045/uni0000004c/uni0000004f/uni00000048/uni00000003/uni00000044/uni00000053/uni00000053\n",
      "/uni00000027/uni00000048/uni00000048/uni00000053/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004f/uni0000004c/uni00000045/uni00000055/uni00000044/uni00000055/uni0000005c\n",
      "/uni00000026/uni00000052/uni00000050/uni00000053/uni0000004c/uni0000004f/uni00000048/uni00000055\n",
      "/uni00000036/uni00000030/uni00000037/uni00000003/uni00000056/uni00000052/uni0000004f/uni00000059/uni00000048/uni00000055\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000051/uni00000052/uni00000050/uni00000052/uni00000058/uni00000056/uni00000003/uni00000047/uni00000055/uni0000004c/uni00000059/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni00000026/uni0000005c/uni00000045/uni00000048/uni00000055/uni00000003/uni00000053/uni0000004b/uni0000005c/uni00000056/uni0000004c/uni00000046/uni00000044/uni0000004f/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni0000002a/uni00000032/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051\n",
      "/uni0000002d/uni00000044/uni00000059/uni00000044/uni00000036/uni00000046/uni00000055/uni0000004c/uni00000053/uni00000057/uni00000003/uni00000048/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048\n",
      "/uni00000034/uni00000058/uni00000044/uni00000051/uni00000057/uni00000058/uni00000050/uni00000003/uni00000046/uni00000052/uni00000050/uni00000053/uni00000058/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000049/uni00000052/uni00000055/uni00000050\n",
      "/uni00000039/uni0000004c/uni00000047/uni00000048/uni00000052/uni00000003/uni0000004a/uni00000044/uni00000050/uni00000048\n",
      "/uni00000036/uni00000052/uni00000049/uni00000057/uni0000005a/uni00000044/uni00000055/uni00000048/uni00000003/uni00000038/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000037/uni00000048/uni00000056/uni00000057\n",
      "/uni00000018\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "Fig. 5: Distribution of software under test\n",
      "in today’s business and daily life. Additionally, there are\n",
      "respectively two studies focusing on testing deep learning\n",
      "libraries, compilers, and SMT solvers. Moreover, LLM-based\n",
      "testing techniques have also been applied to domains such\n",
      "as cyber-physical systems, quantum computing platforms,\n",
      "and more. This widespread adoption of LLMs demonstrates\n",
      "their effectiveness in handling diverse test inputs and en-\n",
      "hancing testing activities across various software domains.\n",
      "A detailed analysis is provided below.\n",
      "Test input generation for mobile apps. For mobile app\n",
      "testing, one difficulty is to generate the appropriate text in-\n",
      "puts to proceed to the next page, which remains a prominent\n",
      "obstacle for testing coverage. Considering the diversity and\n",
      "semantic requirement of valid inputs (e.g., flight departure,\n",
      "movie name), traditional techniques with heuristic-based or\n",
      "constraint-based techniques [10], [140] are far from generat-\n",
      "ing meaningful text input. Liu et al. [49] employ the LLM\n",
      "to intelligently generate the semantic input text according\n",
      "to the GUI context. In detail, their proposed QTypist auto-\n",
      "matically extracts the component information related to the\n",
      "EditText for generating the prompts, and then inputs the\n",
      "prompts into the LLM to generate the input text.\n",
      "Besides the text input, there are other forms of input\n",
      "for mobile apps, i.e., operations like ‘click a button’ and\n",
      "‘select a list’. To fully test an app, it is required to cover\n",
      "more GUI pages and conduct more meaningful exploration\n",
      "traces through the GUI operations, yet existing studies with\n",
      "random-/rule-based methods [9], [10], model-based meth-\n",
      "ods [11], [12], and learning-based methods [13] are unable\n",
      "to understand the semantic information of the GUI page\n",
      "thus could not conduct the trace planning effectively. Liu et\n",
      "al. [14] formulates the test input generation of mobile GUI\n",
      "testing problem as a Q&A task, which asks LLM to chat\n",
      "with the mobile apps by passing the GUI page information\n",
      "to LLM to elicit testing scripts (i.e., GUI operation), and\n",
      "executing them to keep passing the app feedback to LLM, it-\n",
      "erating the whole process. The proposed GPTDroid extracts\n",
      "the static context of the GUI page and the dynamic context\n",
      "of the iterative testing process, and designs prompts for in-\n",
      "putting this information to LLM which enables the LLM to\n",
      "better understand the GUI page as well as the whole testing\n",
      "process. It also introduces a functionality-aware memory\n",
      "prompting mechanism that equips the LLM with the abil-\n",
      "ity to retain testing knowledge of the whole process and\n",
      "conduct long-term, functionality-based reasoning to guide\n",
      "exploration. Similarly, Zimmermann et al. utilize the LLM to10\n",
      "interpret natural language test cases and programmatically\n",
      "navigate through the application under test [54].\n",
      "Yu et al. [61] investigate the LLM’s capabilities in the\n",
      "mobile app test script generation and migration task, in-\n",
      "cluding the scenario-based test generation, and the cross-\n",
      "platform/app test migration.\n",
      "Test input generation for DL libraries. The input for\n",
      "testing DL libraries is DL programs, and the difficulty\n",
      "in generating the diversified input DL programs is that\n",
      "they need to satisfy both the input language (e.g., Python)\n",
      "syntax/semantics and the API input/shape constraints for\n",
      "tensor computations. Traditional techniques with API-level\n",
      "fuzzing [141], [142] or model-level fuzzing [143], [144]\n",
      "suffer from the following limitations: 1) lack of diverse API\n",
      "sequence thus cannot reveal bugs caused by chained API\n",
      "sequences; 2) cannot generate arbitrary code thus cannot\n",
      "explore the huge search space that exists when using the DL\n",
      "libraries. Since LLMs can include numerous code snippets\n",
      "invoking DL library APIs in their training corpora, they\n",
      "can implicitly learn both language syntax/semantics and\n",
      "intricate API constraints for valid DL program generation.\n",
      "Taken in this sense, Deng et al. [59] used both generative\n",
      "and infilling LLMs to generate and mutate valid/diverse\n",
      "input DL programs for fuzzing DL libraries. In detail, it first\n",
      "uses a generative LLM (CodeX) to generate a set of seed\n",
      "programs (i.e., code snippets that use the target DL APIs).\n",
      "Then it replaces part of the seed program with masked\n",
      "tokens using different mutation operators and leverages the\n",
      "ability of infilling LLM (InCoder) to perform code infilling\n",
      "to generate new code that replaces the masked tokens. Their\n",
      "follow-up study [58] goes a step further to prime LLMs to\n",
      "synthesize unusual programs for the fuzzing DL libraries.\n",
      "It is built on the well-known hypothesis that historical\n",
      "bug-triggering programs may include rare/valuable code\n",
      "ingredients important for bug finding and show improved\n",
      "bug detection performance.\n",
      "Test input generation for other types of software.There\n",
      "are also dozens of studies that address testing tasks in vari-\n",
      "ous other domains, due to space limitations, we will present\n",
      "a selection of representative studies in these domains.\n",
      "Finding bugs in a commercial cyber-physical system\n",
      "(CPS) development tool such as Simulink is even more\n",
      "challenging. Given the complexity of the Simulink language,\n",
      "generating valid Simulink model files for testing is an\n",
      "ambitious task for traditional machine learning or deep\n",
      "learning techniques. Shrestha et al. [51] employs a small set\n",
      "of Simulink-specific training data to fine-tune the LLM for\n",
      "generating Simulink models. Results show that it can create\n",
      "Simulink models quite similar to the open-source models,\n",
      "and can find a super-set of the bugs traditional fuzzing\n",
      "approaches found.\n",
      "Sun et al. [63] utilize LLM to generate test formulas for\n",
      "fuzzing SMT solvers. It retrains the LLMs on a large corpus\n",
      "of SMT formulas to enable them to acquire SMT-specific\n",
      "domain knowledge. Then it further fine-tunes the LLMs\n",
      "on historical bug-triggering formulas, which are known\n",
      "to involve structures that are more likely to trigger bugs\n",
      "and solver-specific behaviors. The LLM-based compiler\n",
      "fuzzer proposed by Yang et al. [69] adopts a dual-model\n",
      "framework: (1) an analysis LLM examines the low-level\n",
      "optimization source code and produces requirements on the\n",
      "high-level test programs that can trigger the optimization;\n",
      "(2) a generation LLM produces test programs based on the\n",
      "summarized requirements. Ye et al. [48] utilize the LLM\n",
      "for generating the JavaScript programs and then use the\n",
      "well-structured ECMAScript specifications to automatically\n",
      "generate test data along with the test programs, after that\n",
      "they apply differential testing to expose bugs.\n",
      "4.3.2 Input Generation in Terms of Testing Techniques\n",
      "By utilizing system test inputs generated by LLMs, the col-\n",
      "lected studies aim to enhance traditional testing techniques\n",
      "and make them more effective. Among these techniques,\n",
      "fuzz testing is the most commonly involved one. Fuzz test-\n",
      "ing, as a general concept, revolves around generating in-\n",
      "valid, unexpected, or random data as inputs to evaluate the\n",
      "behavior of software. LLMs play a crucial role in improv-\n",
      "ing traditional fuzz testing by facilitating the generation of\n",
      "diverse and realistic input data. This enables fuzz testing to\n",
      "uncover potential bugs in the software by subjecting it to a\n",
      "wide range of input scenarios. In addition to fuzz testing,\n",
      "LLMs also contribute to enhancing other testing techniques,\n",
      "which will be discussed in detail later.\n",
      "Universal fuzzing framework. Xia et al. [67] present\n",
      "Fuzz4All that can target many different input languages\n",
      "and many different features of these languages. The key\n",
      "idea behind it is to leverage LLMs as an input generation\n",
      "and mutation engine, which enables the approach to\n",
      "produce diverse and realistic inputs for any practically\n",
      "relevant language. To realize this potential, they present\n",
      "a novel auto-prompting technique, which creates LLM\n",
      "prompts that are well-suited for fuzzing, and a novel\n",
      "LLM-powered fuzzing loop, which iteratively updates the\n",
      "prompt to create new fuzzing inputs. They experiment\n",
      "with six different languages (C, C++, Go, SMT2, Java and\n",
      "Python) as inputs and demonstrate higher coverage than\n",
      "existing language-specific fuzzers. Hu et al. [52] propose a\n",
      "greybox fuzzer augmented by the LLM, which picks a seed\n",
      "in the fuzzer’s seed pool and prompts the LLM to produce\n",
      "the mutated seeds that might trigger a new code region\n",
      "of the software. They experiment with three categories of\n",
      "input formats, i.e., formatted data files (e.g., json, xml),\n",
      "source code in different programming languages (e.g., JS,\n",
      "SQL, C), text with no explicit syntax rules (e.g., HTTP\n",
      "response, md5 checksum). In addition, effective fuzzing\n",
      "relies on the effective fuzz driver, and Zhang et al. [66]\n",
      "utilize LLMs on the fuzz driver generation, in which five\n",
      "query strategies are designed and analyzed from basic to\n",
      "enhanced.\n",
      "Fuzzing techniques for specific software. There are\n",
      "studies that focus on the fuzzing techniques tailored to\n",
      "specific software, e.g., the deep learning library [58], [59],\n",
      "compiler [69], SMT solvers [63], input widget of mobile app\n",
      "[65], cyber-physical system [51], etc. One key focus of these\n",
      "fuzzing techniques is to generate diverse test inputs so as\n",
      "to achieve higher coverage. This is commonly achieved\n",
      "by combining the mutation technique with LLM-based\n",
      "generation, where the former produces various candidates\n",
      "while the latter is responsible for generating the executable\n",
      "test inputs [59], [63]. Another focus of these fuzzing\n",
      "techniques is to generate the risky test inputs that can\n",
      "trigger bugs earlier. To achieve this, a common practice is to11\n",
      "collect the historical bug-triggering programs to fine-tune\n",
      "the LLM [63] or treat them as the demonstrations when\n",
      "querying the LLM [58], [65].\n",
      "Other testing techniques. There are studies that utilize\n",
      "LLMs for enhancing GUI testing for generating meaningful\n",
      "text input [49] and functionality-oriented exploration traces\n",
      "[14], which has been introduced in Test input generation for\n",
      "mobile apps part of Section 4.3.1.\n",
      "Besides, Deng et al. [62] leverage the LLMs to carry out\n",
      "penetration testing tasks automatically. It involves setting a\n",
      "penetration testing goal for the LLM, soliciting it for the\n",
      "appropriate operation to execute, implementing it in the\n",
      "testing environment, and feeding the test outputs back to\n",
      "the LLM for next-step reasoning.\n",
      "4.3.3 Input Generation in Terms of Input and Output\n",
      "Other output format of test generation. Although most\n",
      "works use LLM to generate test cases directly, there are also\n",
      "some works generating indirect inputs like testing code, test\n",
      "scenarios, metamorphic relations, etc. Liu et al. [65] pro-\n",
      "pose InputBlaster which leverages the LLM to automati-\n",
      "cally generate unusual text inputs for fuzzing the text input\n",
      "widgets in mobile apps. It formulates the unusual inputs\n",
      "generation problem as a task of producing a set of test gen-\n",
      "erators, each of which can yield a batch of unusual text\n",
      "inputs under the same mutation rule. In detail, InputBlaster\n",
      "leverages LLM to produce the test generators together with\n",
      "the mutation rules serving as the reasoning chain and uti-\n",
      "lizes the in-context learning schema to demonstrate the LLM\n",
      "with examples for boosting the performance. Deng et al.\n",
      "[64] use LLM to extract key information related to the test\n",
      "scenario from a traffic rule, and represent the extracted in-\n",
      "formation in a test scenario schema, then synthesize the\n",
      "corresponding scenario scripts to construct the test scenario.\n",
      "Luu et al. [56] examine the effectiveness of LLM in generat-\n",
      "ing metamorphic relations (MRs) for metamorphic testing.\n",
      "Their results show that ChatGPT can be used to advance\n",
      "software testing intelligence by proposing MRs candidates\n",
      "that can be later adapted for implementing tests, but human\n",
      "intelligence should still inevitably be involved to justify and\n",
      "rectify their correctness.\n",
      "Other input format of test generation. The aforemen-\n",
      "tioned studies primarily take the source code or the software\n",
      "as the input of LLM, yet there are also studies that take\n",
      "natural language description as the input for test generation.\n",
      "Mathur et al. [53] propose to generate test cases from the\n",
      "natural language described requirements. Ackerman et al.\n",
      "[60] generate the instances from natural language described\n",
      "requirements recursively to serve as the seed examples for a\n",
      "mutation fuzzer.\n",
      "4.4 Bug Analysis\n",
      "This category involves analyzing and categorizing the iden-\n",
      "tified software bugs to enhance understanding of the bug,\n",
      "and facilitate subsequent debug and bug repair. Mukher-\n",
      "jee et al. [73] generate relevant answers to follow-up ques-\n",
      "tions for deficient bug reports to facilitate bug triage. Su et\n",
      "al. [76] transform the bug-component triaging into a multi-\n",
      "classification task and a generation task with LLM, then\n",
      "ensemble the prediction results from them to improve the\n",
      "performance of bug-component triaging further. Zhang et\n",
      "al. [72] first leverage the LLM under the zero-shot setting\n",
      "to get essential information on bug reports, then use the\n",
      "essential information as the input to detect duplicate bug re-\n",
      "ports. Mahbub et al. [74] proposes to explain software bugs\n",
      "with LLM, which generates natural language explanations\n",
      "for software bugs by learning from a large corpus of bug-fix\n",
      "commits. Zhang et al. [70] target to automatically generate\n",
      "the bug title from the descriptions of the bug, which aims\n",
      "to help developers write issue titles and facilitate the bug\n",
      "triaging and follow-up fixing process.\n",
      "4.5 Debug\n",
      "This category refers to the process of identifying and locat-\n",
      "ing the cause of a software problem (i.e., bug). It involves\n",
      "analyzing the code, tracing the execution flow, collecting\n",
      "error information to understand the root cause of the issue,\n",
      "and fixing the issue. Some studies concentrate on the com-\n",
      "prehensive debug process, while others delve into specific\n",
      "sub-activities within the process.\n",
      "Overall debug framework. Bui et al. [77] proposes a uni-\n",
      "fied Detect-Localize-Repair framework based on the LLM\n",
      "for debugging, which first determines whether a given code\n",
      "snippet is buggy or not, then identifies the buggy lines, and\n",
      "translates the buggy code to its fixed version. Kang et al.\n",
      "[83] proposes automated scientific debugging, a technique\n",
      "that given buggy code and a bug-revealing test, prompts\n",
      "LLMs to automatically generate hypotheses, uses debuggers\n",
      "to actively interact with buggy code, and thus automati-\n",
      "cally reaches conclusions prior to patch generation. Chen\n",
      "et al. [88] demonstrate that self-debugging can teach the\n",
      "LLM to perform rubber duck debugging; i.e., without any\n",
      "human feedback on the code correctness or error messages,\n",
      "the model is able to identify its mistakes by investigating the\n",
      "execution results and explaining the generated code in nat-\n",
      "ural language. Cao et al. [89] conducts a study of LLM’s de-\n",
      "bugging ability for deep learning programs, including fault\n",
      "detection, fault localization and program repair.\n",
      "Bug localization. Wu et al. [85] compare the two LLMs\n",
      "(ChatGPT and GPT-4) with the existing fault localization\n",
      "techniques, and investigate the consistency of LLMs in fault\n",
      "localization, as well as how prompt engineering and the\n",
      "length of code context affect the results. Kang et al. [79]\n",
      "propose AutoFL, an automated fault localization technique\n",
      "that only requires a single failing test, and during its fault\n",
      "localization process, it also generates an explanation about\n",
      "why the given test fails. Yang et al. [84] propose LLMAO to\n",
      "overcome the left-to-right nature of LLMs by fine-tuning a\n",
      "small set of bidirectional adapter layers on top of the rep-\n",
      "resentations learned by LLMs, which can locate buggy lines\n",
      "of code without any test coverage information. Tu et al. [86]\n",
      "propose LLM4CBI to tame LLMs to generate effective test\n",
      "programs for finding suspicious files.\n",
      "Bug reproduction. There are also studies focusing on a\n",
      "sub-phase of the debugging process. For example, Kang et\n",
      "al. [78] and Plein et al. [81] respectively propose the frame-\n",
      "work to harness the LLM to reproduce bugs, and suggest\n",
      "bug reproducing test cases to the developer for facilitating\n",
      "debugging. Li et al. [87] focus on a similar aspect of finding\n",
      "the failure-inducing test cases whose test input can trigger12\n",
      "the software’s fault. It synergistically combines LLM and\n",
      "differential testing to do that.\n",
      "There are also studies focusing on the bug reproduc-\n",
      "tion of mobile apps to produce the replay script. Feng et\n",
      "al. [75] propose AdbGPT, a new lightweight approach to\n",
      "automatically reproduce the bugs from bug reports through\n",
      "prompt engineering, without any training and hard-coding\n",
      "effort. It leverages few-shot learning and chain-of-thought\n",
      "reasoning to elicit human knowledge and logical reasoning\n",
      "from LLMs to accomplish the bug replay in a manner similar\n",
      "to a developer. Huang et al. [71] propose CrashTranslator to\n",
      "automatically reproduce bugs directly from the stack trace.\n",
      "It accomplishes this by leveraging the LLM to predict the\n",
      "exploration steps for triggering the crash, and designing a\n",
      "reinforcement learning based technique to mitigate the in-\n",
      "accurate prediction and guide the search holistically. Taeb et\n",
      "al. [55] convert the manual accessibility test instructions into\n",
      "replayable, navigable videos by using LLM and UI element\n",
      "detection models, which can also help reveal accessibility\n",
      "issues.\n",
      "Error explanation. Taylor et al. [82] integrates the LLM\n",
      "into the Debugging C Compiler to generate unique, novice-\n",
      "focused explanations tailored to each error. Widjojo et al.\n",
      "[80] study the effectiveness of Stack Overflow and LLMs at\n",
      "explaining compiler errors.\n",
      "4.6 Program Repair\n",
      "This category denotes the task of fixing the identified\n",
      "software bugs. The high frequency of repair-related studies\n",
      "can be attributed to the close relationship between this\n",
      "task and the source code. With their advanced natural\n",
      "language processing and understanding capabilities, LLM\n",
      "are well-equipped to process and analyze source code,\n",
      "making them an ideal tool for performing code-related\n",
      "tasks such as fixing bugs.\n",
      "There have been template-based [145], heuristic-based\n",
      "[146], and constraint-based [147], [148] automatic program\n",
      "repair techniques. And with the development of deep\n",
      "learning techniques in the past few years, there have been\n",
      "several studies employing deep learning techniques for\n",
      "program repair. They typically adopt deep learning models\n",
      "to take a buggy software program as input and generate a\n",
      "patched program. Based on the training data, they would\n",
      "build a neural network model that learns the relations\n",
      "between the buggy code and the corresponding fixed code.\n",
      "Nevertheless, these techniques still fail to fix a large portion\n",
      "of bugs, and they typically have to generate hundreds to\n",
      "thousands of candidate patches and take hours to validate\n",
      "these patches to fix enough bugs. Furthermore, the deep\n",
      "learning based program repair models need to be trained\n",
      "with huge amounts of labeled training data (typically\n",
      "pairs of buggy and fixed code), which is time- and effort-\n",
      "consuming to collect the high-quality dataset. Subsequently,\n",
      "with the popularity and demonstrated capability of the\n",
      "LLMs, researchers begin to explore the LLMs for program\n",
      "repair.\n",
      "Patch single-line bugs. In the early era of program re-\n",
      "pair, the focus was mainly on addressing defects related to\n",
      "single-line code errors, which are relatively simple and did\n",
      "not require the repair of complex program logic. Lajk ´o et\n",
      "al. [95] propose to fine-tune the LLM with JavaScript code\n",
      "snippets to serve as the purpose for the JavaScript program\n",
      "repair. Zhang et al. [116] employs program slicing to extract\n",
      "contextual information directly related to the given buggy\n",
      "statement as repair ingredients from the corresponding pro-\n",
      "gram dependence graph, which makes the fine-tuning more\n",
      "focused on the buggy code. Zhang et al. [121] propose a\n",
      "stage-wise framework STEAM for patching single-line bugs,\n",
      "which simulates the interactive behavior of multiple pro-\n",
      "grammers involved in bug management, e.g., bug reporting,\n",
      "bug diagnosis, patch generation, and patch verification.\n",
      "Since most real-world bugs would involve multiple lines\n",
      "of code, and later studies explore these more complex situa-\n",
      "tions (although some of them can also patch the single-line\n",
      "bugs).\n",
      "Patch multiple-lines bugs. The studies in this category\n",
      "would input a buggy function to the LLM, and the goal is to\n",
      "output the patched function, which might involve complex\n",
      "semantic understanding, code hunk modification, as well\n",
      "as program refactoring. Earlier studies typically employ the\n",
      "fine-tuning strategy to enable the LLM to better understand\n",
      "the code semantics. Fu et al. [123] fine-tune the LLM by\n",
      "employing BPE tokenization to handle Out-Of-Vocabulary\n",
      "(OOV) issues which makes the approach generate new to-\n",
      "kens that never appear in a training function but are newly\n",
      "introduced in the repair. Wang et. al. [120] train the LLM\n",
      "based on both buggy input and retrieved bug-fix examples\n",
      "which are retrieved in terms of the lexical and semantical\n",
      "similarities. The aforementioned studies (including the ones\n",
      "in patching single-line bugs) would predict the fixed pro-\n",
      "grams directly, and Hu et al. [92] utilize a different setup\n",
      "that predicts the scripts that can fix the bugs when executed\n",
      "with the delete and insert grammar. For example, it predicts\n",
      "whether an original line of code should be deleted, and what\n",
      "content should be inserted.\n",
      "Nevertheless, fine-tuning may face limitations in terms\n",
      "of its reliance on abundant high-quality labeled data,\n",
      "significant computational resources, and the possibility of\n",
      "overfitting. To approach the program repair problem more\n",
      "effectively, later studies focus on how to design an effective\n",
      "prompt for program repair. Several studies empirically\n",
      "investigate the effectiveness of prompt variants of the latest\n",
      "LLMs for program repair under different repair settings\n",
      "and commonly-used benchmarks (which will be explored\n",
      "in depth later), while other studies focus on proposing\n",
      "new techniques. Ribeiro et al. [109] take advantage of\n",
      "LLM to conduct the code completion in a buggy line for\n",
      "patch generation, and elaborate on how to circumvent the\n",
      "open-ended nature of code generation to appropriately\n",
      "fit the new code in the original program. Xia et al. [115]\n",
      "propose the conversation-driven program repair approach\n",
      "that interleaves patch generation with instant feedback\n",
      "to perform the repair in a conversational style. They first\n",
      "feed the LLM with relevant test failure information to start\n",
      "with, and then learns from both failures and successes\n",
      "of earlier patching attempts of the same bug for more\n",
      "powerful repair. For earlier patches that failed to pass\n",
      "all tests, they combine the incorrect patches with their\n",
      "corresponding relevant test failure information to construct\n",
      "a new prompt for the LLM to generate the next patch,\n",
      "in order to avoid making the same mistakes. For earlier13\n",
      "TABLE 4: Performance of program repair\n",
      "Dataset % Correct patches LLM Paper\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs,\n",
      "HumanEval-Java\n",
      "22/40 Jave bugs (QuixBugs dataset, with InCoder-6B, correct\n",
      "code infilling setting)\n",
      "PLBART, CodeT5, CodeGen, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 10 LLMs in total)\n",
      "[113]\n",
      "QuixBugs 23/40 Python bugs, 14/40 Java bugs (complete function genera-\n",
      "tion setting)\n",
      "Codex-12B [100]\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs, Many-\n",
      "Bugs\n",
      "39/40 Python bugs, 34/40 Java bugs (QuixBugs dataset, with\n",
      "Codex-12B, correct code infilling setting); 37/40 Python bugs,\n",
      "32/40 Java bugs (QuixBugs dataset, with Codex-12B, complete\n",
      "function generation setting)\n",
      "Codex, GPT-Neo, CodeT5, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 9 LLMs in total)\n",
      "[93]\n",
      "QuixBugs 31/40 Python bugs (completion function generation setting) ChatGPT-175B [96]\n",
      "DL programs from Stack-\n",
      "Overflow\n",
      "16/72 Python bugs (complete function generation setting) ChatGPT-175B [89]\n",
      "Note that, for studies with multiple datasets or LLMs, we only present the best performance or in the most commonly utilized dataset.\n",
      "patches that passed all the tests (i.e., plausible patches),\n",
      "they further ask the LLM to generate alternative variations\n",
      "of the original plausible patches. This can further build on\n",
      "and learn from earlier successes to generate more plausible\n",
      "patches to increase the chance of having correct patches.\n",
      "Zhang et al. [94] propose a similar approach design by\n",
      "leveraging multimodal prompts (e.g., natural language\n",
      "description, error message, input-output-based test cases),\n",
      "iterative querying, test-case-based few-shot selection to\n",
      "produce repairs. Moon et al. [102] propose for bug fixing\n",
      "with feedback. It consists of a critic model to generate\n",
      "feedback, an editor to edit codes based on the feedback,\n",
      "and a feedback selector to choose the best possible feedback\n",
      "from the critic.\n",
      "Wei et. al. [103] propose Repilot to copilot the AI “copi-\n",
      "lots” (i.e., LLMs) by synthesizing more valid patches during\n",
      "the repair process. Its key insight is that many LLMs pro-\n",
      "duce outputs autoregressively (i.e., token by token), and by\n",
      "resembling human writing programs, the repair can be sig-\n",
      "nificantly boosted and guided through a completion engine.\n",
      "Brownlee et al. [105] propose to use the LLM as mutation\n",
      "operators for the search-based techniques of program repair.\n",
      "Repair with static code analyzer. Most of the program\n",
      "repair studies would suppose the bug has been detected,\n",
      "while Jin et al. [114] propose a program repair framework\n",
      "paired with a static analyzer to first detect the bugs, and\n",
      "then fix them. In detail, the static analyzer first detects an\n",
      "error (e.g., null pointer dereference) and the context infor-\n",
      "mation provided by the static analyzer will be sent into the\n",
      "LLM for querying the patch for this specific error. Wadhwa\n",
      "et al. [110] focus on a similar task, and additionally employ\n",
      "an LLM as the ranker to assess the likelihood of acceptance\n",
      "of generated patches which can effectively catch plausible\n",
      "but incorrect fixes and reduce developer burden.\n",
      "Repair for specific bugs. The aforementioned studies\n",
      "all consider the buggy code as the input for the automatic\n",
      "program repair, while other studies conduct program re-\n",
      "pairing in terms of other types of bug descriptions, specific\n",
      "types of bugs, etc. Fakhoury et al. [122] focus on program\n",
      "repair from natural language issue descriptions, i.e., gen-\n",
      "erating the patch with the bug and fix-related information\n",
      "described in the issue reports. Garg et al. [119] aim at re-\n",
      "pairing performance issues, in which they first retrieve a\n",
      "prompt instruction from a pre-constructed knowledge-base\n",
      "of previous performance bug fixes and then generate a re-\n",
      "pair prompt using the retrieved instruction. There are stud-\n",
      "ies focusing on the bug fixing of Rust programs [108] or\n",
      "OCaml programs (an industrial-strength programming lan-\n",
      "guage) [111].\n",
      "Empirical study about program repair.There are several\n",
      "studies related to the empirical or experimental evaluation\n",
      "of the various LLMs on program repair, and we summa-\n",
      "rize the performance in Table 4. Jiang et al. [113], Xia et al.\n",
      "[93], and Zhang et. al. [118] respectively conduct compre-\n",
      "hensive experimental evaluations with various LLMs and\n",
      "on different automated program repair benchmarks, while\n",
      "other researchers [89], [96], [98], [100] focus on a specific\n",
      "LLM and on one dataset, e.g., QuixBugs. In addition, Gao\n",
      "et al. [124] empirically investigate the impact of in-context\n",
      "demonstrations for bug fixing, including the selection, or-\n",
      "der, and number of demonstration examples. Prenner et al.\n",
      "[117] empirically study how the local context (i.e., code that\n",
      "comes before or after the bug location) affects the repair per-\n",
      "formance. Horv ´ath et al. [99] empirically study the impact\n",
      "of program representation and model architecture on the\n",
      "repair performance.\n",
      "There are two commonly-used repair settings when us-\n",
      "ing LLMs to generate patches: 1) complete function gen-\n",
      "eration (i.e., generating the entire patch function), 2) cor-\n",
      "rect code infilling (i.e., filling in a chunk of code given the\n",
      "prefix and suffix), and different studies might utilize differ-\n",
      "ent settings which are marked in Table 4. The commonly-\n",
      "used datasets are QuixBugs, Defects4J, etc. These datasets\n",
      "only involve the fundamental functionalities such as sorting\n",
      "algorithms, each program’s average number of lines rang-\n",
      "ing from 13 to 22, implementing one functionality, and in-\n",
      "volving few dependencies. To tackle this, Cao et al. [89]\n",
      "conducts an empirical study on a more complex dataset\n",
      "with DL programs collected from StackOverflow. Every pro-\n",
      "gram contains about 46 lines of code on average, imple-\n",
      "menting several functionalities including data preprocess-\n",
      "ing, DL model construction, model training, and evaluation.\n",
      "And the dataset involves more than 6 dependencies for each\n",
      "program, including TensorFlow, Keras, and Pytorch. Their\n",
      "results demonstrate a much lower rate of correct patches\n",
      "than in other datasets, which again reveals the potential\n",
      "difficulty of this task. Similarly, Haque et al. [106] introduce\n",
      "a dataset comprising of buggy code submissions and their\n",
      "corresponding fixes collected from online judge platforms,\n",
      "in which it offers an extensive collection of unit tests to\n",
      "enable the evaluations about the correctness of fixes and fur-\n",
      "ther information regarding time, memory constraints, and\n",
      "acceptance based on a verdict.14\n",
      "ChatGPT, 36\n",
      "25%\n",
      "Codex, 23\n",
      "16%\n",
      "CodeT5, 18\n",
      "13% GPT-4, 14\n",
      "10%\n",
      "GPT-3, 7\n",
      "5%\n",
      "CodeGen, 64%\n",
      "InCoder, 54%\n",
      "PLBART, 54%\n",
      "T5, 5\n",
      "4%\n",
      "CodeGPT, 4\n",
      "3%\n",
      "GPT-2, 4\n",
      "3%\n",
      "BART, 3\n",
      "2%\n",
      "StarCoder, 3\n",
      "2%\n",
      "UniXCoder, 2\n",
      "1%\n",
      "Others, 7\n",
      "5%\n",
      "Fig. 6: LLMs used in the collected papers\n",
      "5 A NALYSIS FROM LLM PERSPECTIVE\n",
      "This section discusses the analysis based on the viewpoints\n",
      "of LLM, specifically, it’s unfolded from the viewpoints of\n",
      "utilized LLMs, types of prompt engineering, input of the\n",
      "LLMs, as well as the accompanied techniques when utilizing\n",
      "LLM.\n",
      "5.1 LLM Models\n",
      "As shown in Figure 6, the most commonly utilized LLM\n",
      "in software testing tasks is ChatGPT, which was released\n",
      "on Nov. 2022 by OpenAI. It is trained on a large corpus\n",
      "of natural language text data, and primarily designed for\n",
      "natural language processing and conversation. ChatGPT is\n",
      "the most widely recognized and popular LLM up until now,\n",
      "known for its exceptional performance across various tasks.\n",
      "Therefore, it comes as no surprise that it ranks in the top\n",
      "position in terms of our collected studies.\n",
      "Codex, an LLM based on GPT-3, is the second most com-\n",
      "monly used LLM in our collected studies. It is trained on a\n",
      "massive code corpus containing examples from many pro-\n",
      "gramming languages such as JavaScript, Python, C/C++,\n",
      "and Java. Codex was released on Sep. 2021 by OpenAI and\n",
      "powers GitHub Copilot– an AI pair programmer that gener-\n",
      "ates whole code snippets, given a natural language descrip-\n",
      "tion as a prompt. Since a large portion of our collected stud-\n",
      "ies involve the source code (e.g., repair, unit test case gen-\n",
      "eration), it is not surprising that researchers choose Codex\n",
      "as the LLM in assisting them in accomplishing the coding-\n",
      "related tasks.\n",
      "The third-ranked LLM is CodeT5, which is an open-\n",
      "sourced LLM developed by salesforce 3. Thanks to its open\n",
      "source, researchers can easily conduct the pre-training and\n",
      "fine-tuning with domain-specific data to achieve better\n",
      "performance. Similarly, CodeGen is also open-sourced and\n",
      "ranked relatively higher. Besides, for CodeT5 and CodeGen,\n",
      "there are more than half of the related studies involve the\n",
      "empirical evaluations (which employ multiple LLMs), e.g.,\n",
      "program repair [112], [113], unit test case generation [39].\n",
      "3. https://blog.salesforceairesearch.com/codet5/\n",
      "There are already 14 studies that utilize GPT-4, ranking\n",
      "at the fourth place, which is launched on March 2023. Sev-\n",
      "eral studies directly utilize this state-of-the-art LLM of Ope-\n",
      "nAI, since it demonstrates excellent performance across a\n",
      "wide range of generation and reasoning tasks. For example,\n",
      "Xie et al. utilize GPT-4 to generate fuzzing inputs [67], while\n",
      "Vikram et al. employ it to generate property-based tests with\n",
      "the assistance of API documentation [34]. In addition, some\n",
      "studies conduct experiments using both GPT-4 and Chat-\n",
      "GPT or other LLMs to provide a more comprehensive evalu-\n",
      "ation of these models’ performance. In their proposed LLM-\n",
      "empowered automatic penetration testing technique, Deng\n",
      "et al. find that GPT-4 surpasses ChatGPT and LaMDA from\n",
      "Google [62]. Similarly, Zhang et al. find that GPT-4 shows\n",
      "its performance superiority over ChatGPT when generat-\n",
      "ing the fuzz drivers with both the basic query strategies\n",
      "and enhanced query strategies [66]. Furthermore, GPT-4, as\n",
      "a multi-modal LLM, sets itself apart from the other men-\n",
      "tioned LLMs by showcasing additional capabilities such as\n",
      "generating image narratives and answering questions based\n",
      "on images [149]. Yet we have not come across any studies\n",
      "that explore the utilization of GPT-4’s image-related features\n",
      "(e.g., UI screenshots, programming screencasts) in software\n",
      "testing tasks.\n",
      "5.2 Types of Prompt Engineering\n",
      "As shown in Figure 7, among our collected studies, 38\n",
      "studies utilize the LLMs through pre-training or fine-\n",
      "tuning schema, while 64 studies employ the prompt\n",
      "engineering to communicate with LLMs to steer its\n",
      "behavior for desired outcomes without updating the model\n",
      "weights. When using the early LLMs, their performances\n",
      "might not be as impressive, so researchers often use\n",
      "pre-training or fine-tuning techniques to adjust the models\n",
      "for specific domains and tasks in order to improve their\n",
      "performance. Then with the upgrading of LLM technology,\n",
      "especially with the introduction of GPT-3 and later\n",
      "LLMs, the knowledge contained within the models and\n",
      "their understanding/inference capability has increased\n",
      "significantly. Therefore, researchers will typically rely on\n",
      "prompt engineering to consider how to design appropriate\n",
      "prompts to stimulate the model’s knowledge.\n",
      "Among the 64 studies with prompt engineering, 51 stud-\n",
      "ies involve zero-shot learning, and 25 studies involve few-\n",
      "shot learning (a study may involve multiple types). There\n",
      "are also studies involving the chain-of-though (7 studies),\n",
      "self-consistency (1 study), and automatic prompt (1 study).\n",
      "Zero-shot learning is to simply feed the task text to the\n",
      "model and ask for results. Many of the collected studies em-\n",
      "ploy the Codex, CodeT5, and CodeGen (as shown in Section\n",
      "5.1), which is already trained on source code. Hence, for the\n",
      "tasks dealing with source code like unit test case generation\n",
      "and program repair as demonstrated in previous sections,\n",
      "directly querying the LLM with prompts is the common\n",
      "practice. There are generally two types of manners of zero-\n",
      "shot learning, i.e., with and without instructions. For exam-\n",
      "ple, Xie et al. [36] would provide the LLMs with the instruc-\n",
      "tions as “please help me generate a JUnit test for a specific\n",
      "Java method ...” to facilitate the unit test case generation.\n",
      "In contrast, Siddiq et al. [39] only provide the code header15\n",
      "Fig. 7: Distribution about how LLM is used (Note that, a study can involve multiple types of prompt engineering)\n",
      "of the unit test case (e.g., “class $ {className}${suffix}Test\n",
      "{”), and the LLMs would carry out the unit test case gener-\n",
      "ation automatically. Generally speaking, prompts with clear\n",
      "instructions will yield more accurate results, while prompts\n",
      "without instructions are typically suitable for very specific\n",
      "situations.\n",
      "Few-shot learning presents a set of high-quality demon-\n",
      "strations, each consisting of both input and desired output,\n",
      "on the target task. As the model first sees the examples,\n",
      "it can better understand human intention and criteria for\n",
      "what kinds of answers are wanted, which is especially im-\n",
      "portant for tasks that are not so straightforward or intuitive\n",
      "to the LLM. For example, when conducting the automatic\n",
      "test generation from general bug reports, Kang et al. [78]\n",
      "provide examples of bug reports (questions) and the corre-\n",
      "sponding bug reproducing tests (answers) to the LLM, and\n",
      "their results show that two examples can achieve the highest\n",
      "performance than no examples or other number of exam-\n",
      "ples. Another example of test assertion generation, Nashid\n",
      "et al. [47] provide demonstrations of the focal method, the\n",
      "test method containing an <AssertPlaceholder>, and the ex-\n",
      "pected assertion, which enables the LLMs to better under-\n",
      "stand the task.\n",
      "Chain-of-thought (CoT) prompting generates a\n",
      "sequence of short sentences to describe reasoning logics\n",
      "step by step (also known as reasoning chains or rationales)\n",
      "to the LLMs for generating the final answer. For example,\n",
      "for program repair from the natural language issue\n",
      "descriptions [122], given the buggy code and issue report,\n",
      "the authors first ask the LLM to localize the bug, and then\n",
      "they ask it to explain why the localized lines are buggy,\n",
      "finally, they ask the LLM to fix the bug. Another example is\n",
      "for generating unusual programs for fuzzing deep learning\n",
      "libraries, Deng et al. [58] first generate a possible “bug” (bug\n",
      "description) before generating the actual “bug-triggering”\n",
      "code snippet that invokes the target API. The predicted\n",
      "bug description provides an additional hint to the LLM,\n",
      "indicating that the generated code should try to cover\n",
      "specific potential buggy behavior.\n",
      "Self-consistency involves evaluating the coherence and\n",
      "consistency of the LLM’s responses on the same input in\n",
      "different contexts. There is one study with this prompt\n",
      "type, and it is about debugging. Kang et al. [83] employ a\n",
      "hypothesize-observe-conclude loop, which first generates\n",
      "a hypothesis about what the bug is and constructs an\n",
      "experiment to verify, using an LLM, then decide whether\n",
      "the hypothesis is correct based on the experiment result\n",
      "(with a debugger or code execution) using an LLM, after\n",
      "that, depending on the conclusion, it either starts with a\n",
      "new hypothesis or opts to terminate the debugging process\n",
      "and generate a fix.\n",
      "Automatic prompt aims to automatically generate and\n",
      "select the appropriate instruction for the LLMs, instead of\n",
      "requiring the user to manually engineer a prompt. Xia et\n",
      "al. [67] introduce an auto-prompting step that automatically\n",
      "distils all user-provided inputs into a concise and effective\n",
      "prompt for fuzzing. Specifically, they first generate a list of\n",
      "candidate prompts by incorporating the user inputs and\n",
      "auto prompting instruction while setting the LLM at high\n",
      "temperature, then a small-scale fuzzing experiment is con-\n",
      "ducted to evaluate each candidate prompt, and the best one\n",
      "is selected.\n",
      "Note that there are fourteen studies that apply the it-\n",
      "erative prompt design when using zero-shot or few-shot\n",
      "learning, in which the approach continuously refines the\n",
      "prompts with the running information of the testing task,\n",
      "e.g., the test failure information. For example, for program\n",
      "repair, Xia et al. [115] interleave patch generation with test\n",
      "validation feedback to prompt future generation iteratively.\n",
      "In detail, they incorporate various information from a failing\n",
      "test including its name, the relevant code line(s) triggering\n",
      "the test failure, and the error message produced in the next\n",
      "round of prompting which can help the model understand\n",
      "the failure reason and provide guidance towards generating\n",
      "the correct fix. Another example is for mobile GUI testing,\n",
      "Liu et al. [14] iteratively query the LLM about the operation\n",
      "(e.g., click a button, enter a text) to be conducted in the\n",
      "mobile app, and at each iteration, they would provide the\n",
      "LLM with current context information like which GUI pages\n",
      "and widgets have just explored.\n",
      "Mapping between testing tasks and how LLMs are\n",
      "used. Figure 8 demonstrates the mapping between the test-\n",
      "ing tasks (mentioned in Section 4) and how LLMs are used\n",
      "(as introduced in this subsection). The unit test case gen-\n",
      "eration and program repair share similar patterns of com-\n",
      "municating with the LLMs, since both tasks are closely re-\n",
      "lated to the source code. Typically, researchers utilize pre-\n",
      "training and/or fine-tuning and zero-shot learning methods\n",
      "for these two tasks. Zero-shot learning is suitable because\n",
      "these tasks are relatively straightforward and can be easily\n",
      "understood by LLMs. Moreover, since the training data for\n",
      "these two tasks can be automatically collected from source\n",
      "code repositories, pre-training and/or fine-tuning methods16\n",
      "Fig. 8: Mapping between testing tasks and how LLMs are\n",
      "used\n",
      "Code, 78\n",
      "68%\n",
      "Bug description, 1210%\n",
      "Error information, 7\n",
      "6%\n",
      "View hierarchy file of UI, 6\n",
      "5%\n",
      "Others, 12\n",
      "10%\n",
      "Fig. 9: Input of LLM\n",
      "are widely employed for these two tasks, which can enhance\n",
      "LLMs’ understanding of domain-specific knowledge.\n",
      "In comparison, for system test input generation, zero-\n",
      "shot learning and few-shot learning methods are commonly\n",
      "used. This might be because this task often involves gener-\n",
      "ating specific types of inputs, and demonstrations in few-\n",
      "shot learning can assist the LLMs in better understanding\n",
      "what should be generated. Besides, for this task, the uti-\n",
      "lization of pre-training and/or fine-tuning methods are not\n",
      "as widespread as in unit test case generation and program\n",
      "repair. This might be attributed to the fact that training data\n",
      "for system testing varies across different software and is\n",
      "relatively challenging to collect automatically.\n",
      "5.3 Input of LLM\n",
      "We also find that different testing tasks or software under\n",
      "test might involve diversified input when querying the\n",
      "LLM, as demonstrated in Figure 9.\n",
      "The most commonly utilized input is the source code\n",
      "since a large portion of collected studies relate to program\n",
      "repair or unit test case generation whose input are source\n",
      "code. For unit test case generation, typical code-related in-\n",
      "formation would be (i) the complete focal method, including\n",
      "the signature and body; (ii) the name of the focal class (i.e.,\n",
      "the class that the focal method belongs to); (iii) the field in\n",
      "the focal class; and (iv) the signatures of all methods defined\n",
      "in the focal class [7], [26]. For program repair, there can be\n",
      "different setups and involve different inputs, including (i)\n",
      "inputting a buggy function with the goal of outputting the\n",
      "patched function, (ii) inputting the buggy location with the\n",
      "goal of generating the correct replacement code (can be a\n",
      "single line change) given the prefix and suffix of the buggy\n",
      "function [93]. Besides, there can be variations for the buggy\n",
      "location input, i.e., (i) does not contain the buggy lines (but\n",
      "the bug location is still known), (ii) give the buggy lines as\n",
      "lines of comments.\n",
      "There are also 12 studies taking the bug description as\n",
      "input for the LLM. For example, Kang et al. [78] take the\n",
      "bug description as input when querying LLM and let the\n",
      "LLM generate the bug-reproducing test cases. Fakhoury et\n",
      "al. [122] input the natural language descriptions of bugs to\n",
      "the LLM, and generate the correct code fixes.\n",
      "There are 7 studies that would provide the intermedi-\n",
      "ate error information , e.g., test failure information, to the\n",
      "LLM, and would conduct the iterative prompt (as described\n",
      "in Section 5.2) to enrich the context provided to the LLM.\n",
      "These studies are related to the unit test case generation\n",
      "and program repair, since in these scenarios, the running\n",
      "information can be acquired easily.\n",
      "When testing mobile apps, since the utilized LLM could\n",
      "not understand the image of the GUI page, the view hierar-\n",
      "chy file which represents the details of the GUI page usually\n",
      "acts as the input to LLMs. Nevertheless, with the emergence\n",
      "of GPT-4 which is a multimodal model and accepts both\n",
      "image and text inputs for model input, the GUI screenshots\n",
      "might be directly utilized for LLM’s input.\n",
      "5.4 Incorporating Other Techniques with LLM\n",
      "There are divided opinions on whether LLM has reached\n",
      "an all-powerful status that requires no other techniques. As\n",
      "shown in Figure 10, among our collected studies, 67 of them\n",
      "utilize LLMs to address the entire testing task, while 35 stud-\n",
      "ies incorporate additional techniques. These techniques in-\n",
      "clude mutation testing, differential testing, syntactic check-\n",
      "ing, program analysis, statistical analysis, etc. .\n",
      "The reason why researchers still choose to combine\n",
      "LLMs with other techniques might be because, despite\n",
      "exhibiting enormous potential in various tasks, LLMs still\n",
      "possess limitations such as comprehending code semantics\n",
      "and handling complex program structures. Therefore,\n",
      "combining LLMs with other techniques optimizes their\n",
      "strengths and weaknesses to achieve better outcomes in\n",
      "specific scenarios. In addition, it is important to note that\n",
      "while LLMs are capable of generating correct code, they\n",
      "may not necessarily produce sufficient test cases to check\n",
      "for edge cases or rare scenarios. This is where mutation\n",
      "and other testing techniques come into play, as they allow\n",
      "for the generation of more diverse and complex code that\n",
      "can better simulate real-world scenarios. Taken in this\n",
      "sense, a testing approach can incorporate a combination\n",
      "of different techniques, including both LLMs and other\n",
      "testing strategies, to ensure comprehensive coverage and\n",
      "effectiveness.\n",
      "LLM + statistical analysis. As LLMs can often generate\n",
      "a multitude of outputs, manually sifting through and iden-\n",
      "tifying the correct output can be overwhelmingly laborious.\n",
      "As such, researchers have turned to statistical analysis tech-\n",
      "niques like ranking and clustering [28], [45], [78], [93], [116]17\n",
      "Fig. 10: Distribution about other techniques incorporated with LLMs (Note that, a study can involve multiple types)\n",
      "to efficiently filter through LLM’s outputs and ultimately\n",
      "obtain more accurate results.\n",
      "LLM + program analysis. When utilizing LLMs to\n",
      "accomplish tasks such as generating unit test cases and\n",
      "repairing software code, it is important to consider that\n",
      "software code inherently possesses structural information,\n",
      "which may not be fully understood by LLMs. Hence,\n",
      "researchers often utilize program analysis techniques,\n",
      "including code abstract syntax trees (ASTs) [74], to\n",
      "represent the structure of code more effectively and increase\n",
      "the LLM’s ability to comprehend the code accurately.\n",
      "Researchers also perform the structure-based subsetting\n",
      "of code lines to narrow the focus for LLM [94], or extract\n",
      "additional code context from other code files [7], to enable\n",
      "the models to focus on the most task-relevant information\n",
      "in the codebase and lead to more accurate predictions.\n",
      "LLM + mutation testing. It is mainly targeting at gener-\n",
      "ating more diversified test inputs. For example, Deng et al.\n",
      "[59] first use LLM to generate the seed programs (e.g., code\n",
      "snippets using a target DL API) for fuzzing deep learning\n",
      "libraries. To enrich the pool of these test programs, they\n",
      "replace parts of the seed program with masked tokens using\n",
      "mutation operators (e.g., replaces the API call arguments\n",
      "with the span token) to produce masked inputs, and again\n",
      "utilize the LLMs to perform code infilling to generate new\n",
      "code that replaces the masked tokens.\n",
      "LLM + syntactic checking. Although LLMs have shown\n",
      "remarkable performance in various natural language pro-\n",
      "cessing tasks, the generated code from these models can\n",
      "sometimes be syntactically incorrect, leading to potential er-\n",
      "rors and reduced usability. Therefore, researchers have pro-\n",
      "posed to leverage syntax checking to identify and correct\n",
      "errors in the generated code. For example, in their work for\n",
      "unit test case generation, Alagarsamy et al. [29] addition-\n",
      "ally introduce a verification method to check and repair the\n",
      "naming consistency (i.e., revising the test method name to\n",
      "be consistent with the focal method name) and the test sig-\n",
      "natures (i.e., adding missing keywords like public, void, or\n",
      "@test annotations). Xie et al. [36] also validates the generated\n",
      "unit test case and employs rule-based repair to fix syntactic\n",
      "and simple compile errors.\n",
      "LLM + differential testing. Differential testing is well-\n",
      "suited to find semantic or logic bugs that do not exhibit\n",
      "explicit erroneous behaviors like crashes or assertion\n",
      "failures. In this category of our collected studies, the LLM\n",
      "is mainly responsible for generating valid and diversified\n",
      "inputs, while the differential testing helps to determine\n",
      "whether there is a triggered bug based on the software’s\n",
      "output. For example, Ye et al. [48] first uses LLM to\n",
      "produce random JavaScript programs, and leverages the\n",
      "language specification document to generate test data, then\n",
      "conduct the differential testing on JavaScript engines such\n",
      "as JavaScriptCore, ChakraCore, SpiderMonkey, QuickJS,\n",
      "etc. There are also studies utilizing the LLMs to generate\n",
      "test inputs and then conduct differential testing for fuzzing\n",
      "DL libraries [58], [59] and SAT solvers [63]. Li et al. [87]\n",
      "employs the LLM in finding the failure-inducing test cases.\n",
      "In detail, given a program under test, they first request the\n",
      "LLM to infer the intention of the program, then request the\n",
      "LLM to generate programs that have the same intention,\n",
      "which are alternative implementations of the program, and\n",
      "are likely free of the program’s bug. Then they perform\n",
      "the differential testing with the program under test and the\n",
      "generated programs to find the failure-inducing test cases.\n",
      "6 C HALLENGES AND OPPORTUNITIES\n",
      "Based on the above analysis from the viewpoints of soft-\n",
      "ware testing and LLM, we summarize the challenges and\n",
      "opportunities when conducting software testing with LLM.\n",
      "6.1 Challenges\n",
      "As indicated by this survey, software testing with LLMs\n",
      "has undergone significant growth in the past two years.\n",
      "However, it is still in its early stages of development, and\n",
      "numerous challenges and open questions need to be ad-\n",
      "dressed.\n",
      "6.1.1 Challenges for Achieving High Coverage\n",
      "Exploring the diverse behaviors of the software under test\n",
      "to achieve high coverage is always a significant concern\n",
      "in software testing. In this context, test generation differs\n",
      "from code generation, as code generation primarily focuses\n",
      "on producing a single, correct code snippet, whereas soft-\n",
      "ware testing requires generating diverse test inputs to en-\n",
      "sure better coverage of the software. Although setting a high\n",
      "temperature can facilitate the LLMs in generating different\n",
      "outputs, it remains challenging for LLMs to directly achieve\n",
      "the required diversity. For example, for unit test case gen-\n",
      "eration, in SF110 dataset, the line coverage is merely 2%\n",
      "and the branch coverage is merely 1% [39]. For system test\n",
      "input generation, in terms of fuzzing DL libraries, the API\n",
      "coverage for TensorFlow is reported to be 66% (2215/3316)\n",
      "[59].18\n",
      "From our collected studies, we observe that the\n",
      "researchers often utilize mutation testing together with the\n",
      "LLMs to generate more diversified outputs. For example,\n",
      "when fuzzing a DL library, instead of directly generating\n",
      "the code snippet with LLM, Deng et al. [59] replace parts\n",
      "of the selected seed (code generated by LLM) with masked\n",
      "tokens using different mutation operators to produce\n",
      "masked inputs. They then leverage the LLM to perform\n",
      "code infilling to generate new code that replaces the masked\n",
      "tokens, which can significantly increase the diversity of the\n",
      "generated tests. Liu et al. [65] leverage LLM to produce the\n",
      "test generators (each of which can yield a batch of unusual\n",
      "text inputs under the same mutation rule) together with the\n",
      "mutation rules for text-oriented fuzzing, which reduces the\n",
      "human effort required for designing mutation rules.\n",
      "A potential research direction could involve utilizing\n",
      "testing-specific data to train or fine-tune a specialized LLM\n",
      "that is specifically designed to understand the nature of\n",
      "testing. By doing so, the LLM can inherently acknowledge\n",
      "the requirements of testing and autonomously generate\n",
      "diverse outputs.\n",
      "6.1.2 Challenges in Test Oracle Problem\n",
      "The oracle problem has been a longstanding challenge in\n",
      "various testing applications, e.g., testing machine learning\n",
      "systems [150] and testing deep learning libraries [59]. To\n",
      "alleviate the oracle problem to the overall testing activities,\n",
      "a common practice in our collected studies is to transform it\n",
      "into a more easily derived form, often by utilizing differen-\n",
      "tial testing [63] or focusing on only identifying crash bugs\n",
      "[14].\n",
      "There are successful applications of differential testing\n",
      "with LLMs, as shown in Figure 10. For instance, when\n",
      "testing the SMT solvers, Sun et al. adopt differential testing\n",
      "which involves comparing the results of multiple SMT\n",
      "solvers (i.e., Z3, cvc5, and Bitwuzla) on the same generated\n",
      "test formulas by LLM [63]. However, this approach is\n",
      "limited to systems where counterpart software or running\n",
      "environment can easily be found, potentially restricting\n",
      "its applicability. Moreover, to mitigate the oracle problem,\n",
      "other studies only focus on the crash bugs which are easily\n",
      "observed automatically. This is particularly the case for\n",
      "mobile applications testing, in which the LLMs guide the\n",
      "testing in exploring more diversified pages, conducting\n",
      "more complex operational actions, and covering more\n",
      "meaningful operational sequences [14]. However, this\n",
      "significantly restricts the potential of utilizing the LLMs for\n",
      "uncovering various types of software bugs.\n",
      "Exploring the use of LLMs to derive other types of\n",
      "test oracles represents an interesting and valuable research\n",
      "direction. Specifically, metamorphic testing is also widely\n",
      "used in software testing practices to help mitigate the oracle\n",
      "problem, yet in most cases, defining metamorphic relations\n",
      "relies on human ingenuity. Luu et al. [56] have examined the\n",
      "effectiveness of LLM in generating metamorphic relations,\n",
      "yet they only experiment with straightforward prompts by\n",
      "directly querying ChatGPT. Further exploration, potentially\n",
      "incorporating human-computer interaction or domain\n",
      "knowledge, is highly encouraged. Another promising\n",
      "avenue is exploring the capability of LLMs to automatically\n",
      "generate test cases based on metamorphic relations,\n",
      "covering a wide range of inputs.\n",
      "The advancement of multi-model LLMs like GPT-4 may\n",
      "open up possibilities for exploring their ability to detect\n",
      "bugs in software user interfaces and assist in deriving test\n",
      "oracles. By leveraging the image understanding and reason-\n",
      "ing capabilities of these models, one can investigate their\n",
      "potential to automatically identify inconsistencies, errors, or\n",
      "usability issues in user interfaces.\n",
      "6.1.3 Challenges for Rigorous Evaluations\n",
      "The lack of benchmark datasets and the potential data leak-\n",
      "age issues associated with LLM-based techniques present\n",
      "challenges in conducting rigorous evaluations and compre-\n",
      "hensive comparisons of proposed methods.\n",
      "For program repair, there are only two well-known and\n",
      "commonly-used benchmarks, i.e., Defect4J and QuixBugs,\n",
      "as demonstrated in Table 4. Furthermore, these datasets are\n",
      "not specially designed for testing the LLMs. For example, as\n",
      "reported by Xia et al. [93], 39 out of 40 Python bugs in the\n",
      "QuixBugs dataset can be fixed by Codex, yet in real-world\n",
      "practice, the successful fix rate can be nowhere near as high.\n",
      "For unit test case generation, there are no widely recognized\n",
      "benchmarks, and different studies would utilize different\n",
      "datasets for performance evaluation, as demonstrated in Ta-\n",
      "ble 3. This indicates the need to build more specialized and\n",
      "diversified benchmarks.\n",
      "Furthermore, the LLMs may have seen the widely-used\n",
      "benchmarks in their pre-training data, i.e., data leakage\n",
      "issues. Jiang et al. [113] check the CodeSearchNet and\n",
      "BigQuery, which are the data sources of common LLMs,\n",
      "and the results show that four repositories used by the\n",
      "Defect4J benchmark are also in CodeSearchNet, and the\n",
      "whole Defects4J repository is included by BigQuery.\n",
      "Therefore, it is very likely that existing program repair\n",
      "benchmarks are seen by the LLMs during pre-training. This\n",
      "data leakage issue has also been investigated in machine\n",
      "learning-related studies. For example, Tu et al. [151] focus\n",
      "on the data leakage in issue tracking data, and results show\n",
      "that information leaked from the “future” makes prediction\n",
      "models misleadingly optimistic. This reminds us that the\n",
      "performance of LLMs on software testing tasks may not be\n",
      "as good as reported in previous studies. It also suggests\n",
      "that we need more specialized datasets that are not seen by\n",
      "LLMs to serve as benchmarks. One way is to collect it from\n",
      "specialized sources, e.g., user-generated content from niche\n",
      "online communities.\n",
      "6.1.4 Challenges in Real-world Application of LLMs in Soft-\n",
      "ware Testing\n",
      "As we mentioned in Section 5.2, in the early days of us-\n",
      "ing LLMs, pre-training and fine-tuning are commonly used\n",
      "practice, considering the model parameters are relatively\n",
      "few resulting in weaker model capabilities (e.g., T5). As time\n",
      "progressed, the number of model parameters increased sig-\n",
      "nificantly, leading to the emergence of models with greater\n",
      "capabilities (e.g., ChatGPT). And in recent studies, prompt\n",
      "engineering has become a common approach. However, due\n",
      "to concerns regarding data privacy, when considering real-\n",
      "world practice, most software organizations tend to avoid19\n",
      "using commercial LLMs and would prefer to adopt open-\n",
      "source ones with training or fine-tuning using organization-\n",
      "specific data. Furthermore, some companies also consider\n",
      "the current limitations in terms of computational power or\n",
      "pay close attention to energy consumption, they tend to\n",
      "fine-tune medium-sized models. It is quite challenging for\n",
      "these models to achieve similar performance to what our\n",
      "collected papers have reported. For instance, in the widely-\n",
      "used QuixBugs dataset, it has been reported that 39 out of\n",
      "40 Python bugs and 34 out of 40 Java bugs can be automat-\n",
      "ically fixed [93]. However, when it comes to DL programs\n",
      "collected from Stack Overflow, which represent real-world\n",
      "coding practice, only 16 out of 72 Python bugs can be auto-\n",
      "matically fixed [89].\n",
      "Recent research has highlighted the importance of high-\n",
      "quality training data in improving the performance of mod-\n",
      "els for code-related tasks [152], yet manually building high-\n",
      "quality organization-specific datasets for training or fine-\n",
      "tuning is time-consuming and labor-intensive. To address\n",
      "this, one is encouraged to utilize the automated techniques\n",
      "of mining software repositories to build the datasets, for\n",
      "example, techniques like key information extraction tech-\n",
      "niques from Stack Overflow [153] offer potential solutions\n",
      "for automatically gathering relevant data.\n",
      "In addition, exploring the methodology for better fine-\n",
      "tuning the LLMs with software-specific data is worth con-\n",
      "sidering because software-specific data differs from natural\n",
      "language data as it contains more structural information,\n",
      "such as data flow and control flow. Previous research on\n",
      "code representations has shown the benefits of incorporat-\n",
      "ing data flow, which captures the semantic-level structure\n",
      "of code and represents the relationship between variables in\n",
      "terms of “whether-value-comes-from” [154]. These insights\n",
      "can provide valuable guidance for effectively fine-tuning\n",
      "LLMs with software-specific data.\n",
      "6.2 Opportunities\n",
      "There are also many research opportunities in software test-\n",
      "ing with LLMs, which can greatly benefit developers, users,\n",
      "and the research community. While not necessarily chal-\n",
      "lenges, these opportunities contribute to advancements in\n",
      "software testing, benefiting practitioners and the wider re-\n",
      "search community.\n",
      "6.2.1 Exploring LLMs in the Early Stage of Testing\n",
      "As shown in Figure 4, LLMs have not been used in the early\n",
      "stage of testing, e.g., test requirements, and test planning.\n",
      "There might be two main reasons behind that. The first is\n",
      "the subjectivity in early-stage testing tasks. Many tasks in\n",
      "the early stages of testing, such as requirements gathering,\n",
      "test plan creation, and design reviews, may involve subjec-\n",
      "tive assessments that require significant input from human\n",
      "experts. This could make it less suitable for LLMs that rely\n",
      "heavily on data-driven approaches. The second might be the\n",
      "lack of open-sourced data in the early stages. Unlike in later\n",
      "stages of testing, there may be limited data available online\n",
      "during early-stage activities. This could mean that LLMs\n",
      "may not have seen much of this type of data, and therefore\n",
      "may not perform well on these tasks.\n",
      "Adopting a human-computer interaction schema for\n",
      "tackling early-stage testing tasks would harness the domain-\n",
      "specific knowledge of human developers and leverage the\n",
      "general knowledge embedded in LLMs. Additionally, it is\n",
      "highly encouraged for software development companies\n",
      "to record and provide access to early-stage testing data,\n",
      "allowing for improved training and performance of LLMs\n",
      "in these critical testing activities.\n",
      "6.2.2 Exploring LLMs in Other Testing Phases\n",
      "We have analyzed the distribution of testing phases for the\n",
      "collected studies. As shown in Fig 11, we can observe that\n",
      "LLMs are most commonly used in unit testing, followed by\n",
      "system testing. However, there is still no research on the use\n",
      "of LLMs in integration testing and acceptance testing.\n",
      "/uni00000013/uni00000018/uni00000014/uni00000013/uni00000014/uni00000018/uni00000015/uni00000013/uni00000015/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000038/uni00000051/uni0000004c/uni00000057/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni0000002c/uni00000051/uni00000057/uni00000048/uni0000004a/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000036/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000024/uni00000046/uni00000046/uni00000048/uni00000053/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057/uni00000037/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000033/uni0000004b/uni00000044/uni00000056/uni00000048/uni00000056\n",
      "/uni00000015/uni00000017\n",
      "/uni00000013\n",
      "/uni00000015/uni00000015\n",
      "/uni00000013\n",
      "Fig. 11: Distribution of testing phases (note that we omit the\n",
      "studies which do not explicitly specify the testing phases,\n",
      "e.g., program repair)\n",
      "For integration testing, it involves testing the interfaces\n",
      "between different software modules. In some software or-\n",
      "ganizations, integration testing might be merged with unit\n",
      "testing, which can be a possible reason why LLM is rarely\n",
      "utilized in integration testing. Another reason might be that\n",
      "the size and complexity of the input data in this circum-\n",
      "stance may exceed the capacity of the LLM to process and\n",
      "analyze (e.g., the source code of all involved software mod-\n",
      "ules), which can lead to errors or unreliable results. To tackle\n",
      "this, a potential reference can be found in Section 4.1, where\n",
      "Xie et al. [36] design a method to organize the necessary\n",
      "information into the pre-defined maximum prompt token\n",
      "limit of the LLM. Furthermore, integration testing requires\n",
      "diversified data to be generated to sufficiently test the in-\n",
      "terface among multiple modules. As mentioned in Section\n",
      "4.3, previous work has demonstrated the LLM’s capability\n",
      "in generating diversified test input for system testing, in\n",
      "conjunction with mutation testing techniques [48], [59]. And\n",
      "these can provide insights about generating the diversified\n",
      "interface data for integration testing.\n",
      "Acceptance testing is usually conducted by business an-\n",
      "alysts or end-users to validate the system’s functionality\n",
      "and usability, which requires more non-technical language\n",
      "and domain-specific knowledge, thus making it challenging\n",
      "to apply LLM effectively. Since acceptance testing involves\n",
      "humans, it is well-suited for the use of human-in-the-loop\n",
      "schema with LLMs. This has been studied in traditional\n",
      "machine learning [155], but has not yet been explored with\n",
      "LLMs. Specifically, the LLMs can be responsible for auto-\n",
      "matically generating test cases, evaluating test coverage, etc,\n",
      "while human testers are responsible for checking the pro-\n",
      "gram’s behavior and verifying test oracle.20\n",
      "6.2.3 Exploring LLMs for More Types of Software\n",
      "We analyze what types of software have been explored in\n",
      "the collected studies, as shown in Figure 5. Note that, since\n",
      "a large portion of studies are focused on unit testing or\n",
      "program repair, they are conducted on publicly available\n",
      "datasets and do not involve specific software types.\n",
      "From the analysis in Section 4.3, the LLM can generate\n",
      "not only the source code for testing DL libraries but also\n",
      "the textual input for testing mobile apps, even the models\n",
      "for testing CPS. Overall, the LLM provides a flexible and\n",
      "powerful framework for generating test inputs for a wide\n",
      "range of applications. Its versatility would make it useful\n",
      "for testing the software in other domains.\n",
      "From one point of view, some proposed techniques can\n",
      "be applied to other types of software. For example, in the\n",
      "paper proposed for testing deep learning libraries [58], since\n",
      "it proposes techniques for generating diversified, compli-\n",
      "cated, and human-like DL programs, the authors state that\n",
      "the approach can be easily extended to test software systems\n",
      "from other application domains, e.g., interpreters, database\n",
      "systems, and other popular libraries. More than that, there\n",
      "are already studies that focus on universal fuzzing tech-\n",
      "niques [52], [67] which are designed to be adaptable and\n",
      "applicable to different types of test inputs and software.\n",
      "From another point of view, other types of software can\n",
      "also benefit from the capabilities of LLMs to design the test-\n",
      "ing techniques that are better suited to their specific do-\n",
      "main and characteristics. For instance, the metaverse, with\n",
      "its immersive virtual environments and complex interac-\n",
      "tions, presents unique challenges for software testing. LLMs\n",
      "can be leveraged to generate diverse and realistic inputs that\n",
      "mimic user behavior and interactions within the metaverse,\n",
      "which are never explored.\n",
      "6.2.4 Exploring LLMs for Non-functional Testing\n",
      "In our collected studies, LLMs are primarily used for func-\n",
      "tional testing, and no practice in performance testing, usabil-\n",
      "ity testing or others. One possible reason for the prevalence\n",
      "of LLM-based solutions in functional testing is that they\n",
      "can convert functional testing problems into code gener-\n",
      "ation or natural language generation problems [14], [59],\n",
      "which LLMs are particularly adept at solving.\n",
      "On the other hand, performance testing and usability\n",
      "testing may require more specialized models that are de-\n",
      "signed to detect and analyze specific types of data, handle\n",
      "complex statistical analyses, or determine the buggy criteria.\n",
      "Moreover, there have been dozens of performance testing\n",
      "tools (e.g., LoadRunner [156]) that can generate a workload\n",
      "that simulates real-world usage scenarios and achieve rela-\n",
      "tively satisfactory performance.\n",
      "The potential opportunities might let the LLM integrate\n",
      "the performance testing tools and acts like the LangChain\n",
      "[157], to better simulate different types of workloads based\n",
      "on real user behavior. Furthermore, the LLMs can identify\n",
      "the parameter combinations and values that have the high-\n",
      "est potential to trigger performance problems. It is essen-\n",
      "tially a way to rank and prioritize different parameter set-\n",
      "tings based on their impact on performance and improve\n",
      "the efficiency of performance testing.\n",
      "6.2.5 Exploring Advanced Prompt Engineering\n",
      "There are a total of 11 commonly used prompt engineering\n",
      "techniques as listed in a popular prompt engineering guide\n",
      "[158], as shown in Figure 12. Currently, in our collected\n",
      "studies, only the first five techniques are being utilized. The\n",
      "more advanced techniques have not been employed yet, and\n",
      "can be explored in the future for prompt design.\n",
      "/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni0000003d/uni00000048/uni00000055/uni00000052/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000029/uni00000048/uni0000005a/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000026/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni00000036/uni00000048/uni0000004f/uni00000049/uni00000010/uni00000046/uni00000052/uni00000051/uni00000056/uni0000004c/uni00000056/uni00000057/uni00000048/uni00000051/uni00000046/uni0000005c\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000003/uni0000004e/uni00000051/uni00000052/uni0000005a/uni0000004f/uni00000048/uni00000047/uni0000004a/uni00000048/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000037/uni00000055/uni00000048/uni00000048/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057/uni00000056\n",
      "/uni00000024/uni00000046/uni00000057/uni0000004c/uni00000059/uni00000048/uni00000010/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000027/uni0000004c/uni00000055/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000056/uni00000057/uni0000004c/uni00000050/uni00000058/uni0000004f/uni00000058/uni00000056/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000035/uni00000048/uni00000024/uni00000046/uni00000057/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000050/uni00000052/uni00000047/uni00000044/uni0000004f/uni00000003/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000055/uni00000048/uni00000044/uni00000056/uni00000052/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000044/uni00000051/uni00000047/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000010/uni00000058/uni00000056/uni00000048\n",
      "/uni00000033/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057/uni00000003/uni00000028/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048/uni00000048/uni00000055/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000018/uni00000014\n",
      "/uni00000015/uni00000018\n",
      "/uni0000001a\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "Fig. 12: List of advanced prompt engineering practices and\n",
      "those utilized in the collected papers\n",
      "For instance, multimodal chain of thought prompting in-\n",
      "volves using diverse sensory and cognitive cues to stimulate\n",
      "thinking and creativity in LLMs [159]. By providing images\n",
      "(e.g., GUI screenshots) or audio recordings related to the\n",
      "software under test can help the LLM better understand\n",
      "the software’s context and potential issues. Besides, try to\n",
      "prompt the LLM to imagine itself in different roles, such\n",
      "as a developer, user, or quality assurance specialist. This\n",
      "perspective-shifting exercise enables the LLM to approach\n",
      "software testing from multiple viewpoints and uncover dif-\n",
      "ferent aspects that might require attention or investigation.\n",
      "Graph prompting [160] involves the representation of\n",
      "information using graphs or visual structures to facilitate\n",
      "understanding and problem-solving. Graph prompting can\n",
      "be a natural match with software engineering, consider\n",
      "it involves various dependencies, control flow, data flow,\n",
      "state transitions, or other relevant graph structure. Graph\n",
      "prompting can be beneficial in analyzing this structural\n",
      "information, and enabling the LLMs to comprehend the\n",
      "software under test effectively. For instance, testers can use\n",
      "graph prompts to visualize test coverage, identify untested\n",
      "areas or paths, and ensure adequate test execution.\n",
      "6.2.6 Incorporating LLMs with Traditional Techniques\n",
      "There is currently no clear consensus on the extent to which\n",
      "LLMs can solve software testing problems. From the analy-\n",
      "sis in Section 5.4, we have seen some promising results from\n",
      "studies that have combined LLMs with traditional software\n",
      "testing techniques. This implies the LLMs are not the sole\n",
      "silver bullet for software testing. Considering the availabil-\n",
      "ity of many mature software testing techniques and tools,\n",
      "and the limited capabilities of LLMs, it is necessary to ex-\n",
      "plore other better ways to combine LLMs with traditional\n",
      "testing or program analysis techniques and tools for better\n",
      "software testing.21\n",
      "Based on the collected studies, the LLMs have been suc-\n",
      "cessfully utilized together with various techniques such as\n",
      "differential testing (e.g., [63]), mutation testing (e.g., [59]),\n",
      "program analysis (e.g., [104], as shown in Figure 10. From\n",
      "one perspective, future studies can explore improved in-\n",
      "tegration of these traditional techniques with LLMs. Take\n",
      "mutation testing as an example, current practices mainly\n",
      "rely on the human-designed mutation rules to mutate the\n",
      "candidate tests, and let the LLMs re-generate new tests [38],\n",
      "[59], [67], while Liu et al. directly utilize the LLMs for pro-\n",
      "ducing the mutation rules alongside the mutated tests [65].\n",
      "Further explorations in this direction are of great interest.\n",
      "From another point of view, more traditional techniques\n",
      "can be incorporated in LLMs for software testing. For in-\n",
      "stance, besides the aforementioned traditional techniques,\n",
      "the LLMs have been combined with formal verification for\n",
      "self-healing software detection in the field of software se-\n",
      "curity [161]. More attempts are encouraged. Moreover, con-\n",
      "sidering the existence of numerous mature software testing\n",
      "tools, one can explore the integration of LLMs with these\n",
      "tools, allowing them to act as a “LangChain” to better ex-\n",
      "plore the potential of these tools.\n",
      "7 R ELATED WORK\n",
      "The systematic literature review is a crucial manner for gain-\n",
      "ing insights into the current trends and future directions\n",
      "within a particular field. It enables us to understand and\n",
      "stay updated on the developments in that domain.\n",
      "Wang et al. surveyed the machine learning and deep\n",
      "learning techniques for software engineering [162]. Yang et\n",
      "al. and Watson et al. respectively carried out surveys about\n",
      "the use of deep learning in software engineering domain\n",
      "[163], [164]. Bajammal et al. surveyed the utilization of com-\n",
      "puter vision techniques to improve software engineering\n",
      "tasks [165]. Zhang et al. provided a survey of techniques\n",
      "for testing machine learning systems [150]\n",
      "With the advancements of artificial intelligence and\n",
      "LLMs, researchers also conduct systematic literature\n",
      "reviews about LLMs, and their applications in various\n",
      "fields (e.g., software engineering). Zhao et al. [17] reviewed\n",
      "recent advances in LLMs by providing an overview of their\n",
      "background, key findings, and mainstream techniques.\n",
      "They focused on four major aspects of LLMs, namely\n",
      "pre-training, adaptation tuning, utilization, and capacity\n",
      "evaluation. Additionally, they summarized the available\n",
      "resources for developing LLMs and discuss the remaining\n",
      "issues for future directions. Hou et al. conducted a\n",
      "systematic literature review on using LLMs for software\n",
      "engineering, with a particular focus on understanding\n",
      "how LLMs can be exploited to optimize processes and\n",
      "outcomes [166]. Fan et al. conducted a survey of LLMs for\n",
      "software engineering, and set out open research challenges\n",
      "for the application of LLMs to technical problems faced by\n",
      "software engineers [167]. Zan et al. conducted a survey of\n",
      "existing LLMs for NL2Code task (i.e., generating code from\n",
      "a natural language description), and reviewed benchmarks\n",
      "and metrics [168].\n",
      "While these studies either targeted the broader software\n",
      "engineering domain (with a limited focus on software test-\n",
      "ing tasks) or focused on other software development tasks\n",
      "(excluding software testing), this paper specifically focuses\n",
      "on the use of LLMs for software testing. It surveys related\n",
      "studies, summarizes key challenges and potential opportu-\n",
      "nities, and serves as a roadmap for future research in this\n",
      "area.\n",
      "8 C ONCLUSION\n",
      "This paper provides a comprehensive review of the use\n",
      "of LLMs in software testing. We have analyzed relevant\n",
      "studies that have utilized LLMs in software testing from\n",
      "both the software testing and LLMs perspectives. This paper\n",
      "also highlights the challenges and potential opportunities\n",
      "in this direction. Results of this review demonstrate that\n",
      "LLMs have been successfully applied in a wide range\n",
      "of testing tasks, including unit test case generation, test\n",
      "oracle generation, system test input generation, program\n",
      "debugging, and program repair. However, challenges still\n",
      "exist in achieving high testing coverage, addressing the\n",
      "test oracle problem, conducting rigorous evaluations, and\n",
      "applying LLMs in real-world scenarios. Additionally, it is\n",
      "observed that LLMs are commonly used in only a subset of\n",
      "the entire testing lifecycle, for example, they are primarily\n",
      "utilized in the middle and later stages of testing, only\n",
      "serving the unit and system testing phases, and only for\n",
      "functional testing. This highlights the research opportunities\n",
      "for exploring the uncovered areas. Regarding how the LLMs\n",
      "are utilized, we find that various pre-training/fine-tuning\n",
      "and prompt engineering methods have been developed\n",
      "to enhance the capabilities of LLMs in addressing testing\n",
      "tasks. However, more advanced techniques in prompt\n",
      "design have yet to be explored and can be an avenue for\n",
      "future research.\n",
      "It can serve as a roadmap for future research in this area,\n",
      "identifying gaps in our current understanding of the use of\n",
      "LLMs in software testing and highlighting potential avenues\n",
      "for exploration. We believe that the insights provided in this\n",
      "paper will be valuable to both researchers and practition-\n",
      "ers in the field of software engineering, assisting them in\n",
      "leveraging LLMs to improve software testing practices and\n",
      "ultimately enhance the quality and reliability of software\n",
      "systems.\n",
      "REFERENCES\n",
      "[1] G. J. Myers, The art of software testing (2. ed.) . Wiley,\n",
      "2004. [Online]. Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[2] M. Pezz `e and M. Young, Software testing and analysis - process,\n",
      "principles and techniques. Wiley, 2007.\n",
      "[3] M. Harman and P . McMinn, “A theoretical and empirical study\n",
      "of search-based testing: Local, global, and hybrid search,” vol. 36,\n",
      "no. 2, 2010, pp. 226–247.\n",
      "[4] P . Delgado-P ´erez, A. Ram ´ırez, K. J. Valle-G ´omez, I. Medina-\n",
      "Bulo, and J. R. Romero, “Interevo-tr: Interactive evolutionary\n",
      "test generation with readability assessment,” IEEE Trans. Software\n",
      "Eng., vol. 49, no. 4, pp. 2580–2596, 2023.\n",
      "[5] X. Xiao, S. Li, T. Xie, and N. Tillmann, “Characteristic studies\n",
      "of loop problems for structural test generation via symbolic\n",
      "execution,” in 2013 28th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2013, Silicon Valley, CA, USA,\n",
      "November 11-15, 2013 , E. Denney, T. Bultan, and A. Zeller, Eds.\n",
      "IEEE, 2013, pp. 246–256.\n",
      "[6] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball, “Feedback-\n",
      "directed random test generation,” in 29th International Conference\n",
      "on Software Engineering (ICSE 2007), Minneapolis, MN, USA, May\n",
      "20-26, 2007. IEEE Computer Society, 2007, pp. 75–84.22\n",
      "[7] Z. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, and X. Peng,\n",
      "“No more manual tests? evaluating and improving chatgpt for\n",
      "unit test generation,” arXiv preprint arXiv:2305.04207, 2023.\n",
      "[8] Y. Tang, Z. Liu, Z. Zhou, and X. Luo, “Chatgpt vs SBST:\n",
      "A comparative assessment of unit test suite generation,”\n",
      "CoRR, vol. abs/2307.00588, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2307.00588\n",
      "[9] A. Developers, “Ui/application exerciser monkey,” 2012.\n",
      "[10] Y. Li, Z. Yang, Y. Guo, and X. Chen, “Droidbot: a lightweight ui-\n",
      "guided test input generator for android,” in ICSE. IEEE, 2017.\n",
      "[11] T. Su, G. Meng, Y. Chen, K. Wu, W. Yang, Y. Yao, G. Pu, Y. Liu, and\n",
      "Z. Su, “Guided, stochastic model-based gui testing of android\n",
      "apps,” in Proceedings of the 2017 11th Joint Meeting on Foundations\n",
      "of Software Engineering, 2017, pp. 245–256.\n",
      "[12] Z. Dong, M. B ¨ohme, L. Cojocaru, and A. Roychoudhury, “Time-\n",
      "travel testing of android apps,” in ICSE. IEEE, 2020.\n",
      "[13] M. Pan, A. Huang, G. Wang, T. Zhang, and X. Li, “Reinforcement\n",
      "learning based curiosity-driven testing of android applications,”\n",
      "in Proceedings of the 29th ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2020, pp. 153–164.\n",
      "[14] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che, D. Wang,\n",
      "and Q. Wang, “Make LLM a testing expert: Bringing human-\n",
      "like interaction to mobile GUI testing via functionality-aware\n",
      "decisions,” CoRR, vol. abs/2310.15780, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15780\n",
      "[15] T. Su, J. Wang, and Z. Su, “Benchmarking automated GUI testing\n",
      "for android against real-world bugs,” in ESEC/FSE ’21: 29th ACM\n",
      "Joint European Software Engineering Conference and Symposium on\n",
      "the Foundations of Software Engineering, Athens, Greece, August 23-\n",
      "28, 2021. ACM, 2021, pp. 119–130.\n",
      "[16] M. Shanahan, “Talking about large language models,”\n",
      "CoRR, vol. abs/2212.03551, 2022. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2212.03551\n",
      "[17] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou,\n",
      "Y. Min, B. Zhang, J. Zhang, Z. Dong, Y. Du, C. Yang,\n",
      "Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu,\n",
      "P . Liu, J. Nie, and J. Wen, “A survey of large language\n",
      "models,” CoRR, vol. abs/2303.18223, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2303.18223\n",
      "[18] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and\n",
      "Y. Iwasawa, “Large language models are zero-\n",
      "shot reasoners,” in NeurIPS, 2022. [Online]. Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html\n",
      "[19] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter,\n",
      "F. Xia, E. H. Chi, Q. V . Le, and D. Zhou,\n",
      "“Chain-of-thought prompting elicits reasoning in large\n",
      "language models,” in NeurIPS, 2022. [Online]. Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html\n",
      "[20] J. Li, G. Li, Y. Li, and Z. Jin, “Structured chain-of-thought\n",
      "prompting for code generation,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:258615421\n",
      "[21] J. Li, Y. Li, G. Li, Z. Jin, Y. Hao, and X. Hu, “Skcoder: A\n",
      "sketch-based approach for automatic code generation,” in 2023\n",
      "IEEE/ACM 45th International Conference on Software Engineering\n",
      "(ICSE), 2023, pp. 2124–2135.\n",
      "[22] J. Li, Y. Zhao, Y. Li, G. Li, and Z. Jin, “Acecoder: Utilizing existing\n",
      "code to enhance code generation,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:257901190\n",
      "[23] Y. Dong, X. Jiang, Z. Jin, and G. Li, “Self-collaboration\n",
      "code generation via chatgpt,” CoRR, vol. abs/2304.07590, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2304.07590\n",
      "[24] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu,\n",
      "“Unifying large language models and knowledge graphs: A\n",
      "roadmap,” CoRR, vol. abs/2306.08302, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2306.08302\n",
      "[25] G. J. Myers, T. Badgett, T. M. Thomas, and C. Sandler, The art of\n",
      "software testing. Wiley Online Library, 2004, vol. 2.\n",
      "[26] M. Tufano, D. Drain, A. Svyatkovskiy, S. K. Deng, and N. Sun-\n",
      "daresan, “Unit test case generation with transformers and focal\n",
      "context,” arXiv preprint arXiv:2009.05617, 2020.\n",
      "[27] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou, and\n",
      "W. Chen, “Codet: Code generation with generated tests,” arXiv\n",
      "preprint arXiv:2207.10397, 2022.\n",
      "[28] S. K. Lahiri, A. Naik, G. Sakkas, P . Choudhury, C. von Veh,\n",
      "M. Musuvathi, J. P . Inala, C. Wang, and J. Gao, “Interactive\n",
      "code generation via test-driven user-intent formalization,” arXiv\n",
      "preprint arXiv:2208.05950, 2022.\n",
      "[29] S. Alagarsamy, C. Tantithamthavorn, and A. Aleti, “A3test:\n",
      "Assertion-augmented automated test case generation,” arXiv\n",
      "preprint arXiv:2302.10352, 2023.\n",
      "[30] M. Sch ¨afer, S. Nadi, A. Eghbali, and F. Tip, “An empirical eval-\n",
      "uation of using large language models for automated unit test\n",
      "generation,” IEEE Transactions on Software Engineering , pp. 1–21,\n",
      "2023.\n",
      "[31] V . Guilherme and A. Vincenzi, “An initial investigation\n",
      "of chatgpt unit test generation capability,” in 8th Brazilian\n",
      "Symposium on Systematic and Automated Software Testing, SAST\n",
      "2023, Campo Grande, MS, Brazil, September 25-29, 2023 , A. L.\n",
      "Font˜ao, D. M. B. Paiva, H. Borges, M. I. Cagnin, P . G.\n",
      "Fernandes, V . Borges, S. M. Melo, V . H. S. Durelli, and E. D.\n",
      "Canedo, Eds. ACM, 2023, pp. 15–24. [Online]. Available:\n",
      "https://doi.org/10.1145/3624032.3624035\n",
      "[32] S. Hashtroudi, J. Shin, H. Hemmati, and S. Wang,\n",
      "“Automated test case generation using code models and\n",
      "domain adaptation,” CoRR, vol. abs/2308.08033, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2308.08033\n",
      "[33] L. Plein, W. C. Ou ´edraogo, J. Klein, and T. F. Bissyand ´e,\n",
      "“Automatic generation of test cases based on bug reports:\n",
      "a feasibility study with large language models,” CoRR, vol.\n",
      "abs/2310.06320, 2023. [Online]. Available: https://doi.org/10.\n",
      "48550/arXiv.2310.06320\n",
      "[34] V . Vikram, C. Lemieux, and R. Padhye, “Can large\n",
      "language models write good property-based tests?” CoRR,\n",
      "vol. abs/2307.04346, 2023. [Online]. Available: https://doi.org/\n",
      "10.48550/arXiv.2307.04346\n",
      "[35] N. Rao, K. Jain, U. Alon, C. L. Goues, and V . J. Hellendoorn,\n",
      "“CAT-LM training language models on aligned code and\n",
      "tests,” in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 . IEEE, 2023, pp. 409–420. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00193\n",
      "[36] Z. Xie, Y. Chen, C. Zhi, S. Deng, and J. Yin, “Chatunitest: a\n",
      "chatgpt-based automated unit test generation tool,”arXiv preprint\n",
      "arXiv:2305.04764, 2023.\n",
      "[37] C. Lemieux, J. P . Inala, S. K. Lahiri, and S. Sen, “Codamosa:\n",
      "Escaping coverage plateaus in test generation with pre-trained\n",
      "large language models,” in International conference on software\n",
      "engineering (ICSE), 2023.\n",
      "[38] A. M. Dakhel, A. Nikanjam, V . Majdinasab, F. Khomh,\n",
      "and M. C. Desmarais, “Effective test generation using\n",
      "pre-trained large language models and mutation testing,”\n",
      "CoRR, vol. abs/2308.16557, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.16557\n",
      "[39] M. L. Siddiq, J. Santos, R. H. Tanvir, N. Ulfat, F. A. Rifat, and V . C.\n",
      "Lopes, “Exploring the effectiveness of large language models in\n",
      "generating unit tests,” arXiv preprint arXiv:2305.00418, 2023.\n",
      "[40] Y. Zhang, W. Song, Z. Ji, D. Yao, and N. Meng, “How well does\n",
      "LLM generate security tests?” CoRR, vol. abs/2310.00710, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2310.00710\n",
      "[41] V . Li and N. Doiron, “Prompting code interpreter to write better\n",
      "unit tests on quixbugs functions,” CoRR, vol. abs/2310.00483,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2310.\n",
      "00483\n",
      "[42] B. Steenhoek, M. Tufano, N. Sundaresan, and A. Svyatkovskiy,\n",
      "“Reinforcement learning from automatic feedback for high-\n",
      "quality unit test generation,” 2023.\n",
      "[43] S. Bhatia, T. Gandhi, D. Kumar, and P . Jalote, “Unit test generation\n",
      "using generative ai : A comparative performance analysis of\n",
      "autogeneration tools,” 2023.\n",
      "[44] M. Tufano, D. Drain, A. Svyatkovskiy, and N. Sundaresan,\n",
      "“Generating accurate assert statements for unit test cases using\n",
      "pretrained transformers,” in Proceedings of the 3rd ACM/IEEE\n",
      "International Conference on Automation of Software Test , 2022, pp.\n",
      "54–64.\n",
      "[45] P . Nie, R. Banerjee, J. J. Li, R. J. Mooney, and M. Gligoric,\n",
      "“Learning deep semantics for test completion,” arXiv preprint\n",
      "arXiv:2302.10166, 2023.\n",
      "[46] A. Mastropaolo, N. Cooper, D. Nader-Palacio, S. Scalabrino,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Using transfer\n",
      "learning for code-related tasks,” IEEE Trans. Software Eng. ,\n",
      "vol. 49, no. 4, pp. 1580–1598, 2023. [Online]. Available:\n",
      "https://doi.org/10.1109/TSE.2022.318329723\n",
      "[47] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\n",
      "selection for code-related few-shot learning,” in Proceedings of\n",
      "the 45th International Conference on Software Engineering (ICSE’23) ,\n",
      "2023.\n",
      "[48] G. Ye, Z. Tang, S. H. Tan, S. Huang, D. Fang, X. Sun, L. Bian,\n",
      "H. Wang, and Z. Wang, “Automated conformance testing for\n",
      "javascript engines via deep compiler fuzzing,” in Proceedings of\n",
      "the 42nd ACM SIGPLAN international conference on programming\n",
      "language design and implementation, 2021, pp. 435–450.\n",
      "[49] Z. Liu, C. Chen, J. Wang, X. Che, Y. Huang, J. Hu, and Q. Wang,\n",
      "“Fill in the blank: Context-aware automated text input generation\n",
      "for mobile gui testing,” arXiv preprint arXiv:2212.04732, 2022.\n",
      "[50] M. R. Taesiri, F. Macklon, Y. Wang, H. Shen, and C.-P . Bezemer,\n",
      "“Large language models are pretty good zero-shot video game\n",
      "bug detectors,” arXiv preprint arXiv:2210.02506, 2022.\n",
      "[51] S. L. Shrestha and C. Csallner, “Slgpt: using transfer learning\n",
      "to directly generate simulink model files and find bugs in the\n",
      "simulink toolchain,” in Evaluation and Assessment in Software\n",
      "Engineering, 2021, pp. 260–265.\n",
      "[52] J. Hu, Q. Zhang, and H. Yin, “Augmenting greybox fuzzing\n",
      "with generative AI,” CoRR, vol. abs/2306.06782, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2306.06782\n",
      "[53] A. Mathur, S. Pradhan, P . Soni, D. Patel, and R. Regunathan,\n",
      "“Automated test case generation using t5 and gpt-3,” in 2023 9th\n",
      "International Conference on Advanced Computing and Communication\n",
      "Systems (ICACCS), vol. 1, 2023, pp. 1986–1992.\n",
      "[54] D. Zimmermann and A. Koziolek, “Automating gui-based soft-\n",
      "ware testing with gpt-3,” in 2023 IEEE International Conference\n",
      "on Software Testing, Verification and Validation Workshops (ICSTW),\n",
      "2023, pp. 62–65.\n",
      "[55] M. Taeb, A. Swearngin, E. Schoop, R. Cheng, Y. Jiang, and\n",
      "J. Nichols, “Axnav: Replaying accessibility tests from natural\n",
      "language,” CoRR, vol. abs/2310.02424, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.02424\n",
      "[56] Q. Luu, H. Liu, and T. Y. Chen, “Can chatgpt advance software\n",
      "testing intelligence? an experience report on metamorphic\n",
      "testing,” CoRR, vol. abs/2310.19204, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.19204\n",
      "[57] A. Khanfir, R. Degiovanni, M. Papadakis, and Y. L. Traon, “Ef-\n",
      "ficient mutation testing via pre-trained language models,” arXiv\n",
      "preprint arXiv:2301.03543, 2023.\n",
      "[58] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang,\n",
      "“Large language models are edge-case fuzzers: Testing deep\n",
      "learning libraries via fuzzgpt,” arXiv preprint arXiv:2304.02014 ,\n",
      "2023.\n",
      "[59] ——, “Large language models are zero shot fuzzers: Fuzzing\n",
      "deep learning libraries via large language models,” arXiv preprint\n",
      "arXiv:2209.11515, 2023.\n",
      "[60] J. Ackerman and G. Cybenko, “Large language models for\n",
      "fuzzing parsers (registered report),” in Proceedings of the\n",
      "2nd International Fuzzing Workshop, FUZZING 2023, Seattle,\n",
      "WA, USA, 17 July 2023 , M. B ¨ohme, Y. Noller, B. Ray, and\n",
      "L. Szekeres, Eds. ACM, 2023, pp. 31–38. [Online]. Available:\n",
      "https://doi.org/10.1145/3605157.3605173\n",
      "[61] S. Yu, C. Fang, Y. Ling, C. Wu, and Z. Chen, “LLM for\n",
      "test script generation and migration: Challenges, capabilities,\n",
      "and opportunities,” CoRR, vol. abs/2309.13574, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2309.13574\n",
      "[62] G. Deng, Y. Liu, V . M. Vilches, P . Liu, Y. Li, Y. Xu,\n",
      "T. Zhang, Y. Liu, M. Pinzger, and S. Rass, “Pentestgpt:\n",
      "An llm-empowered automatic penetration testing tool,”\n",
      "CoRR, vol. abs/2308.06782, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.06782\n",
      "[63] M. Sun, Y. Yang, Y. Wang, M. Wen, H. Jia, and Y. Zhou,\n",
      "“SMT solver validation empowered by large pre-trained\n",
      "language models,” in 38th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2023, Luxembourg, September\n",
      "11-15, 2023 . IEEE, 2023, pp. 1288–1300. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00180\n",
      "[64] Y. Deng, J. Yao, Z. Tu, X. Zheng, M. Zhang, and T. Zhang,\n",
      "“Target: Automated scenario generation from traffic rules\n",
      "for testing autonomous vehicles,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:258588387\n",
      "[65] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che,\n",
      "D. Wang, and Q. Wang, “Testing the limits: Unusual text inputs\n",
      "generation for mobile app crash detection with large language\n",
      "model,” CoRR, vol. abs/2310.15657, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15657\n",
      "[66] C. Zhang, M. Bai, Y. Zheng, Y. Li, X. Xie, Y. Li, W. Ma, L. Sun,\n",
      "and Y. Liu, “Understanding large language model based fuzz\n",
      "driver generation,” CoRR, vol. abs/2307.12469, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2307.12469\n",
      "[67] C. Xia, M. Paltenghi, J. Tian, M. Pradel, and L. Zhang,\n",
      "“Universal fuzzing via large language models,” ArXiv,\n",
      "vol. abs/2308.04748, 2023. [Online]. Available: https://api.\n",
      "semanticscholar.org/CorpusID:260735598\n",
      "[68] C. Tsigkanos, P . Rani, S. M ¨uller, and T. Kehrer, “Variable\n",
      "discovery with large language models for metamorphic testing\n",
      "of scientific software,” in Computational Science - ICCS 2023 -\n",
      "23rd International Conference, Prague, Czech Republic, July 3-5,\n",
      "2023, Proceedings, Part I , ser. Lecture Notes in Computer\n",
      "Science, J. Mikyska, C. de Mulatier, M. Paszynski, V . V .\n",
      "Krzhizhanovskaya, J. J. Dongarra, and P . M. A. Sloot, Eds.,\n",
      "vol. 14073. Springer, 2023, pp. 321–335. [Online]. Available:\n",
      "https://doi.org/10.1007/978-3-031-35995-8 23\n",
      "[69] C. Yang, Y. Deng, R. Lu, J. Yao, J. Liu, R. Jabbarvand, and\n",
      "L. Zhang, “White-box compiler fuzzing empowered by large\n",
      "language models,” CoRR, vol. abs/2310.15991, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2310.15991\n",
      "[70] T. Zhang, I. C. Irsan, F. Thung, D. Han, D. Lo, and L. Jiang,\n",
      "“itiger: an automatic issue title generation tool,” in Proceedings\n",
      "of the 30th ACM Joint European Software Engineering Conference and\n",
      "Symposium on the Foundations of Software Engineering , 2022, pp.\n",
      "1637–1641.\n",
      "[71] Y. Huang, J. Wang, Z. Liu, Y. Wang, S. Wang, C. Chen,\n",
      "Y. Hu, and Q. Wang, “Crashtranslator: Automatically\n",
      "reproducing mobile application crashes directly from stack\n",
      "trace,” CoRR, vol. abs/2310.07128, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.07128\n",
      "[72] T. Zhang, I. C. Irsan, F. Thung, and D. Lo, “Cupid:\n",
      "Leveraging chatgpt for more accurate duplicate bug report\n",
      "detection,” CoRR, vol. abs/2308.10022, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10022\n",
      "[73] U. Mukherjee and M. M. Rahman, “Employing deep\n",
      "learning and structured information retrieval to answer\n",
      "clarification questions on bug reports,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:259501524\n",
      "[74] P . Mahbub, O. Shuvo, and M. M. Rahman, “Explaining software\n",
      "bugs leveraging code structures in neural machine translation,”\n",
      "arXiv preprint arXiv:2212.04584, 2022.\n",
      "[75] S. Feng and C. Chen, “Prompting is all your need:\n",
      "Automated android bug replay with large language models,”\n",
      "CoRR, vol. abs/2306.01987, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.01987\n",
      "[76] Y. Su, Z. Han, Z. Gao, Z. Xing, Q. Lu, and X. Xu, “Still\n",
      "confusing for bug-component triaging? deep feature learning\n",
      "and ensemble setting to rescue,” in 31st IEEE/ACM International\n",
      "Conference on Program Comprehension, ICPC 2023, Melbourne,\n",
      "Australia, May 15-16, 2023 . IEEE, 2023, pp. 316–327. [Online].\n",
      "Available: https://doi.org/10.1109/ICPC58990.2023.00046\n",
      "[77] N. D. Bui, Y. Wang, and S. Hoi, “Detect-localize-repair: A unified\n",
      "framework for learning to debug with codet5,” arXiv preprint\n",
      "arXiv:2211.14875, 2022.\n",
      "[78] S. Kang, J. Yoon, and S. Yoo, “Large language models are few-shot\n",
      "testers: Exploring llm-based general bug reproduction,” arXiv\n",
      "preprint arXiv:2209.11515, 2022.\n",
      "[79] S. Kang, G. An, and S. Yoo, “A preliminary evaluation of\n",
      "llm-based fault localization,” CoRR, vol. abs/2308.05487, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.05487\n",
      "[80] P . Widjojo and C. Treude, “Addressing compiler errors: Stack\n",
      "overflow or large language models?” CoRR, vol. abs/2307.10793,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2307.\n",
      "10793\n",
      "[81] L. Plein and T. F. Bissyand ´e, “Can llms demystify bug\n",
      "reports?” CoRR, vol. abs/2310.06310, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2310.06310\n",
      "[82] A. Taylor, A. Vassar, J. Renzella, and H. A. Pearce, “Dcc\n",
      "–help: Generating context-aware compiler error explanations\n",
      "with large language models,” 2023. [Online]. Available:\n",
      "https://api.semanticscholar.org/CorpusID:261076439\n",
      "[83] S. Kang, B. Chen, S. Yoo, and J.-G. Lou, “Explainable automated\n",
      "debugging via large language model-driven scientific debug-\n",
      "ging,” arXiv preprint arXiv:2304.02195, 2023.24\n",
      "[84] A. Z. H. Yang, R. Martins, C. L. Goues, and V . J.\n",
      "Hellendoorn, “Large language models for test-free fault\n",
      "localization,” CoRR, vol. abs/2310.01726, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2310.01726\n",
      "[85] Y. Wu, Z. Li, J. M. Zhang, M. Papadakis, M. Harman,\n",
      "and Y. Liu, “Large language models in fault localisation,”\n",
      "CoRR, vol. abs/2308.15276, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.15276\n",
      "[86] H. Tu, Z. Zhou, H. Jiang, I. N. B. Yusuf, Y. Li, and L. Jiang,\n",
      "“LLM4CBI: taming llms to generate effective test programs\n",
      "for compiler bug isolation,” CoRR, vol. abs/2307.00593, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2307.00593\n",
      "[87] T.-O. Li, W. Zong, Y. Wang, H. Tian, Y. Wang, S.-C. Cheung,\n",
      "and J. Kramer, “Nuances are the key: Unlocking chatgpt to\n",
      "find failure-inducing tests with differential prompting,” in 2023\n",
      "38th IEEE/ACM International Conference on Automated Software\n",
      "Engineering (ASE), 2023, pp. 14–26.\n",
      "[88] X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou, “Teaching large\n",
      "language models to self-debug,”CoRR, vol. abs/2304.05128, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2304.05128\n",
      "[89] J. Cao, M. Li, M. Wen, and S.-c. Cheung, “A study on prompt\n",
      "design, advantages and limitations of chatgpt for deep learning\n",
      "program repair,” arXiv preprint arXiv:2304.08191, 2023.\n",
      "[90] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt,\n",
      "“Examining zero-shot vulnerability repair with large language\n",
      "models,” in 2023 IEEE Symposium on Security and Privacy (SP) .\n",
      "IEEE Computer Society, 2022, pp. 1–18.\n",
      "[91] Z. Fan, X. Gao, A. Roychoudhury, and S. H. Tan, “Automated\n",
      "repair of programs from large language models,” arXiv preprint\n",
      "arXiv:2205.10583, 2022.\n",
      "[92] Y. Hu, X. Shi, Q. Zhou, and L. Pike, “Fix bugs with trans-\n",
      "former through a neural-symbolic edit grammar,” arXiv preprint\n",
      "arXiv:2204.06643, 2022.\n",
      "[93] C. S. Xia, Y. Wei, and L. Zhang, “Practical program repair in\n",
      "the era of large pre-trained language models,” arXiv preprint\n",
      "arXiv:2210.14179, 2022.\n",
      "[94] J. Zhang, J. Cambronero, S. Gulwani, V . Le, R. Piskac, G. Soares,\n",
      "and G. Verbruggen, “Repairing bugs in python assignments\n",
      "using large language models,” arXiv preprint arXiv:2209.14876 ,\n",
      "2022.\n",
      "[95] M. Lajk ´o, V . Csuvik, and L. Vid´acs, “Towards javascript program\n",
      "repair with generative pre-trained transformer (gpt-2),” in Pro-\n",
      "ceedings of the Third International Workshop on Automated Program\n",
      "Repair, 2022, pp. 61–68.\n",
      "[96] D. Sobania, M. Briesch, C. Hanna, and J. Petke, “An analysis of\n",
      "the automatic bug fixing performance of chatgpt,” arXiv preprint\n",
      "arXiv:2301.08653, 2023.\n",
      "[97] K. Huang, X. Meng, J. Zhang, Y. Liu, W. Wang, S. Li,\n",
      "and Y. Zhang, “An empirical study on fine-tuning large\n",
      "language models of code for automated program repair,”\n",
      "in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 . IEEE, 2023, pp. 1162–1174. [Online]. Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00181\n",
      "[98] M. C. Wuisang, M. Kurniawan, K. A. Wira Santosa, A. Agung\n",
      "Santoso Gunawan, and K. E. Saputra, “An evaluation of the\n",
      "effectiveness of openai’s chatgpt for automated python program\n",
      "bug fixing using quixbugs,” in2023 International Seminar on Appli-\n",
      "cation for Technology of Information and Communication (iSemantic) ,\n",
      "2023, pp. 295–300.\n",
      "[99] D. Horv ´ath, V . Csuvik, T. Gyim ´othy, and L. Vid ´acs,\n",
      "“An extensive study on model architecture and program\n",
      "representation in the domain of learning-based automated\n",
      "program repair,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 . IEEE, 2023, pp. 31–38. [Online]. Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00013\n",
      "[100] J. A. Prenner, H. Babii, and R. Robbes, “Can openai’s codex fix\n",
      "bugs? an evaluation on quixbugs,” in Proceedings of the Third\n",
      "International Workshop on Automated Program Repair, 2022, pp. 69–\n",
      "75.\n",
      "[101] W. Yuan, Q. Zhang, T. He, C. Fang, N. Q. V . Hung, X. Hao, and\n",
      "H. Yin, “Circle: continual repair across programming languages,”\n",
      "in Proceedings of the 31st ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2022, pp. 678–690.\n",
      "[102] S. Moon, Y. Song, H. Chae, D. Kang, T. Kwon, K. T. iunn Ong,\n",
      "S. won Hwang, and J. Yeo, “Coffee: Boost your code llms by\n",
      "fixing bugs with feedback,” 2023.\n",
      "[103] Y. Wei, C. S. Xia, and L. Zhang, “Copiloting the copilots:\n",
      "Fusing large language models with completion engines for\n",
      "automated program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P . Tonella, Eds. ACM, 2023, pp. 172–184. [Online]. Available:\n",
      "https://doi.org/10.1145/3611643.3616271\n",
      "[104] Y. Peng, S. Gao, C. Gao, Y. Huo, and M. R. Lyu, “Domain\n",
      "knowledge matters: Improving prompts with fix templates for\n",
      "repairing python type errors,” CoRR, vol. abs/2306.01394, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2306.01394\n",
      "[105] A. E. I. Brownlee, J. Callan, K. Even-Mendoza, A. Geiger,\n",
      "C. Hanna, J. Petke, F. Sarro, and D. Sobania, “Enhancing\n",
      "genetic improvement mutations using large language models,”\n",
      "in Search-Based Software Engineering - 15th International\n",
      "Symposium, SSBSE 2023, San Francisco, CA, USA, December\n",
      "8, 2023, Proceedings , ser. Lecture Notes in Computer\n",
      "Science, P . Arcaini, T. Yue, and E. M. Fredericks, Eds.,\n",
      "vol. 14415. Springer, 2023, pp. 153–159. [Online]. Available:\n",
      "https://doi.org/10.1007/978-3-031-48796-5 13\n",
      "[106] M. M. A. Haque, W. U. Ahmad, I. Lourentzou, and C. Brown,\n",
      "“Fixeval: Execution-based evaluation of program fixes for\n",
      "programming problems,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 . IEEE, 2023, pp. 11–18. [Online]. Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00009\n",
      "[107] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “Fixing\n",
      "hardware security bugs with large language models,” arXiv\n",
      "preprint arXiv:2302.01215, 2023.\n",
      "[108] P . Deligiannis, A. Lal, N. Mehrotra, and A. Rastogi, “Fixing rust\n",
      "compilation errors using llms,” CoRR, vol. abs/2308.05177, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.05177\n",
      "[109] F. Ribeiro, R. Abreu, and J. Saraiva, “Framing program repair\n",
      "as code completion,” in Proceedings of the Third International\n",
      "Workshop on Automated Program Repair, 2022, pp. 38–45.\n",
      "[110] N. Wadhwa, J. Pradhan, A. Sonwane, S. P . Sahu, N. Natarajan,\n",
      "A. Kanade, S. Parthasarathy, and S. K. Rajamani, “Frustrated with\n",
      "code quality issues? llms can help!” CoRR, vol. abs/2309.12938,\n",
      "2023. [Online]. Available: https://doi.org/10.48550/arXiv.2309.\n",
      "12938\n",
      "[111] F. Ribeiro, J. N. C. de Macedo, K. Tsushima, R. Abreu,\n",
      "and J. Saraiva, “Gpt-3-powered type error debugging:\n",
      "Investigating the use of large language models for code\n",
      "repair,” in Proceedings of the 16th ACM SIGPLAN International\n",
      "Conference on Software Language Engineering, SLE 2023, Cascais,\n",
      "Portugal, October 23-24, 2023 , J. Saraiva, T. Degueule, and\n",
      "E. Scott, Eds. ACM, 2023, pp. 111–124. [Online]. Available:\n",
      "https://doi.org/10.1145/3623476.3623522\n",
      "[112] Y. Wu, N. Jiang, H. V . Pham, T. Lutellier, J. Davis, L. Tan,\n",
      "P . Babkin, and S. Shah, “How effective are neural networks for\n",
      "fixing security vulnerabilities,” arXiv preprint arXiv:2305.18607 ,\n",
      "2023.\n",
      "[113] N. Jiang, K. Liu, T. Lutellier, and L. Tan, “Impact of code\n",
      "language models on automated program repair,” arXiv preprint\n",
      "arXiv:2302.05020, 2023.\n",
      "[114] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan,\n",
      "and A. Svyatkovskiy, “Inferfix: End-to-end program repair with\n",
      "llms,” arXiv preprint arXiv:2303.07263, 2023.\n",
      "[115] C. S. Xia and L. Zhang, “Keep the conversation going: Fixing\n",
      "162 out of 337 bugs for $0.42 each using chatgpt,” arXiv preprint\n",
      "arXiv:2304.00385, 2023.\n",
      "[116] Y. Zhang, G. Li, Z. Jin, and Y. Xing, “Neural program repair with\n",
      "program dependence analysis and effective filter mechanism,”\n",
      "arXiv preprint arXiv:2305.09315, 2023.\n",
      "[117] J. A. Prenner and R. Robbes, “Out of context: How important is\n",
      "local context in neural program repair?” 2023.\n",
      "[118] Q. Zhang, C. Fang, B. Yu, W. Sun, T. Zhang, and Z. Chen,\n",
      "“Pre-trained model-based automated software vulnerability\n",
      "repair: How far are we?” CoRR, vol. abs/2308.12533, 2023.\n",
      "[Online]. Available: https://doi.org/10.48550/arXiv.2308.12533\n",
      "[119] S. Garg, R. Z. Moghaddam, and N. Sundaresan, “Rapgen:\n",
      "An approach for fixing code inefficiencies in zero-shot,”25\n",
      "CoRR, vol. abs/2306.17077, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.17077\n",
      "[120] W. Wang, Y. Wang, S. Joty, and S. C. H. Hoi, “Rap-\n",
      "gen: Retrieval-augmented patch generation with codet5 for\n",
      "automatic program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P . Tonella, Eds. ACM, 2023, pp. 146–158. [Online]. Available:\n",
      "https://doi.org/10.1145/3611643.3616256\n",
      "[121] Y. Zhang, Z. Jin, Y. Xing, and G. Li, “STEAM: simulating\n",
      "the interactive behavior of programmers for automatic bug\n",
      "fixing,” CoRR, vol. abs/2308.14460, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.14460\n",
      "[122] S. Fakhoury, S. Chakraborty, M. Musuvathi, and S. K. Lahiri,\n",
      "“Towards generating functionally correct code edits from natu-\n",
      "ral language issue descriptions,” arXiv preprint arXiv:2304.03816,\n",
      "2023.\n",
      "[123] M. Fu, C. Tantithamthavorn, T. Le, V . Nguyen, and D. Phung,\n",
      "“Vulrepair: a t5-based automated software vulnerability repair,”\n",
      "in Proceedings of the 30th ACM Joint European Software Engineering\n",
      "Conference and Symposium on the Foundations of Software Engineer-\n",
      "ing, 2022, pp. 935–947.\n",
      "[124] S. Gao, X. Wen, C. Gao, W. Wang, H. Zhang, and\n",
      "M. R. Lyu, “What makes good in-context demonstrations\n",
      "for code intelligence tasks with llms?” in 38th IEEE/ACM\n",
      "International Conference on Automated Software Engineering, ASE\n",
      "2023, Luxembourg, September 11-15, 2023 . IEEE, 2023, pp. 761–\n",
      "773. [Online]. Available: https://doi.org/10.1109/ASE56229.\n",
      "2023.00109\n",
      "[125] C. Treude and H. Hata, “She elicits requirements and he\n",
      "tests: Software engineering gender bias in large language\n",
      "models,” CoRR, vol. abs/2303.10131, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2303.10131\n",
      "[126] R. Kocielnik, S. Prabhumoye, V . Zhang, R. M. Alvarez, and\n",
      "A. Anandkumar, “Autobiastest: Controllable sentence generation\n",
      "for automated and open-ended social bias testing in language\n",
      "models,” CoRR, vol. abs/2302.07371, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2302.07371\n",
      "[127] M. Ciniselli, L. Pascarella, and G. Bavota, “To what extent do\n",
      "deep learning-based code recommenders generate predictions\n",
      "by cloning code from the training set?” in 19th IEEE/ACM\n",
      "International Conference on Mining Software Repositories, MSR 2022,\n",
      "Pittsburgh, P A, USA, May 23-24, 2022. ACM, 2022, pp. 167–178.\n",
      "[Online]. Available: https://doi.org/10.1145/3524842.3528440\n",
      "[128] D. Erhabor, S. Udayashankar, M. Nagappan, and S. Al-Kiswany,\n",
      "“Measuring the runtime performance of code produced with\n",
      "github copilot,” CoRR, vol. abs/2305.06439, 2023. [Online].\n",
      "Available: https://doi.org/10.48550/arXiv.2305.06439\n",
      "[129] R. Wang, R. Cheng, D. Ford, and T. Zimmermann, “Investigating\n",
      "and designing for trust in ai-powered code generation\n",
      "tools,” CoRR, vol. abs/2305.11248, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2305.11248\n",
      "[130] B. Yetistiren, I. ¨Ozsoy, M. Ayerdem, and E. T ¨uz ¨un, “Evaluating\n",
      "the code quality of ai-assisted code generation tools: An\n",
      "empirical study on github copilot, amazon codewhisperer, and\n",
      "chatgpt,” CoRR, vol. abs/2304.10778, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2304.10778\n",
      "[131] C. Wohlin, “Guidelines for snowballing in systematic literature\n",
      "studies and a replication in software engineering,” in\n",
      "18th International Conference on Evaluation and Assessment\n",
      "in Software Engineering, EASE ’14, London, England, United\n",
      "Kingdom, May 13-14, 2014 , M. J. Shepperd, T. Hall, and\n",
      "I. Myrtveit, Eds. ACM, 2014, pp. 38:1–38:10. [Online]. Available:\n",
      "https://doi.org/10.1145/2601248.2601268\n",
      "[132] A. Mastropaolo, S. Scalabrino, N. Cooper, D. Nader-Palacio,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Studying the usage\n",
      "of text-to-text transfer transformer to support code-related tasks,”\n",
      "in 43rd IEEE/ACM International Conference on Software Engineering,\n",
      "ICSE 2021, Madrid, Spain, 22-30 May 2021 . IEEE, 2021, pp. 336–\n",
      "347.\n",
      "[133] C. Tsigkanos, P . Rani, S. M ¨uller, and T. Kehrer, “Large\n",
      "language models: The next frontier for variable discovery\n",
      "within metamorphic testing?” in IEEE International Conference\n",
      "on Software Analysis, Evolution and Reengineering, SANER 2023,\n",
      "Taipa, Macao, March 21-24, 2023 , T. Zhang, X. Xia, and\n",
      "N. Novielli, Eds. IEEE, 2023, pp. 678–682. [Online]. Available:\n",
      "https://doi.org/10.1109/SANER56733.2023.00070\n",
      "[134] G. J. Myers, The art of software testing (2. ed.) . Wiley,\n",
      "2004. [Online]. Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[135] P . Farrell-Vinay,Manage software testing. Auerbach Publ., 2008.\n",
      "[136] A. Mili and F. Tchier, Software testing: Concepts and operations .\n",
      "John Wiley & Sons, 2015.\n",
      "[137] S. Lukasczyk and G. Fraser, “Pynguin: Automated unit\n",
      "test generation for python,” in 44th IEEE/ACM International\n",
      "Conference on Software Engineering: Companion Proceedings,\n",
      "ICSE Companion 2022, Pittsburgh, P A, USA, May 22-24,\n",
      "2022. ACM/IEEE, 2022, pp. 168–172. [Online]. Available:\n",
      "https://doi.org/10.1145/3510454.3516829\n",
      "[138] E. T. Barr, M. Harman, P . McMinn, M. Shahbaz, and S. Yoo, “The\n",
      "oracle problem in software testing: A survey,” IEEE transactions\n",
      "on software engineering, vol. 41, no. 5, pp. 507–525, 2014.\n",
      "[139] C. Watson, M. Tufano, K. Moran, G. Bavota, and D. Poshyvanyk,\n",
      "“On learning meaningful assert statements for unit test cases,”\n",
      "in ICSE ’20: 42nd International Conference on Software Engineering,\n",
      "Seoul, South Korea, 27 June - 19 July, 2020, G. Rothermel and D. Bae,\n",
      "Eds. ACM, 2020, pp. 1398–1409.\n",
      "[140] Y. He, L. Zhang, Z. Yang, Y. Cao, K. Lian, S. Li, W. Yang, Z. Zhang,\n",
      "M. Yang, Y. Zhang, and H. Duan, “Textexerciser: Feedback-driven\n",
      "text input exercising for android applications,” in 2020 IEEE\n",
      "Symposium on Security and Privacy, SP 2020, San Francisco, CA,\n",
      "USA, May 18-21, 2020. IEEE, 2020, pp. 1071–1087.\n",
      "[141] A. Wei, Y. Deng, C. Yang, and L. Zhang, “Free lunch for test-\n",
      "ing: Fuzzing deep-learning libraries from open source,” in 44th\n",
      "IEEE/ACM 44th International Conference on Software Engineering,\n",
      "ICSE 2022, Pittsburgh, P A, USA, May 25-27, 2022 . ACM, 2022,\n",
      "pp. 995–1007.\n",
      "[142] D. Xie, Y. Li, M. Kim, H. V . Pham, L. Tan, X. Zhang, and M. W.\n",
      "Godfrey, “Docter: documentation-guided fuzzing for testing\n",
      "deep learning API functions,” in ISSTA ’22: 31st ACM SIGSOFT\n",
      "International Symposium on Software Testing and Analysis, Virtual\n",
      "Event, South Korea, July 18 - 22, 2022 , S. Ryu and Y. Smaragdakis,\n",
      "Eds. ACM, 2022, pp. 176–188.\n",
      "[143] Q. Guo, X. Xie, Y. Li, X. Zhang, Y. Liu, X. Li, and C. Shen,\n",
      "“Audee: Automated testing for deep learning frameworks,” in\n",
      "35th IEEE/ACM International Conference on Automated Software\n",
      "Engineering, ASE 2020, Melbourne, Australia, September 21-25, 2020.\n",
      "IEEE, 2020, pp. 486–498.\n",
      "[144] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning\n",
      "library testing via effective model generation,” in ESEC/FSE\n",
      "’20: 28th ACM Joint European Software Engineering Conference\n",
      "and Symposium on the Foundations of Software Engineering, Virtual\n",
      "Event, USA, November 8-13, 2020 , P . Devanbu, M. B. Cohen, and\n",
      "T. Zimmermann, Eds. ACM, 2020, pp. 788–799.\n",
      "[145] J. Jiang, Y. Xiong, H. Zhang, Q. Gao, and X. Chen, “Shaping\n",
      "program repair space with existing patches and similar code,” in\n",
      "Proceedings of the 27th ACM SIGSOFT International Symposium on\n",
      "Software Testing and Analysis , ser. ISSTA 2018. New York, NY,\n",
      "USA: Association for Computing Machinery, 2018, p. 298–309.\n",
      "[Online]. Available: https://doi.org/10.1145/3213846.3213871\n",
      "[146] M. Wen, J. Chen, R. Wu, D. Hao, and S.-C. Cheung, “Context-\n",
      "aware patch generation for better automated program repair,”\n",
      "in Proceedings of the 40th International Conference on Software\n",
      "Engineering, ser. ICSE ’18. New York, NY, USA: Association\n",
      "for Computing Machinery, 2018, p. 1–11. [Online]. Available:\n",
      "https://doi.org/10.1145/3180155.3180233\n",
      "[147] Y. Xiong, J. Wang, R. Yan, J. Zhang, S. Han, G. Huang, and\n",
      "L. Zhang, “Precise condition synthesis for program repair,” in\n",
      "2017 IEEE/ACM 39th International Conference on Software Engineer-\n",
      "ing (ICSE), 2017, pp. 416–426.\n",
      "[148] J. Xuan, M. Martinez, F. DeMarco, M. Cl ´ement, S. L. Marcote,\n",
      "T. Durieux, D. Le Berre, and M. Monperrus, “Nopol: Automatic\n",
      "repair of conditional statement bugs in java programs,” IEEE\n",
      "Transactions on Software Engineering, vol. 43, no. 1, pp. 34–55, 2017.\n",
      "[149] S. Song, X. Li, and S. Li, “How to bridge the gap between modal-\n",
      "ities: A comprehensive survey on multimodal large language\n",
      "model,” CoRR, vol. abs/2311.07594, 2023.\n",
      "[150] J. M. Zhang, M. Harman, L. Ma, and Y. Liu, “Machine learning\n",
      "testing: Survey, landscapes and horizons,” IEEE Trans. Software\n",
      "Eng., vol. 48, no. 2, pp. 1–36, 2022.\n",
      "[151] F. Tu, J. Zhu, Q. Zheng, and M. Zhou, “Be careful of when:\n",
      "an empirical study on time-related misuse of issue tracking26\n",
      "data,” in Proceedings of the 2018 ACM Joint Meeting on European\n",
      "Software Engineering Conference and Symposium on the Foundations\n",
      "of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena\n",
      "Vista, FL, USA, November 04-09, 2018 , G. T. Leavens, A. Garcia,\n",
      "and C. S. Pasareanu, Eds. ACM, 2018, pp. 307–318. [Online].\n",
      "Available: https://doi.org/10.1145/3236024.3236054\n",
      "[152] Z. Sun, L. Li, Y. Liu, X. Du, and L. Li, “On the importance\n",
      "of building high-quality training datasets for neural code\n",
      "search,” in 44th IEEE/ACM 44th International Conference on\n",
      "Software Engineering, ICSE 2022, Pittsburgh, P A, USA, May\n",
      "25-27, 2022 . ACM, 2022, pp. 1609–1620. [Online]. Available:\n",
      "https://doi.org/10.1145/3510003.3510160\n",
      "[153] L. Shi, Z. Jiang, Y. Yang, X. Chen, Y. Zhang, F. Mu, H. Jiang, and\n",
      "Q. Wang, “ISPY: automatic issue-solution pair extraction from\n",
      "community live chats,” in 36th IEEE/ACM International Conference\n",
      "on Automated Software Engineering, ASE 2021, Melbourne, Australia,\n",
      "November 15-19, 2021 . IEEE, 2021, pp. 142–154. [Online].\n",
      "Available: https://doi.org/10.1109/ASE51524.2021.9678894\n",
      "[154] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu,\n",
      "L. Zhou, N. Duan, A. Svyatkovskiy, S. Fu, M. Tufano,\n",
      "S. K. Deng, C. B. Clement, D. Drain, N. Sundaresan, J. Yin,\n",
      "D. Jiang, and M. Zhou, “Graphcodebert: Pre-training code\n",
      "representations with data flow,” in 9th International Conference\n",
      "on Learning Representations, ICLR 2021, Virtual Event, Austria,\n",
      "May 3-7, 2021 . OpenReview.net, 2021. [Online]. Available:\n",
      "https://openreview.net/forum?id=jLoC4ez43PZ\n",
      "[155] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and\n",
      "J. Xiao, “Lsun: Construction of a large-scale image dataset us-\n",
      "ing deep learning with humans in the loop,” arXiv preprint\n",
      "arXiv:1506.03365, 2015.\n",
      "[156] LoadRunner, Inc., “Loadrunner,” 2023, microfocus.com.\n",
      "[157] LangChain, Inc., “Langchain,” 2023, https://docs.langchain.\n",
      "com/docs/.\n",
      "[158] Prompt engineering, “Prompt engineering guide,” 2023, https:\n",
      "//github.com/dair-ai/Prompt-Engineering-Guide.\n",
      "[159] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola,\n",
      "“Multimodal chain-of-thought reasoning in language models,”\n",
      "CoRR, vol. abs/2302.00923, 2023.\n",
      "[160] Z. Liu, X. Yu, Y. Fang, and X. Zhang, “Graphprompt: Unifying\n",
      "pre-training and downstream tasks for graph neural networks,”\n",
      "in Proceedings of the ACM Web Conference 2023, WWW 2023, Austin,\n",
      "TX, USA, 30 April 2023 - 4 May 2023, Y. Ding, J. Tang, J. F. Sequeda,\n",
      "L. Aroyo, C. Castillo, and G. Houben, Eds. ACM, 2023, pp. 417–\n",
      "428.\n",
      "[161] Y. Charalambous, N. Tihanyi, R. Jain, Y. Sun, M. A. Ferrag, and\n",
      "L. C. Cordeiro, “A new era in software security: Towards self-\n",
      "healing software via large language models and formal verifica-\n",
      "tion,” 2023.\n",
      "[162] S. Wang, L. Huang, A. Gao, J. Ge, T. Zhang, H. Feng, I. Satyarth,\n",
      "M. Li, H. Zhang, and V . Ng, “Machine/deep learning for\n",
      "software engineering: A systematic literature review,” IEEE\n",
      "Trans. Software Eng., vol. 49, no. 3, pp. 1188–1231, 2023. [Online].\n",
      "Available: https://doi.org/10.1109/TSE.2022.3173346\n",
      "[163] Y. Yang, X. Xia, D. Lo, and J. C. Grundy, “A survey on\n",
      "deep learning for software engineering,” ACM Comput. Surv. ,\n",
      "vol. 54, no. 10s, pp. 206:1–206:73, 2022. [Online]. Available:\n",
      "https://doi.org/10.1145/3505243\n",
      "[164] C. Watson, N. Cooper, D. Nader-Palacio, K. Moran, and\n",
      "D. Poshyvanyk, “A systematic literature review on the use of\n",
      "deep learning in software engineering research,” ACM Trans.\n",
      "Softw. Eng. Methodol., vol. 31, no. 2, pp. 32:1–32:58, 2022. [Online].\n",
      "Available: https://doi.org/10.1145/3485275\n",
      "[165] M. Bajammal, A. Stocco, D. Mazinanian, and A. Mesbah,\n",
      "“A survey on the use of computer vision to improve\n",
      "software engineering tasks,” IEEE Trans. Software Eng. ,\n",
      "vol. 48, no. 5, pp. 1722–1742, 2022. [Online]. Available:\n",
      "https://doi.org/10.1109/TSE.2020.3032986\n",
      "[166] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo,\n",
      "D. Lo, J. C. Grundy, and H. Wang, “Large language\n",
      "models for software engineering: A systematic literature\n",
      "review,” CoRR, vol. abs/2308.10620, 2023. [Online]. Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10620\n",
      "[167] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta,\n",
      "S. Yoo, and J. M. Zhang, “Large language models\n",
      "for software engineering: Survey and open problems,”\n",
      "CoRR, vol. abs/2310.03533, 2023. [Online]. Available: https:\n",
      "//doi.org/10.48550/arXiv.2310.03533\n",
      "[168] D. Zan, B. Chen, F. Zhang, D. Lu, B. Wu, B. Guan,\n",
      "Y. Wang, and J. Lou, “Large language models meet nl2code:\n",
      "A survey,” in Proceedings of the 61st Annual Meeting of\n",
      "the Association for Computational Linguistics (Volume 1: Long\n",
      "Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , A. Rogers,\n",
      "J. L. Boyd-Graber, and N. Okazaki, Eds. Association for\n",
      "Computational Linguistics, 2023, pp. 7443–7464. [Online].\n",
      "Available: https://doi.org/10.18653/v1/2023.acl-long.41127\n",
      "TABLE 5: All details of the collected papers\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "1 Unit Test Case Generation with Transform-\n",
      "ers and Focal Context\n",
      "2021 Unit test case gener-\n",
      "ation\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[26]\n",
      "2 Codet: Code Generation with Generated\n",
      "Tests\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Pure LLM ICLR 2023\n",
      "[27]\n",
      "3 Interactive Code Generation via Test-Driven\n",
      "User-Intent Formalization\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Statistic analysis\n",
      "Arxiv\n",
      "[28]\n",
      "4 A3Test: Assertion-Augmented Automated\n",
      "Test Case Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[29]\n",
      "5 An Empirical Evaluation of Using Large\n",
      "Language Models for Automated Unit Test\n",
      "Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Others Syntactic repair Arxiv\n",
      "[30]\n",
      "6 An Initial Investigation of ChatGPT Unit\n",
      "Test Generation Capability\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM SAST 2023\n",
      "[31]\n",
      "7 Automated Test Case Generation Using\n",
      "Code Models and Domain Adaptation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeT5; LLaMA-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[32]\n",
      "8 Automatic Generation of Test Cases based\n",
      "on Bug Reports: a Feasibility Study with\n",
      "Large Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGPT; ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM Arxiv\n",
      "[33]\n",
      "9 Can Large Language Models Write Good\n",
      "Property-Based Tests?\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Zero-shot learning Code; Others Pure LLM Arxiv\n",
      "[34]\n",
      "10 CAT-LM Training Language Models on\n",
      "Aligned Code And Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-neox Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[35]\n",
      "11 ChatGPT vs SBST: A Comparative Assess-\n",
      "ment of Unit Test Suite Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv [8]\n",
      "12 ChatUniTest: a ChatGPT-based Automated\n",
      "Unit Test Generation Tool\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Syntactic repair Arxiv\n",
      "[36]\n",
      "13 CODAMOSA: Escaping Coverage Plateaus\n",
      "in Test Generation with Pre-trained Large\n",
      "Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Program analysis\n",
      "ICSE 2023\n",
      "[37]\n",
      "14 Effective Test Generation Using Pre-trained\n",
      "Large Language Models and Mutation Test-\n",
      "ing\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Mutation testing;\n",
      "Syntactic repair\n",
      "Arxiv\n",
      "[38]\n",
      "15 Exploring the Effectiveness of Large Lan-\n",
      "guage Models in Generating Unit Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGen; Codex;\n",
      "ChatGPT\n",
      "Zero-shot learning Code Syntactic repair Arxiv\n",
      "[39]\n",
      "16 How Well does LLM Generate Security\n",
      "Tests?\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[40]\n",
      "17 No More Manual Tests? Evaluating and Im-\n",
      "proving ChatGPT for Unit Test Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv [7]\n",
      "18 Prompting Code Interpreter to Write Better\n",
      "Unit Tests on Quixbugs Functions\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Few-shot learning Code Pure LLM Arxiv\n",
      "[41]\n",
      "19 Reinforcement Learning from Automatic\n",
      "Feedback for High-Quality Unit Test Gen-\n",
      "eration\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis,\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[42]\n",
      "20 Unit Test Generation using Generative AI: A\n",
      "Comparative Performance Analysis of Au-\n",
      "togeneration Tools\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[43]\n",
      "21 Generating Accurate Assert Statements for\n",
      "Unit Test Cases Using Pretrained Trans-\n",
      "formers\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM AST 2022\n",
      "[44]\n",
      "22 Learning Deep Semantics for Test Comple-\n",
      "tion\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[45]\n",
      "23 Using Transfer Learning for Code-Related\n",
      "Tasks\n",
      "2022 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM TSE 2022\n",
      "[46]\n",
      "24 Retrieval-Based Prompt Selection for Code-\n",
      "Related Few-Shot Learning\n",
      "2023 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "Codex Few-shot learning Code Pure LLM ICSE 2023\n",
      "[47]28\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "25 Automated Conformance Testing for\n",
      "JavaScript Engines via Deep Compiler\n",
      "Fuzzing\n",
      "2021 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing;\n",
      "Program analysis\n",
      "PLDI 2021\n",
      "[48]\n",
      "26 Fill in the Blank: Context-aware Automated\n",
      "Text Input Generation for Mobile GUI Test-\n",
      "ing\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2023\n",
      "[49]\n",
      "27 Large Language Models are Pretty Good\n",
      "Zero-Shot Video Game Bug Detectors\n",
      "2022 System test input\n",
      "generation\n",
      "InstructGPT Chain-of-Thought;\n",
      "Zero-shot learning\n",
      "Others Pure LLM Arxiv\n",
      "[50]\n",
      "28 Slgpt: Using Transfer Learning to Directly\n",
      "Generate Simulink Model Files and Find\n",
      "Bugs in the Simulink Toolchain\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Others Formal method EASE 2021\n",
      "[51]\n",
      "29 Augmenting Greybox Fuzzing with Gener-\n",
      "ative AI\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[52]\n",
      "30 Automated Test Case Generation Using T5\n",
      "and GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3; T5 Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM ICACCS\n",
      "2023 [53]\n",
      "31 Automating GUI-based Software Testing\n",
      "with GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSTW\n",
      "2023 [54]\n",
      "32 AXNav: Replaying Accessibility Tests from\n",
      "Natural Language\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Chain-of-Thought View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[55]\n",
      "33 Can ChatGPT Advance Software Testing In-\n",
      "telligence? An Experience Report on Meta-\n",
      "morphic Testing\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning Others Pure LLM Arxiv\n",
      "[56]\n",
      "34 Efficient Mutation Testing via Pre-Trained\n",
      "Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "CodeBert Zero-shot learning Code Mutation testing Arxiv\n",
      "[57]\n",
      "35 Large Language Models are Edge-Case\n",
      "Generators:Crafting Unusual Programs for\n",
      "Fuzzing Deep Learning Libraries\n",
      "2023 System test input\n",
      "generation\n",
      "Codex Chain-of-Thought; Pre-\n",
      "training and/or Fine-\n",
      "tuning; Zero-shot learn-\n",
      "ing; Few-shot learning\n",
      "Code Differential testing ICSE 2024\n",
      "[58]\n",
      "36 Large Language Models are Zero Shot\n",
      "Fuzzers: Fuzzing Deep Learning Libraries\n",
      "via Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "Codex; InCoder Zero-shot learning Code Mutation testing;\n",
      "Differential testing\n",
      "ISSTA 2023\n",
      "[59]\n",
      "37 Large Language Models for Fuzzing Parsers\n",
      "(Registered Report)\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Few-shot learning NL specifica-\n",
      "tion\n",
      "Pure LLM FUZZING\n",
      "2023 [60]\n",
      "38 LLM for Test Script Generation and Migra-\n",
      "tion: Challenges, Capabilities, and Opportu-\n",
      "nities\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[61]\n",
      "39 Make LLM a Testing Expert: Bringing\n",
      "Human-like Interaction to Mobile GUI Test-\n",
      "ing via Functionality-aware Decisions\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Natural language\n",
      "processing\n",
      "ICSE 2024\n",
      "[14]\n",
      "40 PentestGPT: An LLM-empowered Auto-\n",
      "matic Penetration Testing Tool\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4;\n",
      "LaMDA\n",
      "Chain-of-Thought;\n",
      "Few-shot learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[62]\n",
      "41 SMT Solver Validation Empowered by\n",
      "Large Pre-Trained Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing ASE 2023\n",
      "[63]\n",
      "42 TARGET: Automated Scenario Generation\n",
      "from Traffic Rules for Testing Autonomous\n",
      "Vehicles\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning Others Scenario testing Arxiv\n",
      "[64]\n",
      "43 Testing the Limits: Unusual Text Inputs\n",
      "Generation for Mobile App Crash Detection\n",
      "with Large Language Model\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2024\n",
      "[65]\n",
      "44 Understanding Large Language Model\n",
      "Based Fuzz Driver Generation\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4 Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Others Pure LLM Arxiv\n",
      "[66]\n",
      "45 Universal Fuzzing via Large Language\n",
      "Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning; Au-\n",
      "tomatic prompt\n",
      "Code Mutation testing ICSE 2024\n",
      "[67]\n",
      "46 Variable Discovery with Large Language\n",
      "Models for Metamorphic Testing of Scien-\n",
      "tific Software\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-j Zero-shot learning Others Pure LLM SANER\n",
      "2023 [68]29\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "47 White-box Compiler Fuzzing Empowered\n",
      "by Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning Code Pure LLM Arxiv\n",
      "[69]\n",
      "48 Itiger: an Automatic Issue Title Generation\n",
      "Tool\n",
      "2022 Bug analysis BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM FSE 2022\n",
      "[70]\n",
      "49 CrashTranslator: Automatically Reproduc-\n",
      "ing Mobile Application Crashes Directly\n",
      "from Stack Trace\n",
      "2023 Bug analysis ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Reinforcement\n",
      "learning\n",
      "ICSE 2024\n",
      "[71]\n",
      "50 Cupid: Leveraging ChatGPT for More Ac-\n",
      "curate Duplicate Bug Report Detection\n",
      "2023 Bug analysis ChatGPT Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[72]\n",
      "51 Employing Deep Learning and Structured\n",
      "Information Retrieval to Answer Clarifica-\n",
      "tion Questions on Bug Reports\n",
      "2023 Bug analysis CodeT5 Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[73]\n",
      "52 Explaining Software Bugs Leveraging Code\n",
      "Structures in Neural Machine Translation\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2023\n",
      "[74]\n",
      "53 Prompting Is All Your Need: Automated\n",
      "Android Bug Replay with Large Language\n",
      "Models\n",
      "2023 Bug analysis ChatGPT Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Bug description Pure LLM ICSE 2024\n",
      "[75]\n",
      "54 Still Confusing for Bug-Component Triag-\n",
      "ing? Deep Feature Learning and Ensemble\n",
      "Setting to Rescue\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Statistic analysis ICPC 2023\n",
      "[76]\n",
      "55 Detect-Localize-Repair: A Unified Frame-\n",
      "work for Learning to Debug with CodeT5\n",
      "2022 Debug CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM EMNLP\n",
      "2022 [77]\n",
      "56 Large Language Models are Few-shot\n",
      "Testers: Exploring LLM-based General Bug\n",
      "Reproduction\n",
      "2022 Debug Codex Few-shot learning Bug description Program analysis;\n",
      "Statistic analysis\n",
      "ICSE 2023\n",
      "[78]\n",
      "57 A Preliminary Evaluation of LLM-Based\n",
      "Fault Localization\n",
      "2023 Debug ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[79]\n",
      "58 Addressing Compiler Errors: Stack Over-\n",
      "flow or Large Language Models?\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Error informa-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[80]\n",
      "59 Can LLMs Demystify Bug Reports? 2023 Debug ChatGPT Zero-shot learning Bug description Pure LLM Arxiv\n",
      "[81]\n",
      "60 Dcc –help: Generating Context-Aware Com-\n",
      "piler Error Explanations with Large Lan-\n",
      "guage Models\n",
      "2023 Debug ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM SIGCSE\n",
      "2024 [82]\n",
      "61 Explainable Automated Debugging via\n",
      "Large Language Model-driven Scientific De-\n",
      "bugging\n",
      "2023 Debug CodeGen; Codex;\n",
      "ChatGPT\n",
      "Self-consistency; Zero-\n",
      "shot learning\n",
      "Code Pure LLM Arxiv\n",
      "[83]\n",
      "62 Large Language Models for Test-Free Fault\n",
      "Localization\n",
      "2023 Debug CodeGen Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[84]\n",
      "63 Large Language Models in Fault Localisa-\n",
      "tion\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[85]\n",
      "64 LLM4CBI: Taming LLMs to Generate Effec-\n",
      "tive Test Programs for Compiler Bug Isola-\n",
      "tion\n",
      "2023 Debug ChatGPT Zero-shot learning Code Mutation testing;\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[86]\n",
      "65 Nuances are the Key: Unlocking ChatGPT\n",
      "to Find Failure-Inducing Tests with Differ-\n",
      "ential Prompting\n",
      "2023 Debug ChatGPT Zero-shot learning Code Differential testing ASE 2023\n",
      "[87]\n",
      "66 Teaching Large Language Models to Self-\n",
      "Debug\n",
      "2023 Debug Codex; ChatGPT;\n",
      "GPT-4; StarCoder\n",
      "Few-shot learning Code Pure LLM Arxiv\n",
      "[88]\n",
      "67 A study on Prompt Design, Advantages and\n",
      "Limitations of ChatGPT for Deep Learning\n",
      "Program Repair\n",
      "2023 Debug; Program re-\n",
      "pair\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[89]\n",
      "68 Examining Zero-Shot Vulnerability Repair\n",
      "with Large Language Models\n",
      "2021 Program repair Codex Zero-shot learning Code; Bug de-\n",
      "scription\n",
      "Pure LLM SP 2023\n",
      "[90]\n",
      "69 Automated Repair of Programs from Large\n",
      "Language Models\n",
      "2022 Program repair Codex Zero-shot learning Code Pure LLM ICSE 2023\n",
      "[91]\n",
      "70 Fix Bugs with Transformer through a\n",
      "Neural-Symbolic Edit Grammar\n",
      "2022 Program repair CodeGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[92]\n",
      "71 Practical Program Repair in the Era of Large\n",
      "Pre-trained Language Models\n",
      "2022 Program repair GPT-3; Codex;\n",
      "CodeT5; InCoder\n",
      "Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[93]30\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "72 Repairing Bugs in Python Assignments Us-\n",
      "ing Large Language Models\n",
      "2022 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv\n",
      "[94]\n",
      "73 Towards JavaScript Program Repair with\n",
      "Generative Pre-trained Transformer (GPT-2)\n",
      "2022 Program repair GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2022\n",
      "[95]\n",
      "74 An Analysis of the Automatic Bug Fixing\n",
      "Performance of ChatGPT\n",
      "2023 Program repair ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM APR 2023\n",
      "[96]\n",
      "75 An Empirical Study on Fine-Tuning Large\n",
      "Language Models of Code for Automated\n",
      "Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "UniXCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[97]\n",
      "76 An Evaluation of the Effectiveness of Ope-\n",
      "nAI’s ChatGPT for Automated Python Pro-\n",
      "gram Bug Fixing using QuixBugs\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM iSemantic\n",
      "2023 [98]\n",
      "77 An Extensive Study on Model Architecture\n",
      "and Program Representation in the Domain\n",
      "of Learning-based Automated Program Re-\n",
      "pair\n",
      "2023 Program repair T5; CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[99]\n",
      "78 Can OpenAI’s Codex Fix Bugs? An Evalua-\n",
      "tion on QuixBugs\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Pure LLM APR 2022\n",
      "[100]\n",
      "79 CIRCLE: Continual Repair Across Program-\n",
      "ming Languages\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ISSTA 2022\n",
      "[101]\n",
      "80 Coffee: Boost Your Code LLMs by Fixing\n",
      "Bugs with Feedback\n",
      "2023 Program repair CodeLLAMA Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[102]\n",
      "81 Copiloting the Copilots: Fusing Large Lan-\n",
      "guage Models with Completion Engines for\n",
      "Automated Program Repair\n",
      "2023 Program repair CodeT5; InCoder Zero-shot learning Code Statistic analysis FSE 2023\n",
      "[103]\n",
      "82 Domain Knowledge Matters: Improving\n",
      "Prompts with Fix Templates for Repairing\n",
      "Python Type Errors\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2024\n",
      "[104]\n",
      "83 Enhancing Genetic Improvement Mutations\n",
      "Using Large Language Models\n",
      "2023 Program repair GPT-4 Zero-shot learning Code Pure LLM SSBSE 2023\n",
      "[105]\n",
      "84 FixEval: Execution-based Evaluation of Pro-\n",
      "gram Fixes for Programming Problems\n",
      "2023 Program repair CodeT5; PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[106]\n",
      "85 Fixing Hardware Security Bugs with Large\n",
      "Language Models\n",
      "2023 Program repair Codex; CodeGen Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[107]\n",
      "86 Fixing Rust Compilation Errors using LLMs 2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[108]\n",
      "87 Framing Program Repair as Code Comple-\n",
      "tion\n",
      "2023 Program repair CodeGPT Zero-shot learning Code Pure LLM ICSE 2022\n",
      "[109]\n",
      "88 Frustrated with Code Quality Issues? LLMs\n",
      "can Help!\n",
      "2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[110]\n",
      "89 GPT-3-Powered Type Error Debugging: In-\n",
      "vestigating the Use of Large Language Mod-\n",
      "els for Code Repair\n",
      "2023 Program repair GPT-3 Zero-shot learning Code Program analysis SLE 2023\n",
      "[111]\n",
      "90 How Effective Are Neural Networks for Fix-\n",
      "ing Security Vulnerabilities\n",
      "2023 Program repair Codex; CodeGen;\n",
      "CodeT5; PLBART;\n",
      "InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ISSTA 2023\n",
      "[112]\n",
      "91 Impact of Code Language Models on Auto-\n",
      "mated Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "CodeGen; InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ICSE 2023\n",
      "[113]\n",
      "92 Inferfix: End-to-end Program Repair with\n",
      "LLMs\n",
      "2023 Program repair Codex Few-shot learning; Pre-\n",
      "training and/or Fine-\n",
      "tuning\n",
      "Code Pure LLM FSE 2023\n",
      "[114]\n",
      "93 Keep the Conversation Going: Fixing 162\n",
      "out of 337 bugs for $0.42 each using Chat-\n",
      "GPT\n",
      "2023 Program repair ChatGPT Few-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[115]\n",
      "94 Neural Program Repair with Program De-\n",
      "pendence Analysis and Effective Filter\n",
      "Mechanism\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis Arxiv\n",
      "[116]31\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "95 Out of Context: How important is Local\n",
      "Context in Neural Program Repair?\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[117]\n",
      "96 Pre-trained Model-based Automated Soft-\n",
      "ware Vulnerability Repair: How Far are We?\n",
      "2023 Program repair CodeT5; UniX-\n",
      "Coder; CodeGPT\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM IEEE TDSC\n",
      "[118]\n",
      "97 RAPGen: An Approach for Fixing Code In-\n",
      "efficiencies in Zero-Shot\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Code Pure LLM Arxiv\n",
      "[119]\n",
      "98 RAP-Gen: Retrieval-Augmented Patch Gen-\n",
      "eration with CodeT5 for Automatic Pro-\n",
      "gram Repair\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis FSE 2023\n",
      "[120]\n",
      "99 STEAM: Simulating the InTeractive BEhav-\n",
      "ior of ProgrAMmers for Automatic Bug Fix-\n",
      "ing\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[121]\n",
      "100 Towards Generating Functionally Correct\n",
      "Code Edits from Natural Language Issue\n",
      "Descriptions\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning;\n",
      "Zero-shot learning;\n",
      "Chain-of-Thought\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[122]\n",
      "101 VulRepair: a T5-based Automated Software\n",
      "Vulnerability Repair\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM FSE 2022\n",
      "[123]\n",
      "102 What Makes Good In-Context Demonstra-\n",
      "tions for Code Intelligence Tasks with\n",
      "LLMs?\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning Code Pure LLM ASE 2023\n",
      "[124]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Split text based on 2 or more \\n using re\n",
    "import re\n",
    "\n",
    "# \n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Software Testing with Large Language Models:\n",
      "Survey, Landscape, and Vision\n",
      "Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang\n",
      "Abstract—Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language\n",
      "processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide\n",
      "range of tasks.\n",
      "----------\n",
      "Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability\n",
      "of software products.\n",
      "----------\n",
      "As the scope and complexity of software systems continue to grow, the need for more effective software testing\n",
      "techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs.\n",
      "----------\n",
      "This paper provides\n",
      "a comprehensive review of the utilization of LLMs in software testing.\n",
      "----------\n",
      "It analyzes 102 relevant studies that have used LLMs for software\n",
      "testing, from both the software testing and LLMs perspectives.\n",
      "----------\n",
      "The paper presents a detailed discussion of the software testing tasks for\n",
      "which LLMs are commonly used, among which test case preparation and program repair are the most representative.\n",
      "----------\n",
      "It also analyzes\n",
      "the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs.\n",
      "----------\n",
      "It also summarizes the key challenges and potential opportunities in this direction.\n",
      "----------\n",
      "This work can serve as a roadmap for future research\n",
      "in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in\n",
      "software testing.\n",
      "----------\n",
      "Index Terms—Pre-trained Large Language Model, Software Testing, LLM, GPT\n",
      "✦\n",
      "1 I NTRODUCTION\n",
      "Software testing is a crucial undertaking that serves as\n",
      "a cornerstone for ensuring the quality and reliability of\n",
      "software products.\n",
      "----------\n",
      "Without the rigorous process of software\n",
      "testing, software enterprises would be reluctant to release\n",
      "their products into the market, knowing the potential\n",
      "consequences of delivering flawed software to end-users.\n",
      "----------\n",
      "By conducting thorough and meticulous testing procedures,\n",
      "software enterprises can minimize the occurrence of critical\n",
      "software failures, usability issues, or security breaches\n",
      "that could potentially lead to financial losses or jeopardize\n",
      "user trust.\n",
      "----------\n",
      "Additionally, software testing helps to reduce\n",
      "maintenance costs by identifying and resolving issues early\n",
      "in the development lifecycle, preventing more significant\n",
      "complications down the line [1], [2].\n",
      "----------\n",
      "The significance of software testing has garnered sub-\n",
      "stantial attention within the research and industrial com-\n",
      "munities.\n",
      "----------\n",
      "In the field of software engineering, it stands as\n",
      "an immensely popular and vibrant research area.\n",
      "----------\n",
      "One can\n",
      "observe the undeniable prominence of software testing by\n",
      "simply examining the landscape of conferences and sym-\n",
      "posiums focused on software engineering.\n",
      "----------\n",
      "Amongst these\n",
      "events, topics related to software testing consistently domi-\n",
      "nate the submission numbers and are frequently selected for\n",
      "publication.\n",
      "----------\n",
      "● J. Wang,Y.\n",
      "----------\n",
      "Huang, Z. Liu, Q. Wang are with State Key Laboratory of\n",
      "Intelligent Game, Institute of Software Chinese Academy of Sciences, and\n",
      "University of Chinese Academy of Sciences, Beijing, China.\n",
      "----------\n",
      "J. Wang and\n",
      "Q. Wang are corresponding authors.\n",
      "----------\n",
      "E-mail: {junjie, yuchao2019, liuzhe2020, wq}@iscas.ac.cn\n",
      "● C. Chen is with Monash University, Melbourne, Australia\n",
      "E-mail: chunyang.chen@monash.edu\n",
      "● S. Wang is with York University, Toronto, Canada.\n",
      "----------\n",
      "E-mail: wangsong@yorku.ca\n",
      "While the field of software testing has gained signifi-\n",
      "cant popularity, there remain dozens of challenges that have\n",
      "not been effectively addressed.\n",
      "----------\n",
      "For example, one such chal-\n",
      "lenge is automated unit test case generation.\n",
      "----------\n",
      "Although var-\n",
      "ious approaches, including search-based [3], [4], constraint-\n",
      "based [5] or random-based [6] techniques to generate a suite\n",
      "of unit tests, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory [7], [8].\n",
      "----------\n",
      "Simi-\n",
      "larly, when it comes to mobile GUI testing, existing studies\n",
      "with random-/rule-based methods [9], [10], model-based\n",
      "methods [11], [12], and learning-based methods [13] are un-\n",
      "able to understand the semantic information of the GUI\n",
      "page and often fall short in achieving comprehensive cov-\n",
      "erage [14], [15].\n",
      "----------\n",
      "Considering these limitations, numerous re-\n",
      "search efforts are currently underway to explore innovative\n",
      "techniques that can enhance the efficacy of software testing\n",
      "tasks, among which large language models are the most\n",
      "promising ones.\n",
      "----------\n",
      "Large language models (LLMs) such as T5 and GPT-3\n",
      "have revolutionized the field of natural language processing\n",
      "(NLP) and artificial intelligence (AI).\n",
      "----------\n",
      "These models, initially\n",
      "pre-trained on extensive corpora, have exhibited remarkable\n",
      "performance across a wide range of NLP tasks including\n",
      "question-answering, machine translation, and text genera-\n",
      "tion [16]–[19].\n",
      "----------\n",
      "In recent years, there has been a significant\n",
      "advancement in LLMs with the emergence of models capa-\n",
      "ble of handling even larger-scale datasets.\n",
      "----------\n",
      "This expansion\n",
      "in model size has not only led to improved performance\n",
      "but also opened up new possibilities for applying LLMs\n",
      "as Artificial General Intelligence.\n",
      "----------\n",
      "Among these advanced\n",
      "LLMs, models like ChatGPT 1 and LLaMA 2 boast billions\n",
      "1. https://openai.com/blog/chatgpt\n",
      "2. https://ai.meta.com/blog/large-language-model-llama-meta-ai/\n",
      "arXiv:2307.07221v3  [cs.SE]  4 Mar 20242\n",
      "of parameters.\n",
      "----------\n",
      "Such models hold tremendous potential for\n",
      "tackling complex practical tasks in domains like code gener-\n",
      "ation and artistic creation.\n",
      "----------\n",
      "With their expanded capacity and\n",
      "enhanced capabilities, LLMs have become game-changers in\n",
      "NLP and AI, and are driving advancements in other fields\n",
      "like coding and software testing.\n",
      "----------\n",
      "LLMs have been used for various coding-related tasks\n",
      "including code generation and code recommendation [20]–\n",
      "[23].\n",
      "----------\n",
      "On one hand, in software testing, there are many tasks\n",
      "related to code generation, such as unit test generation [7],\n",
      "where the utilization of LLMs is expected to yield good\n",
      "performance.\n",
      "----------\n",
      "On the other hand, software testing possesses\n",
      "unique characteristics that differentiate it from code gener-\n",
      "ation.\n",
      "----------\n",
      "For example, code generation primarily focuses on\n",
      "producing a single, correct code snippet, whereas software\n",
      "testing often requires generating diverse test inputs to en-\n",
      "sure better coverage of the software under test [1].\n",
      "----------\n",
      "The ex-\n",
      "istence of these differences introduces new challenges and\n",
      "opportunities when employing LLMs for software testing.\n",
      "----------\n",
      "Moreover, people have benefited from the excellent perfor-\n",
      "mance of LLMs in generation and inference tasks, leading\n",
      "to the emergence of dozens of new practices that use LLMs\n",
      "for software testing.\n",
      "----------\n",
      "This article presents a comprehensive review of the uti-\n",
      "lization of LLMs in software testing.\n",
      "----------\n",
      "We collect 102 relevant\n",
      "papers and conduct a thorough analysis from both software\n",
      "testing and LLMs perspectives, as roughly summarized in\n",
      "Figure 1.\n",
      "----------\n",
      "From the viewpoint of software testing, our analysis in-\n",
      "volves an examination of the specific software testing tasks\n",
      "for which LLMs are employed.\n",
      "----------\n",
      "Results show that LLMs are\n",
      "commonly used for test case preparation (including unit test\n",
      "case generation, test oracle generation, and system test input\n",
      "generation), program debugging, and bug repair, while we\n",
      "do not find the practices for applying LLMs in the tasks of\n",
      "early testing life-cycle (such as test requirement, test plan,\n",
      "etc).\n",
      "----------\n",
      "For each test task, we would provide detailed illustra-\n",
      "tions showcasing the utilization of LLMs in addressing the\n",
      "task, highlighting commonly-used practices, tracking tech-\n",
      "nology evolution trends, and summarizing achieved per-\n",
      "formance, so as to facilitate readers in gaining a thorough\n",
      "overview of how LLMs are employed across various testing\n",
      "tasks.\n",
      "----------\n",
      "From the viewpoint of LLMs, our analysis includes\n",
      "the commonly used LLMs in these studies, the types of\n",
      "prompt engineering, the input of the LLMs, as well as\n",
      "the accompanied techniques with these LLMs.\n",
      "----------\n",
      "Results\n",
      "show that about one-third of the studies utilize the LLMs\n",
      "through pre-training or fine-tuning schema, while the others\n",
      "employ prompt engineering to communicate with LLMs\n",
      "to steer their behavior for desired outcomes.\n",
      "----------\n",
      "For prompt\n",
      "engineering, the zero-shot learning and few-shot learning\n",
      "strategies are most commonly used, while other advances\n",
      "like chain-of-thought promoting and self-consistency are\n",
      "rarely utilized.\n",
      "----------\n",
      "Results also show that traditional testing\n",
      "techniques like differential testing and mutation testing\n",
      "are usually accompanied by LLMs to help generate more\n",
      "diversified tests.\n",
      "----------\n",
      "Furthermore, we summarize the key challenges and po-\n",
      "tential opportunities in this direction.\n",
      "----------\n",
      "Although software\n",
      "testing with LLMs has undergone significant growth in the\n",
      "Fig.\n",
      "----------\n",
      "1: Structure of the contents in this paper (the numbers\n",
      "in bracket indicates the number of involved papers, and a\n",
      "paper might involve zero or multiple items)\n",
      "past two years, there are still challenges in achieving high\n",
      "coverage of the testing, test oracle problem, rigorous evalu-\n",
      "ations, and real-world application of LLMs in software test-\n",
      "ing.\n",
      "----------\n",
      "Since it is a new emerging field, there are many research\n",
      "opportunities, including exploring LLMs in an early stage of\n",
      "testing, exploring LLMs for more types of software and non-\n",
      "functional testing, exploring advanced prompt engineering,\n",
      "as well as incorporating LLMs with traditional techniques.\n",
      "----------\n",
      "This paper makes the following contributions:\n",
      "● We thoroughly analyze 102 relevant studies that used\n",
      "LLMs for software testing, regarding publication\n",
      "trends, distribution of publication venues, etc.\n",
      "----------\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of software testing to understand the distribution of\n",
      "software testing tasks with LLM and present a thorough\n",
      "discussion about how these tasks are solved with LLM.\n",
      "----------\n",
      "● We conduct a comprehensive analysis from the perspec-\n",
      "tive of LLMs, and uncover the commonly-used LLMs,\n",
      "the types of prompt engineering, input of the LLMs, as\n",
      "well as the accompanied techniques with these LLMs.\n",
      "----------\n",
      "● We highlight the challenges in existing studies and\n",
      "present potential opportunities for further studies.\n",
      "----------\n",
      "We believe that this work will be valuable to both re-\n",
      "searchers and practitioners in the field of software engineer-\n",
      "ing, as it provides a comprehensive overview of the current\n",
      "state and future vision of using LLMs for software testing.\n",
      "----------\n",
      "For researchers, this work can serve as a roadmap for future\n",
      "research in this area, highlighting potential avenues for ex-\n",
      "ploration and identifying gaps in our current understanding\n",
      "of the use of LLMs in software testing.\n",
      "----------\n",
      "For practitioners, this\n",
      "work can provide insights into the potential benefits and\n",
      "limitations of using LLMs for software testing, as well as\n",
      "practical guidance on how to effectively integrate them into3\n",
      "existing testing processes.\n",
      "----------\n",
      "By providing a detailed landscape\n",
      "of the current state and future vision of using LLMs for\n",
      "software testing, this work can help accelerate the adoption\n",
      "of this technology in the software engineering community\n",
      "and ultimately contribute to improving the quality and reli-\n",
      "ability of software systems.\n",
      "----------\n",
      "2 B ACKGROUND\n",
      "2.1 Large Language Model (LLM)\n",
      "Recently, pre-trained language models (PLMs) have been\n",
      "proposed by pretraining Transformer-based models over\n",
      "large-scale corpora, showing strong capabilities in solving\n",
      "various natural language processing (NLP) tasks [16]–[19].\n",
      "----------\n",
      "Studies have shown that model scaling can lead to improved\n",
      "model capacity, prompting researchers to investigate the\n",
      "scaling effect through further parameter size increases.\n",
      "----------\n",
      "Interestingly, when the parameter scale exceeds a certain\n",
      "threshold, these larger language models demonstrate not\n",
      "only significant performance improvements but also special\n",
      "abilities such as in-context learning, which are absent in\n",
      "smaller models such as BERT.\n",
      "----------\n",
      "To discriminate the language models in different\n",
      "parameter scales, the research community has coined\n",
      "the term large language models (LLM) for the PLMs of\n",
      "significant size.\n",
      "----------\n",
      "LLMs typically refer to language models\n",
      "that have hundreds of billions (or more) of parameters and\n",
      "are trained on massive text data such as GPT-3, PaLM,\n",
      "Codex, and LLaMA.\n",
      "----------\n",
      "LLMs are built using the Transformer\n",
      "architecture, which stacks multi-head attention layers\n",
      "in a very deep neural network.\n",
      "----------\n",
      "Existing LLMs adopt\n",
      "similar model architectures (Transformer) and pre-training\n",
      "objectives (language modeling) as small language models,\n",
      "but largely scale up the model size, pre-training data,\n",
      "and total compute power.\n",
      "----------\n",
      "This enables LLMs to better\n",
      "understand natural language and generate high-quality text\n",
      "based on given context or prompts.\n",
      "----------\n",
      "Note that, in existing literature, there is no formal con-\n",
      "sensus on the minimum parameter scale for LLMs, since\n",
      "the model capacity is also related to data size and total\n",
      "compute.\n",
      "----------\n",
      "In a recent survey of LLMs [17], the authors focus\n",
      "on discussing the language models with a model size larger\n",
      "than 10B.\n",
      "----------\n",
      "Under their criteria, the first LLM is T5 released\n",
      "by Google in 2019, followed by GPT-3 released by OpenAI\n",
      "in 2020, and there are more than thirty LLMs released be-\n",
      "tween 2021 and 2023 indicating its popularity.\n",
      "----------\n",
      "In another\n",
      "survey of unifying LLMs and knowledge graphs [24], the\n",
      "authors categorize the LLMs into three types: encoder-only\n",
      "(e.g., BERT), encoder-decoder (e.g., T5), and decoder-only\n",
      "network architecture (e.g., GPT-3).\n",
      "----------\n",
      "In our review, we take\n",
      "into account the categorization criteria of the two surveys\n",
      "and only consider the encoder-decoder and decoder-only\n",
      "network architecture of pre-training language models, since\n",
      "they can both support generative tasks.\n",
      "----------\n",
      "We do not consider\n",
      "the encoder-only network architecture because they cannot\n",
      "handle generative tasks, were proposed relatively early (e.g.,\n",
      "BERT in 2018), and there are almost no models using this\n",
      "architecture after 2021.\n",
      "----------\n",
      "In other words, the LLMs discussed\n",
      "in this paper not only include models with parameters of\n",
      "over 10B (as mentioned in [17]) but also include other mod-\n",
      "els that use the encoder-decoder and decoder-only network\n",
      "architecture (as mentioned in [24]), such as BART with 140M\n",
      "parameters and GPT-2 with parameter sizes ranging from\n",
      "117M to 1.5B.\n",
      "----------\n",
      "This is also to potentially include more studies\n",
      "to demonstrate the landscape of this topic.\n",
      "----------\n",
      "2.2 Software Testing\n",
      "Software testing is a crucial process in software develop-\n",
      "ment that involves evaluating the quality of a software prod-\n",
      "uct.\n",
      "----------\n",
      "The primary goal of software testing is to identify de-\n",
      "fects or errors in the software system that could potentially\n",
      "lead to incorrect or unexpected behavior.\n",
      "----------\n",
      "The whole life\n",
      "cycle of software testing typically includes the following\n",
      "tasks (demonstrated in Figure 4):\n",
      "● Requirement Analysis: analyze the software require-\n",
      "ments and identify the testing objectives, scope, and\n",
      "criteria.\n",
      "----------\n",
      "● Test Plan: develop a test plan that outlines the testing\n",
      "strategy, test objectives, and schedule.\n",
      "----------\n",
      "● Test Design and Review: develop and review the test\n",
      "cases and test suites that align with the test plan and\n",
      "the requirements of the software application.\n",
      "----------\n",
      "● Test Case Preparation: the actual test cases are prepared\n",
      "based on the designs created in the previous stage.\n",
      "----------\n",
      "● Test Execution: execute the tests that were designed in\n",
      "the previous stage.\n",
      "----------\n",
      "The software system is executed\n",
      "with the test cases and the results are recorded.\n",
      "----------\n",
      "● Test Reporting: analyze the results of the tests and gen-\n",
      "erate reports that summarize the testing process and\n",
      "identify any defects or issues that were discovered.\n",
      "----------\n",
      "● Bug Fixing and Regression Testing: defects or issues\n",
      "identified during testing are reported to the develop-\n",
      "ment team for fixing.\n",
      "----------\n",
      "Once the defects are fixed, regres-\n",
      "sion testing is performed to ensure that the changes\n",
      "have not introduced new defects or issues.\n",
      "----------\n",
      "● Software Release: once the software system has passed\n",
      "all of the testing stages and the defects have been fixed,\n",
      "the software can be released to the customer or end\n",
      "user.\n",
      "----------\n",
      "The testing process is iterative and may involve multiple\n",
      "cycles of the above stages, depending on the complexity of\n",
      "the software system and the testing requirements.\n",
      "----------\n",
      "During the testing phase, various types of tests may be\n",
      "performed, including unit tests, integration tests, system\n",
      "tests, and acceptance tests.\n",
      "----------\n",
      "● Unit Testing involves testing individual units or com-\n",
      "ponents of the software application to ensure that they\n",
      "function correctly.\n",
      "----------\n",
      "● Integration Testing involves testing different modules\n",
      "or components of the software application together to\n",
      "ensure that they work correctly as a system.\n",
      "----------\n",
      "● System Testing involves testing the entire software sys-\n",
      "tem as a whole, including all the integrated components\n",
      "and external dependencies.\n",
      "----------\n",
      "● Acceptance Testing involves testing the software appli-\n",
      "cation to ensure that it meets the business requirements\n",
      "and is ready for deployment.\n",
      "----------\n",
      "In addition, there can be functional testing, performance\n",
      "testing, unit testing, security testing, accessibility testing,\n",
      "etc, which explores various aspects of the software under\n",
      "test [25].4\n",
      "3.1.1 Automatic \n",
      "Search\n",
      "3.1.1 Automatic \n",
      "Filtering\n",
      "3.1.4 Quality \n",
      "Assessment3.1.5 Snowballing\n",
      "14,623 \n",
      "Papers\n",
      "102\n",
      "Papers\n",
      "1,239 \n",
      "Papers\n",
      "109 \n",
      "Papers\n",
      "START\n",
      "102 \n",
      "Papers\n",
      "Major SE Venues\n",
      "& AI Venues\n",
      "3.1.2 Manual Search\n",
      "1,278 \n",
      "Papers\n",
      "3.1.3 Inclusion and \n",
      "Exclusion Criteria\n",
      "Fig.\n",
      "----------\n",
      "2: Overview of the paper collection process\n",
      "3 P APER SELECTION AND REVIEW SCHEMA\n",
      "3.1 Paper Collection Methodology\n",
      "Figure 2 shows our paper search and selection process.\n",
      "----------\n",
      "To\n",
      "collect as much relevant literature as possible, we use both\n",
      "automatic search (from paper repository database) and man-\n",
      "ual search (from major software engineering and artificial\n",
      "intelligence venues).\n",
      "----------\n",
      "We searched papers from Jan. 2019 to\n",
      "Jun.\n",
      "----------\n",
      "2023 and further conducted the second round of search\n",
      "to include the papers from Jul.\n",
      "----------\n",
      "2023 to Oct. 2023.\n",
      "----------\n",
      "3.1.1 Automatic Search\n",
      "To ensure that we collect papers from diverse research areas,\n",
      "we conduct an extensive search using four popular scientific\n",
      "databases: ACM digital library, IEEE Xplore digital library,\n",
      "arXiv, and DBLP .\n",
      "----------\n",
      "We search for papers whose title contains keywords re-\n",
      "lated to software testing tasks and testing techniques (as shown\n",
      "below) in the first three databases.\n",
      "----------\n",
      "In the case of DBLP , we\n",
      "use additional keywords related to LLMs (as shown below)\n",
      "to filter out irrelevant studies, as relying solely on testing-\n",
      "related keywords would result in a large number of can-\n",
      "didate studies.\n",
      "----------\n",
      "While using two sets of keywords for DBLP\n",
      "may result in overlooking certain related studies, we believe\n",
      "it is still a feasible strategy.\n",
      "----------\n",
      "This is due to the fact that a\n",
      "substantial number of studies present in this database can\n",
      "already be found in the first three databases, and the fourth\n",
      "database only serves as a supplementary source for collect-\n",
      "ing additional papers.\n",
      "----------\n",
      "● Keywords related with software testing tasks and tech-\n",
      "niques: test OR bug OR issue OR defect OR fault OR\n",
      "error OR failure OR crash OR debug OR debugger OR\n",
      "repair OR fix OR assert OR verification OR validation\n",
      "OR fuzz OR fuzzer OR mutation.\n",
      "----------\n",
      "● Keywords related with LLMs: LLMOR language model\n",
      "OR generative model OR large model OR GPT-3 OR\n",
      "ChatGPT OR GPT-4 OR LLaMA OR PaLM2 OR CodeT5\n",
      "OR CodeX OR CodeGen OR Bard OR InstructGPT.\n",
      "----------\n",
      "Note\n",
      "that, we only list the top ten most popular LLMs (based\n",
      "on Google search), since they are the search keywords\n",
      "for matching paper titles, rather than matching the pa-\n",
      "per content.\n",
      "----------\n",
      "The above search strategy based on the paper title can\n",
      "recall a large number of papers, and we further conduct the\n",
      "automatic filtering based on the paper content.\n",
      "----------\n",
      "Specifically,\n",
      "we filter the paper whose content contains “LLM” or “lan-\n",
      "guage model” or “generative model” or “large model” or\n",
      "the name of the LLMs (using the LLMs in [17], [24] except\n",
      "those in our exclusion criteria).\n",
      "----------\n",
      "This can help eliminate the\n",
      "papers that do not involve the neural models.\n",
      "----------\n",
      "3.1.2 Manual Search\n",
      "To compensate for the potential omissions that may result\n",
      "from automated searches, we also conduct manual searches.\n",
      "----------\n",
      "In order to make sure we collect highly relevant papers,\n",
      "we conduct a manual search within the conference proceed-\n",
      "ings and journal articles from top-tier software engineering\n",
      "venues (listed in Table 2).\n",
      "----------\n",
      "In addition, given the interdisciplinary nature of this\n",
      "work, we also include the conference proceedings of the\n",
      "artificial intelligence field.\n",
      "----------\n",
      "We select the top ten venues\n",
      "based on the h5 index from Google Scholar, and exclude\n",
      "three computer vision venues, i.e., CVPR, ICCV , ECCV , as\n",
      "listed in Table 2.\n",
      "----------\n",
      "3.1.3 Inclusion and Exclusion Criteria\n",
      "The search conducted on the databases and venue is, by de-\n",
      "sign, very inclusive.\n",
      "----------\n",
      "This allows us to collect as many papers\n",
      "as possible in our pool.\n",
      "----------\n",
      "However, this generous inclusivity\n",
      "results in having papers that are not directly related to the\n",
      "scope of this survey.\n",
      "----------\n",
      "Accordingly, we define a set of specific\n",
      "inclusion and exclusion criteria and then we apply them to\n",
      "each paper in the pool and remove papers not meeting the\n",
      "criteria.\n",
      "----------\n",
      "This ensures that each collected paper aligns with\n",
      "our scope and research questions.\n",
      "----------\n",
      "Inclusion Criteria.\n",
      "----------\n",
      "We define the following criteria for\n",
      "including papers:\n",
      "● The paper proposes or improves an approach, study, or\n",
      "tool/framework that targets testing specific software or\n",
      "systems with LLMs.\n",
      "----------\n",
      "● The paper applies LLMs to software testing practice,\n",
      "including all tasks within the software testing lifecycle\n",
      "as demonstrated in Section 2.2.\n",
      "----------\n",
      "● The paper presents an empirical or experimental study\n",
      "about utilizing LLMs in software testing practice.\n",
      "----------\n",
      "● The paper involves specific testing techniques (e.g.,\n",
      "fuzz testing) employing LLMs.\n",
      "----------\n",
      "If a paper satisfies any of the following criteria, we will\n",
      "include it.\n",
      "----------\n",
      "Exclusion Criteria.\n",
      "----------\n",
      "The following studies would be ex-\n",
      "cluded during study selection:\n",
      "● The paper does not involve software testing tasks, e.g.,\n",
      "code comment generation.\n",
      "----------\n",
      "● The paper does not utilize LLMs, e.g., using recurrent\n",
      "neural networks.\n",
      "----------\n",
      "● The paper mentions LLMs only in future work or dis-\n",
      "cussions rather than using LLMs in the approach.\n",
      "----------\n",
      "● The paper utilizes language models with encoder-only\n",
      "architecture, e.g., BERT, which can not directly be uti-\n",
      "lized for generation tasks (as demonstrated in Section\n",
      "2.1).\n",
      "----------\n",
      "● The paper focuses on testing the performance of LLMs,\n",
      "such as fairness, stability, security, etc.\n",
      "----------\n",
      "[125]–[127].\n",
      "----------\n",
      "● The paper focuses on evaluating the performance of\n",
      "LLM-enabled tools, e.g., evaluating the code quality of\n",
      "the code generation tool Copilot [128]–[130].\n",
      "----------\n",
      "For the papers collected through automatic search and\n",
      "manual search, we conduct a manual inspection to check\n",
      "whether they satisfy our inclusion criteria and filter those\n",
      "following our exclusion criteria.\n",
      "----------\n",
      "Specifically, the first two\n",
      "authors read each paper to carefully determine whether it5\n",
      "TABLE 1: Details of the collected papers\n",
      "ID Topic Paper title Year Reference\n",
      "1 Unit test case generation Unit Test Case Generation with Transformers and Focal Context 2020 [26]\n",
      "2 Unit test case generation Codet: Code Generation with Generated Tests 2022 [27]\n",
      "3 Unit test case generation Interactive Code Generation via Test-Driven User-Intent Formalization 2022 [28]\n",
      "4 Unit test case generation A3Test: Assertion-Augmented Automated Test Case Generation 2023 [29]\n",
      "5 Unit test case generation An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation 2023 [30]\n",
      "6 Unit test case generation An Initial Investigation of ChatGPT Unit Test Generation Capability 2023 [31]\n",
      "7 Unit test case generation Automated Test Case Generation Using Code Models and Domain Adaptation 2023 [32]\n",
      "8 Unit test case generation Automatic Generation of Test Cases based on Bug Reports: a Feasibility Study with Large Language Models 2023 [33]\n",
      "9 Unit test case generation Can Large Language Models Write Good Property-Based Tests?\n",
      "----------\n",
      "2023 [34]\n",
      "10 Unit test case generation CAT-LM Training Language Models on Aligned Code And Tests 2023 [35]\n",
      "11 Unit test case generation ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation 2023 [8]\n",
      "12 Unit test case generation ChatUniTest: a ChatGPT-based Automated Unit Test Generation Tool 2023 [36]\n",
      "13 Unit test case generation CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models 2023 [37]\n",
      "14 Unit test case generation Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing 2023 [38]\n",
      "15 Unit test case generation Exploring the Effectiveness of Large Language Models in Generating Unit Tests 2023 [39]\n",
      "16 Unit test case generation How Well does LLM Generate Security Tests?\n",
      "----------\n",
      "2023 [40]\n",
      "17 Unit test case generation No More Manual Tests?\n",
      "----------\n",
      "Evaluating and Improving ChatGPT for Unit Test Generation 2023 [7]\n",
      "18 Unit test case generation Prompting Code Interpreter to Write Better Unit Tests on Quixbugs Functions 2023 [41]\n",
      "19 Unit test case generation Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation 2023 [42]\n",
      "20 Unit test case generation Unit Test Generation using Generative AI: A Comparative Performance Analysis of Autogeneration Tools 2023 [43]\n",
      "21 Test oracle generation Generating Accurate Assert Statements for Unit Test Cases Using Pretrained Transformers 2022 [44]\n",
      "22 Test oracle generation Learning Deep Semantics for Test Completion 2023 [45]\n",
      "23 Test oracle generation; Program repairUsing Transfer Learning for Code-Related Tasks 2023 [46]\n",
      "24 Test oracle generation; Program repairRetrieval-Based Prompt Selection for Code-Related Few-Shot Learning 2023 [47]\n",
      "25 System test input generation Automated Conformance Testing for JavaScript Engines via Deep Compiler Fuzzing 2021 [48]\n",
      "26 System test input generation Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing 2022 [49]\n",
      "27 System test input generation Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors 2022 [50]\n",
      "28 System test input generation Slgpt: Using Transfer Learning to Directly Generate Simulink Model Files and Find Bugs in the Simulink Toolchain2021 [51]\n",
      "29 System test input generation Augmenting Greybox Fuzzing with Generative AI 2023 [52]\n",
      "30 System test input generation Automated Test Case Generation Using T5 and GPT-3 2023 [53]\n",
      "31 System test input generation Automating GUI-based Software Testing with GPT-3 2023 [54]\n",
      "32 System test input generation AXNav: Replaying Accessibility Tests from Natural Language 2023 [55]\n",
      "33 System test input generation Can ChatGPT Advance Software Testing Intelligence?\n",
      "----------\n",
      "An Experience Report on Metamorphic Testing 2023 [56]\n",
      "34 System test input generation Efficient Mutation Testing via Pre-Trained Language Models 2023 [57]\n",
      "35 System test input generation Large Language Models are Edge-Case Generators:Crafting Unusual Programs for Fuzzing Deep Learning Libraries2023 [58]\n",
      "36 System test input generation Large Language Models are Zero Shot Fuzzers: Fuzzing Deep Learning Libraries via Large Language Models2023 [59]\n",
      "37 System test input generation Large Language Models for Fuzzing Parsers (Registered Report) 2023 [60]\n",
      "38 System test input generation LLM for Test Script Generation and Migration: Challenges, Capabilities, and Opportunities 2023 [61]\n",
      "39 System test input generation Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions2023 [14]\n",
      "40 System test input generation PentestGPT: An LLM-empowered Automatic Penetration Testing Tool 2023 [62]\n",
      "41 System test input generation SMT Solver Validation Empowered by Large Pre-Trained Language Models 2023 [63]\n",
      "42 System test input generation TARGET: Automated Scenario Generation from Traffic Rules for Testing Autonomous Vehicles 2023 [64]\n",
      "43 System test input generation Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model2023 [65]\n",
      "44 System test input generation Understanding Large Language Model Based Fuzz Driver Generation 2023 [66]\n",
      "45 System test input generation Universal Fuzzing via Large Language Models 2023 [67]\n",
      "46 System test input generation Variable Discovery with Large Language Models for Metamorphic Testing of Scientific Software 2023 [68]\n",
      "47 System test input generation White-box Compiler Fuzzing Empowered by Large Language Models 2023 [69]\n",
      "48 Bug analysis Itiger: an Automatic Issue Title Generation Tool 2022 [70]\n",
      "49 Bug analysis CrashTranslator: Automatically Reproducing Mobile Application Crashes Directly from Stack Trace 2023 [71]\n",
      "50 Bug analysis Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report Detection 2023 [72]\n",
      "51 Bug analysis Employing Deep Learning and Structured Information Retrieval to Answer Clarification Questions on Bug Reports2023 [73]\n",
      "52 Bug analysis Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation 2022 [74]\n",
      "53 Bug analysis Prompting Is All Your Need: Automated Android Bug Replay with Large Language Models 2023 [75]\n",
      "54 Bug analysis Still Confusing for Bug-Component Triaging?\n",
      "----------\n",
      "Deep Feature Learning and Ensemble Setting to Rescue 2023 [76]\n",
      "55 Debug Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5 2022 [77]\n",
      "56 Debug Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction 2022 [78]\n",
      "57 Debug A Preliminary Evaluation of LLM-Based Fault Localization 2023 [79]\n",
      "58 Debug Addressing Compiler Errors: Stack Overflow or Large Language Models?\n",
      "----------\n",
      "2023 [80]\n",
      "59 Debug Can LLMs Demystify Bug Reports?\n",
      "----------\n",
      "2023 [81]\n",
      "60 Debug Dcc –help: Generating Context-Aware Compiler Error Explanations with Large Language Models 2023 [82]\n",
      "61 Debug Explainable Automated Debugging via Large Language Model-driven Scientific Debugging 2023 [83]\n",
      "62 Debug Large Language Models for Test-Free Fault Localization 2023 [84]\n",
      "63 Debug Large Language Models in Fault Localisation 2023 [85]\n",
      "64 Debug LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation 2023 [86]\n",
      "65 Debug Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting 2023 [87]\n",
      "66 Debug Teaching Large Language Models to Self-Debug 2023 [88]\n",
      "67 Debug; Program repair A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair 2023 [89]\n",
      "68 Program repair Examining Zero-Shot Vulnerability Repair with Large Language Models 2022 [90]\n",
      "69 Program repair Automated Repair of Programs from Large Language Models 2022 [91]\n",
      "70 Program repair Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar 2022 [92]\n",
      "71 Program repair Practical Program Repair in the Era of Large Pre-trained Language Models 2022 [93]\n",
      "72 Program repair Repairing Bugs in Python Assignments Using Large Language Models 2022 [94]\n",
      "73 Program repair Towards JavaScript Program Repair with Generative Pre-trained Transformer (GPT-2) 2022 [95]\n",
      "74 Program repair An Analysis of the Automatic Bug Fixing Performance of ChatGPT 2023 [96]\n",
      "75 Program repair An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair 2023 [97]\n",
      "76 Program repair An Evaluation of the Effectiveness of OpenAI’s ChatGPT for Automated Python Program Bug Fixing using QuixBugs2023 [98]\n",
      "77 Program repair An Extensive Study on Model Architecture and Program Representation in the Domain of Learning-based Automated Program Repair2023 [99]\n",
      "78 Program repair Can OpenAI’s Codex Fix Bugs?\n",
      "----------\n",
      "An Evaluation on QuixBugs 2022 [100]\n",
      "79 Program repair CIRCLE: Continual Repair Across Programming Languages 2022 [101]\n",
      "80 Program repair Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback 2023 [102]\n",
      "81 Program repair Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair2023 [103]\n",
      "82 Program repair Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors 2023 [104]\n",
      "83 Program repair Enhancing Genetic Improvement Mutations Using Large Language Models 2023 [105]\n",
      "84 Program repair FixEval: Execution-based Evaluation of Program Fixes for Programming Problems 2023 [106]\n",
      "85 Program repair Fixing Hardware Security Bugs with Large Language Models 2023 [107]\n",
      "86 Program repair Fixing Rust Compilation Errors using LLMs 2023 [108]\n",
      "87 Program repair Framing Program Repair as Code Completion 2022 [109]\n",
      "88 Program repair Frustrated with Code Quality Issues?\n",
      "----------\n",
      "LLMs can Help!\n",
      "----------\n",
      "2023 [110]\n",
      "89 Program repair GPT-3-Powered Type Error Debugging: Investigating the Use of Large Language Models for Code Repair 2023 [111]\n",
      "90 Program repair How Effective Are Neural Networks for Fixing Security Vulnerabilities 2023 [112]\n",
      "91 Program repair Impact of Code Language Models on Automated Program Repair 2023 [113]\n",
      "92 Program repair Inferfix: End-to-end Program Repair with LLMs 2023 [114]\n",
      "93 Program repair Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT 2023 [115]\n",
      "94 Program repair Neural Program Repair with Program Dependence Analysis and Effective Filter Mechanism 2023 [116]\n",
      "95 Program repair Out of Context: How important is Local Context in Neural Program Repair?\n",
      "----------\n",
      "2023 [117]\n",
      "96 Program repair Pre-trained Model-based Automated Software Vulnerability Repair: How Far are We?\n",
      "----------\n",
      "2023 [118]\n",
      "97 Program repair RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot 2023 [119]\n",
      "98 Program repair RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic Program Repair 2023 [120]\n",
      "99 Program repair STEAM: Simulating the InTeractive BEhavior of ProgrAMmers for Automatic Bug Fixing 2023 [121]\n",
      "100 Program repair Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions 2023 [122]\n",
      "101 Program repair VulRepair: a T5-based Automated Software Vulnerability Repair 2022 [123]\n",
      "102 Program repair What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?\n",
      "----------\n",
      "2023 [124]6\n",
      "TABLE 2: Conference proceedings and journals considered\n",
      "for manual search\n",
      "Acronym Venue\n",
      "SE Conference\n",
      "ICSE International Conference on Software EngineeringESEC/FSE Joint European Software Engineering Conference and Symposium on theFoundations of Software EngineeringASE International Conference on Automated Software EngineeringISSTA International Symposium on Software Testing and AnalysisICST International Conference on Software Testing, Verification and ValidationESEM International Symposium on Empirical Software Engineering and Mea-surementMSR International Conference on Mining Software RepositoriesQRS International Conference on Software Quality, Reliability and SecurityICSME International Conference on Software Maintenance and EvolutionISSRE International Symposium on Software Reliability Engineering\n",
      "SE Journal\n",
      "TSE Transactions on Software EngineeringTOSEM Transactions on Software Engineering and MethodologyEMSE Empirical Software EngineeringASE Automated Software EngineeringJSS Journal of Systems and SoftwareJSEP Journal of Software: Evolution and ProcessSTVR Software Testing, Verification and ReliabilityIEEE SOFTW.\n",
      "----------\n",
      "IEEE SoftwareIET SOFTW.\n",
      "----------\n",
      "IET SoftwareIST Information and Software TechnologySQJ Software Quality Journal\n",
      "AI Venues\n",
      "ICLR International Conference on Learning RepresentationsNeurIPS Conference on Neural Information Processing SystemsICML International Conference on Machine LearningAAAI AAAI Conference on Artificial IntelligenceEMNLP Conference on Empirical Methods in Natural Language ProcessingACL Annual Meeting of the Association for Computational LinguisticsIJCAI International Joint Conference on Artificial Intelligence\n",
      "should be included based on the inclusion criteria and exclu-\n",
      "sion criteria, and any paper with different decisions will be\n",
      "handed over to the third author to make the final decision.\n",
      "----------\n",
      "3.1.4 Quality Assessment\n",
      "In addition, we establish quality assessment criteria to ex-\n",
      "clude low-quality studies as shown below.\n",
      "----------\n",
      "For each ques-\n",
      "tion, the study’s quality is rated as “yes”, “partial” or “no”\n",
      "which are assigned values of 1, 0.5, and 0, respectively.\n",
      "----------\n",
      "Pa-\n",
      "pers with a score of less than eight will be excluded from\n",
      "our study.\n",
      "----------\n",
      "● Is there a clearly stated research goal related to software\n",
      "testing?\n",
      "----------\n",
      "● Is there a defined and repeatable technique?\n",
      "----------\n",
      "● Is there any explicit contribution to software testing?\n",
      "----------\n",
      "● Is there an explicit description of which LLMs are uti-\n",
      "lized?\n",
      "----------\n",
      "● Is there an explicit explanation about how the LLMs are\n",
      "utilized?\n",
      "----------\n",
      "● Is there a clear methodology for validating the tech-\n",
      "nique?\n",
      "----------\n",
      "● Are the subject projects selected for validation suitable\n",
      "for the research goals?\n",
      "----------\n",
      "● Are there control techniques or baselines to demon-\n",
      "strate the effectiveness of the proposed technique?\n",
      "----------\n",
      "● Are the evaluation metrics relevant (e.g., evaluate the\n",
      "effectiveness of the proposed technique) to the research\n",
      "objectives?\n",
      "----------\n",
      "● Do the results presented in the study align with the\n",
      "research objectives and are they presented in a clear\n",
      "and relevant manner?\n",
      "----------\n",
      "3.1.5 Snowballing\n",
      "At the end of searching database repositories and confer-\n",
      "ence proceedings and journals, and applying inclusion/ex-\n",
      "clusion criteria and quality assessment, we obtain the initial\n",
      "set of papers.\n",
      "----------\n",
      "Next, to mitigate the risk of omitting rele-\n",
      "vant literature from this survey, we also perform backward\n",
      "/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000013/uni00000015/uni00000014/uni00000015/uni00000013/uni00000015/uni00000015/uni00000015/uni00000013/uni00000015/uni00000016/uni00000003\n",
      "/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000003c/uni00000048/uni00000044/uni00000055\n",
      "/uni00000013\n",
      "/uni00000018/uni00000013\n",
      "/uni00000014/uni00000013/uni00000013\n",
      "/uni00000014/uni00000018/uni00000013\n",
      "/uni00000015/uni00000013/uni00000013/uni00000006/uni00000003/uni00000033/uni00000058/uni00000045/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\n",
      "/uni00000014/uni00000015\n",
      "/uni00000014/uni0000001c\n",
      "/uni0000001b/uni00000015\n",
      "Fig.\n",
      "----------\n",
      "3: Trend in the number of papers with year\n",
      "snowballing [131] by inspecting the references cited by the\n",
      "collected papers so far.\n",
      "----------\n",
      "Note that, this procedure did not in-\n",
      "clude new studies, which might because the surveyed topic\n",
      "is quite new and the reference studies tend to published pre-\n",
      "viously, and we already include a relatively comprehensive\n",
      "automatic and manual search.\n",
      "----------\n",
      "3.2 Collection Results\n",
      "As shown in Figure 2, the collection process started\n",
      "with a total of 14,623 papers retrieved from four\n",
      "academic databases employing keyword searching.\n",
      "----------\n",
      "Then after automated filtering, manual search, applying\n",
      "inclusion/exclusion criteria, and quality assessment, we\n",
      "finally collected a total of 102 papers involving software\n",
      "testing with LLMs.\n",
      "----------\n",
      "Table 1 shows the details of the collected\n",
      "papers.\n",
      "----------\n",
      "Besides, we also use Table 5 (at the end of the\n",
      "paper) to provide a more comprehensive overview of these\n",
      "papers regarding the specific characteristics which will be\n",
      "illustrated in Section 4 and Section 5.\n",
      "----------\n",
      "Note that, there are two studies which are respectively\n",
      "the extension of a previously published paper by the same\n",
      "authors ( [46] and [132], [68] and [133]), and we only keep\n",
      "the extended version to avoid duplicate.\n",
      "----------\n",
      "3.3 General Overview of Collected Paper\n",
      "Among the papers, 47% papers are published in software\n",
      "engineering venues, among which 19 papers are from ICSE,\n",
      "5 papers are from FSE, 5 papers are from ASE, and 3 pa-\n",
      "pers are from ISSTA.\n",
      "----------\n",
      "2% papers are published in artificial\n",
      "intelligence venues such as EMNLP and ICLR, and 5% pa-\n",
      "pers are published in program analysis or security venues\n",
      "like PLDI and S&P .\n",
      "----------\n",
      "Besides, 46% of the papers have not\n",
      "yet been published via peer-reviewed venues, i.e., they are\n",
      "disclosed on arXiv.\n",
      "----------\n",
      "This is understandable because this field\n",
      "is emerging and many works are just completed and in\n",
      "the process of submission.\n",
      "----------\n",
      "Although these papers did not\n",
      "undergo peer review, we have a quality assessment process\n",
      "that eliminates papers with low quality, which potentially\n",
      "ensures the quality of this survey.\n",
      "----------\n",
      "Figure 3 demonstrates the trend of our collected papers\n",
      "per year.\n",
      "----------\n",
      "We can see that as the years go by, the number of\n",
      "papers in this field is growing almost exponentially.\n",
      "----------\n",
      "In 2020\n",
      "and 2021, there were only 1 and 2 papers, respectively.\n",
      "----------\n",
      "In\n",
      "2022, there were 19 papers, and in 2023, there have been 827\n",
      "Fig.\n",
      "----------\n",
      "4: Distribution of testing tasks with LLMs (aligned with software testing life cycle [134]–[136], the number in bracket\n",
      "indicates the number of collected studies per task, and one paper might involve multiple tasks)\n",
      "papers.\n",
      "----------\n",
      "It is conceivable that there will be even more papers\n",
      "in the future, which indicates the popularity and attention\n",
      "that this field is receiving.\n",
      "----------\n",
      "4 A NALYSIS FROM SOFTWARE TESTING PER-\n",
      "SPECTIVE\n",
      "This section presents our analysis from the viewpoint of\n",
      "software testing and organizes the collected studies in terms\n",
      "of testing tasks.\n",
      "----------\n",
      "Figure 4 lists the distribution of each in-\n",
      "volved testing task, aligned with the software testing life\n",
      "cycle.\n",
      "----------\n",
      "We first provide a general overview of the distribu-\n",
      "tion, followed by further analysis for each task.\n",
      "----------\n",
      "Note that,\n",
      "for each following subsection, the cumulative total of sub-\n",
      "categories may not always match the total number of papers\n",
      "since a paper might belong to more than one subcategory.\n",
      "----------\n",
      "We can see that LLMs have been effectively used in both\n",
      "the mid to late stages of the software testing lifecycle.\n",
      "----------\n",
      "In\n",
      "the test case preparation phase, LLMs have been utilized for\n",
      "tasks such as generating unit test cases, test oracle genera-\n",
      "tion, and system test input generation.\n",
      "----------\n",
      "These tasks are cru-\n",
      "cial in the mid-phase of software testing to help catch issues\n",
      "and prevent further development until issues are resolved.\n",
      "----------\n",
      "Furthermore, in later phases such as the test report/bug re-\n",
      "ports and bug fix phase, LLMs have been employed for tasks\n",
      "such as bug analysis, debugging, and repair.\n",
      "----------\n",
      "These tasks are\n",
      "critical towards the end of the testing phase when software\n",
      "bugs need to be resolved to prepare for the product’s release.\n",
      "----------\n",
      "4.1 Unit Test Case Generation\n",
      "Unit test case generation involves writing unit test cases to\n",
      "check individual units/components of the software inde-\n",
      "pendently and ensure that they work correctly.\n",
      "----------\n",
      "For a method\n",
      "under test (i.e., often called the focal method), its corre-\n",
      "sponding unit test consists of a test prefix and a test oracle.\n",
      "----------\n",
      "In particular, the test prefix is typically a series of method\n",
      "invocation statements or assignment statements, which aims\n",
      "at driving the focal method to a testable state; and then the\n",
      "test oracle serves as the specification to check whether the\n",
      "current behavior of the focal method satisfies the expected\n",
      "one, e.g., the test assertion.\n",
      "----------\n",
      "To alleviate manual efforts in writing unit tests,\n",
      "researchers have proposed various techniques to facilitate\n",
      "automated unit test generation.\n",
      "----------\n",
      "Traditional unit test\n",
      "generation techniques leverage search-based [3], [4],\n",
      "constraint-based [5] or random-based strategies [6] to\n",
      "generate a suite of unit tests with the main goal of\n",
      "maximizing the coverage in the software under test.\n",
      "----------\n",
      "Nevertheless, the coverage and the meaningfulness of the\n",
      "generated tests are still far from satisfactory.\n",
      "----------\n",
      "Since LLMs have demonstrated promising results in\n",
      "tasks such as code generation, and given that both code\n",
      "generation and unit test case generation involve generating\n",
      "source code, recent research has extended the domain of\n",
      "code generation to encompass unit test case generation.\n",
      "----------\n",
      "Despite initial success, there are nuances that set unit\n",
      "test case generation apart from general code generation,\n",
      "signaling the need for more tailored approaches.\n",
      "----------\n",
      "Pre-training or fine-tuning LLMs for unit test case\n",
      "generation.\n",
      "----------\n",
      "Due to the limitations of LLMs in their earlier\n",
      "stages, a majority of the earlier published studies adopt\n",
      "this pre-training or fine-tuning schema.\n",
      "----------\n",
      "Moreover, in some\n",
      "recent studies, this schema continues to be employed to\n",
      "increase the LLMs’ familiarity with domain knowledge.\n",
      "----------\n",
      "Alagarsamy et al.\n",
      "----------\n",
      "[29] first pre-trained the LLM with the\n",
      "focal method and asserted statements to enable the LLM to\n",
      "have a stronger foundation knowledge of assertions, then\n",
      "fine-tuned the LLM for the test case generation task where\n",
      "the objective is to learn the relationship between the focal\n",
      "method and the corresponding test case.\n",
      "----------\n",
      "Tufano et al.\n",
      "----------\n",
      "[26]\n",
      "utilized a similar schema by pre-training the LLM on a\n",
      "large unsupervised Java corpus, and supervised fine-tuning\n",
      "a downstream translation task for generating unit tests.\n",
      "----------\n",
      "Hashtroudi et al.\n",
      "----------\n",
      "[32] leveraged the existing developer-\n",
      "written tests for each project to generate a project-specific\n",
      "dataset for domain adaptation when fine-tuning the LLM,\n",
      "which can facilitate generating human-readable unit tests.\n",
      "----------\n",
      "Rao et al.\n",
      "----------\n",
      "[35] trained a GPT-style language model by\n",
      "utilizing a pre-training signal that explicitly considers the\n",
      "mapping between code and test files.\n",
      "----------\n",
      "Steenhoek et al.\n",
      "----------\n",
      "[42] utilizes reinforcement learning to optimize models by\n",
      "providing rewards based on static quality metrics that can\n",
      "be automatically computed for the generated unit test cases.\n",
      "----------\n",
      "Designing effective prompts for unit test case genera-\n",
      "tion.\n",
      "----------\n",
      "The advancement of LLMs has allowed them to excel\n",
      "at targeted tasks without pre-training or fine-tuning.\n",
      "----------\n",
      "There-\n",
      "fore most later studies typically focus on how to design\n",
      "the prompt, to make the LLM better at understanding the\n",
      "context and nuances of this task.\n",
      "----------\n",
      "Xie et al.\n",
      "----------\n",
      "[36] generated\n",
      "unit test cases by parsing the project, extracting essential\n",
      "information, and creating an adaptive focal context that in-\n",
      "cludes a focal method and its dependencies within the pre-\n",
      "defined maximum prompt token limit of the LLM, and in-\n",
      "corporating these context into a prompt to query the LLM.8\n",
      "TABLE 3: Performance of unit test case generation\n",
      "Dataset Correctness Coverage LLM Paper\n",
      "5 Java projects from Defects4J 16.21% 5%-13% (line coverage) BART [26]\n",
      "10 Jave projects 40% 89% (line coverage), 90% (branch coverage) ChatGPT [36]\n",
      "CodeSearchNet 41% N/A ChatGPT [7]\n",
      "HumanEval 78% 87% (line coverage), 92% (branch coverage) Codex [39]\n",
      "SF110 2% 2% (line coverage), 1% (branch coverage) Codex [39]\n",
      "Note that, [39] experiments with Codex, CodeGen, and ChatGPT, and the best performance was achieved by Codex.\n",
      "----------\n",
      "Dakhel et al.\n",
      "----------\n",
      "[38] introduced MuTAP for improving the ef-\n",
      "fectiveness of test cases generated by LLMs in terms of re-\n",
      "vealing bugs by leveraging mutation testing.\n",
      "----------\n",
      "They augment\n",
      "prompts with surviving mutants, as those mutants highlight\n",
      "the limitations of test cases in detecting bugs.\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "[40] generated security tests with vulnerable dependencies\n",
      "with LLMs.\n",
      "----------\n",
      "Yuan et al.\n",
      "----------\n",
      "[7] first performed an empirical study to eval-\n",
      "uate ChatGPT’s capability of unit test generation with both\n",
      "a quantitative analysis and a user study in terms of cor-\n",
      "rectness, sufficiency, readability, and usability.\n",
      "----------\n",
      "And results\n",
      "show that the generated tests still suffer from correctness\n",
      "issues, including diverse compilation errors and execution\n",
      "failures.\n",
      "----------\n",
      "They further propose an approach that leveraged\n",
      "the ChatGPT itself to improve the quality of its generated\n",
      "tests with an initial test generator and an iterative test re-\n",
      "finer.\n",
      "----------\n",
      "Specifically, the iterative test refiner iteratively fixed\n",
      "the compilation errors in the tests generated by the initial\n",
      "test generator, which follows a validate-and-fix paradigm to\n",
      "prompt the LLM based on the compilation error messages\n",
      "and additional code context.\n",
      "----------\n",
      "Guilherme et al.\n",
      "----------\n",
      "[31] and Li\n",
      "et al.\n",
      "----------\n",
      "[41] respectively evaluated the quality of the gener-\n",
      "ated unit tests by LLM using different metrics and different\n",
      "prompts.\n",
      "----------\n",
      "Test generation with additional documentation.\n",
      "----------\n",
      "Vikram et al.\n",
      "----------\n",
      "[34] went a step further by investigating the\n",
      "potential of using LLMs to generate property-based tests\n",
      "when provided API documentation.\n",
      "----------\n",
      "They believe that the\n",
      "documentation of an API method can assist the LLM in\n",
      "producing logic to generate random inputs for that method\n",
      "and deriving meaningful properties of the result to check.\n",
      "----------\n",
      "Instead of generating unit tests from the source code, Plein\n",
      "et al.\n",
      "----------\n",
      "[33] generated the tests based on user-written bug\n",
      "reports.\n",
      "----------\n",
      "LLM and search-based method for unit test generation.\n",
      "----------\n",
      "The aforementioned studies utilize LLMs for the whole unit\n",
      "test case generation task, while Lemieux et al.\n",
      "----------\n",
      "[37] focus on\n",
      "a different direction, i.e., first letting the traditional search-\n",
      "based software testing techniques (e.g., Pynguin [137]) in\n",
      "generating unit test case until its coverage improvements\n",
      "stall, then asking the LLM to provide the example test cases\n",
      "for under-covered functions.\n",
      "----------\n",
      "These examples can help the\n",
      "original test generation redirect its search to more useful\n",
      "areas of the search space.\n",
      "----------\n",
      "Tang et al.\n",
      "----------\n",
      "[8] conducts a systematic comparison of test\n",
      "suites generated by the LLM and the state-of-the-art search-\n",
      "based software testing tool EvoSuite, by considering the cor-\n",
      "rectness, readability, code coverage, and bug detection ca-\n",
      "pability.\n",
      "----------\n",
      "Similarly, Bhatia [43] experimentally investigates\n",
      "the quality of unit tests generated by LLM compared to a\n",
      "commonly-used test generator Pynguin.\n",
      "----------\n",
      "Performance of unit test case generation.\n",
      "----------\n",
      "Since the\n",
      "aforementioned studies of unit test case generation are\n",
      "based on different datasets, one can hardly derive a fair\n",
      "comparison and we present the details in Table 3 to let\n",
      "the readers obtain a general view.\n",
      "----------\n",
      "We can see that in the\n",
      "SF110 benchmark, all three evaluated LLMs have quite low\n",
      "performance, i.e., 2% coverage [39].\n",
      "----------\n",
      "SF110 is an Evosuite\n",
      "(a search-based unit test case generation technique)\n",
      "benchmark consisting of 111 open-source Java projects\n",
      "retrieved from SourceForge, containing 23,886 classes, over\n",
      "800,000 bytecode-level branches, and 6.6 million lines of\n",
      "code.\n",
      "----------\n",
      "The authors did not present detailed reasons for the\n",
      "low performance which can be further explored in the\n",
      "future.\n",
      "----------\n",
      "4.2 Test Oracle Generation\n",
      "A test oracle is a source of information about whether the\n",
      "output of a software system (or program or function or\n",
      "method) is correct or not [138].\n",
      "----------\n",
      "Most of the collected studies\n",
      "in this category target the test assertion generation, which is\n",
      "inside a unit test case.\n",
      "----------\n",
      "Nevertheless, we opted to treat these\n",
      "studies as separate sections to facilitate a more thorough\n",
      "analysis.\n",
      "----------\n",
      "Test assertion, which is to indicate the potential issues\n",
      "in the tested code, is an important aspect that can distin-\n",
      "guish the unit test cases from the regular code.\n",
      "----------\n",
      "This is why\n",
      "some studies specifically focus on the generation of effec-\n",
      "tive test assertions.\n",
      "----------\n",
      "Actually, before using LLMs, researchers\n",
      "have proposed RNN-based approaches that aim at learning\n",
      "from thousands of unit test methods to generate meaning-\n",
      "ful assert statements [139], yet only 17% of the generated\n",
      "asserts can exactly match with the ground truth asserts.\n",
      "----------\n",
      "Sub-\n",
      "sequently, to improve the performance, several researchers\n",
      "utilized the LLMs for this task.\n",
      "----------\n",
      "Mastropaolo et al.\n",
      "----------\n",
      "[46], [132] pre-trained a T5 model on\n",
      "a dataset composed of natural language English text and\n",
      "source code.\n",
      "----------\n",
      "Then, it fine-tuned such a model by reusing\n",
      "datasets used in four previous works that used deep learn-\n",
      "ing techniques (such as RNN as mentioned before) includ-\n",
      "ing test assertion generation and program repair, etc.\n",
      "----------\n",
      "Results\n",
      "showed that the extract match rate of the generated test\n",
      "assertion is 57%.\n",
      "----------\n",
      "Tufano et al.\n",
      "----------\n",
      "[44] proposed a similar ap-\n",
      "proach which separately pre-trained the LLM with English\n",
      "corpus and code corpus, and then fine-tuned it on the asserts\n",
      "dataset (with test methods, focal methods, and asserts).\n",
      "----------\n",
      "This\n",
      "further improved the performance to 62% of the exact match\n",
      "rate.\n",
      "----------\n",
      "Besides the syntax-level data as previous studies, Nie et\n",
      "al.\n",
      "----------\n",
      "[45] fine-tuned the LLMs with six kinds of code semantics\n",
      "data, including the execution result (e.g., types of the local\n",
      "variables) and execution context (e.g., the last called method\n",
      "in the test method), which enabled LLMs to learn to under-\n",
      "stand the code execution information.\n",
      "----------\n",
      "The exact match rate9\n",
      "is 17% (note that this paper is based on a different dataset\n",
      "from all other studies mentioned under this topic).\n",
      "----------\n",
      "The aforementioned studies utilized the pre-training and\n",
      "fine-tuning schema when using LLMs, and with the increas-\n",
      "ingly powerful capabilities of LLMs, they can perform well\n",
      "on specific tasks without these specialized pre-training or\n",
      "fine-tuning datasets.\n",
      "----------\n",
      "Subsequently, Nashid et al.\n",
      "----------\n",
      "[47] uti-\n",
      "lized prompt engineering for this task, and proposed a tech-\n",
      "nique for prompt creation that automatically retrieves code\n",
      "demonstrations similar to the task, based on embedding\n",
      "or frequency analysis.\n",
      "----------\n",
      "They also present evaluations about\n",
      "the few-shot learning with various numbers (e.g., zero-shot,\n",
      "one-shot, or n-shot) and forms (e.g., random vs. systematic,\n",
      "or with vs. without natural language descriptions) of the\n",
      "prompts, to investigate its feasibility on test assertion gen-\n",
      "eration.\n",
      "----------\n",
      "With only a few relevant code demonstrations, this\n",
      "approach can achieve an accuracy of 76% for exact matches\n",
      "in test assertion generation, which is the state-of-the-art per-\n",
      "formance for this task.\n",
      "----------\n",
      "4.3 System Test Input Generation\n",
      "This category encompasses the studies related to creating\n",
      "test input of system testing for enabling the automation of\n",
      "test execution.\n",
      "----------\n",
      "We employ three subsections to present the\n",
      "analysis from three different orthogonal viewpoints, and\n",
      "each of the collected studies may be analyzed in one or\n",
      "more of these subsections.\n",
      "----------\n",
      "The first subsection is input generation in terms of software\n",
      "types.\n",
      "----------\n",
      "The generation of system-level test inputs for software\n",
      "testing varies for specific types of software being tested.\n",
      "----------\n",
      "For\n",
      "example, for mobile applications, the test input generation\n",
      "requires providing a diverse range of text inputs or oper-\n",
      "ation combinations (e.g., click a button, long press a list)\n",
      "[14], [49], which is the key to testing the application’s func-\n",
      "tionality and user interface; while for Deep Learning (DL)\n",
      "libraries, the test input is a program which covers diversified\n",
      "DL APIs [58], [59].\n",
      "----------\n",
      "This subsection will demonstrate how the\n",
      "LLMs are utilized to generate inputs for different types of\n",
      "software.\n",
      "----------\n",
      "The second subsection input generation in terms of testing\n",
      "techniques.\n",
      "----------\n",
      "We have observed that certain approaches serve\n",
      "as specific types of testing techniques.\n",
      "----------\n",
      "For example, dozens\n",
      "of our collected studies specifically focus on using LLMs\n",
      "for fuzz testing.\n",
      "----------\n",
      "Therefore, this subsection would provide\n",
      "an analysis of the collected studies in terms of testing tech-\n",
      "niques, showcasing how the LLMs are employed to enhance\n",
      "traditional testing techniques.\n",
      "----------\n",
      "The third subsection input generation in terms of input and\n",
      "output.\n",
      "----------\n",
      "While most of the collected studies take the source\n",
      "code or the software itself as the input and directly output\n",
      "the software’s test input, there are studies that utilize alter-\n",
      "native forms of input and output.\n",
      "----------\n",
      "This subsection would\n",
      "provide an analysis of such studies, highlighting different\n",
      "approaches and their input-output characteristics.\n",
      "----------\n",
      "4.3.1 Input Generation in Terms of Software Types\n",
      "Figure 5 demonstrates the types of software under test in\n",
      "our collected studies.\n",
      "----------\n",
      "It is evident that the most prominent\n",
      "category is mobile apps, with five studies utilizing LLMs\n",
      "for testing, possibly due to their prevalence and importance\n",
      "/uni00000013/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000030/uni00000052/uni00000045/uni0000004c/uni0000004f/uni00000048/uni00000003/uni00000044/uni00000053/uni00000053\n",
      "/uni00000027/uni00000048/uni00000048/uni00000053/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004f/uni0000004c/uni00000045/uni00000055/uni00000044/uni00000055/uni0000005c\n",
      "/uni00000026/uni00000052/uni00000050/uni00000053/uni0000004c/uni0000004f/uni00000048/uni00000055\n",
      "/uni00000036/uni00000030/uni00000037/uni00000003/uni00000056/uni00000052/uni0000004f/uni00000059/uni00000048/uni00000055\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000051/uni00000052/uni00000050/uni00000052/uni00000058/uni00000056/uni00000003/uni00000047/uni00000055/uni0000004c/uni00000059/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni00000026/uni0000005c/uni00000045/uni00000048/uni00000055/uni00000003/uni00000053/uni0000004b/uni0000005c/uni00000056/uni0000004c/uni00000046/uni00000044/uni0000004f/uni00000003/uni00000056/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050\n",
      "/uni0000002a/uni00000032/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051\n",
      "/uni0000002d/uni00000044/uni00000059/uni00000044/uni00000036/uni00000046/uni00000055/uni0000004c/uni00000053/uni00000057/uni00000003/uni00000048/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048\n",
      "/uni00000034/uni00000058/uni00000044/uni00000051/uni00000057/uni00000058/uni00000050/uni00000003/uni00000046/uni00000052/uni00000050/uni00000053/uni00000058/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000053/uni0000004f/uni00000044/uni00000057/uni00000049/uni00000052/uni00000055/uni00000050\n",
      "/uni00000039/uni0000004c/uni00000047/uni00000048/uni00000052/uni00000003/uni0000004a/uni00000044/uni00000050/uni00000048\n",
      "/uni00000036/uni00000052/uni00000049/uni00000057/uni0000005a/uni00000044/uni00000055/uni00000048/uni00000003/uni00000038/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000037/uni00000048/uni00000056/uni00000057\n",
      "/uni00000018\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000015\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "Fig.\n",
      "----------\n",
      "5: Distribution of software under test\n",
      "in today’s business and daily life.\n",
      "----------\n",
      "Additionally, there are\n",
      "respectively two studies focusing on testing deep learning\n",
      "libraries, compilers, and SMT solvers.\n",
      "----------\n",
      "Moreover, LLM-based\n",
      "testing techniques have also been applied to domains such\n",
      "as cyber-physical systems, quantum computing platforms,\n",
      "and more.\n",
      "----------\n",
      "This widespread adoption of LLMs demonstrates\n",
      "their effectiveness in handling diverse test inputs and en-\n",
      "hancing testing activities across various software domains.\n",
      "----------\n",
      "A detailed analysis is provided below.\n",
      "----------\n",
      "Test input generation for mobile apps.\n",
      "----------\n",
      "For mobile app\n",
      "testing, one difficulty is to generate the appropriate text in-\n",
      "puts to proceed to the next page, which remains a prominent\n",
      "obstacle for testing coverage.\n",
      "----------\n",
      "Considering the diversity and\n",
      "semantic requirement of valid inputs (e.g., flight departure,\n",
      "movie name), traditional techniques with heuristic-based or\n",
      "constraint-based techniques [10], [140] are far from generat-\n",
      "ing meaningful text input.\n",
      "----------\n",
      "Liu et al.\n",
      "----------\n",
      "[49] employ the LLM\n",
      "to intelligently generate the semantic input text according\n",
      "to the GUI context.\n",
      "----------\n",
      "In detail, their proposed QTypist auto-\n",
      "matically extracts the component information related to the\n",
      "EditText for generating the prompts, and then inputs the\n",
      "prompts into the LLM to generate the input text.\n",
      "----------\n",
      "Besides the text input, there are other forms of input\n",
      "for mobile apps, i.e., operations like ‘click a button’ and\n",
      "‘select a list’.\n",
      "----------\n",
      "To fully test an app, it is required to cover\n",
      "more GUI pages and conduct more meaningful exploration\n",
      "traces through the GUI operations, yet existing studies with\n",
      "random-/rule-based methods [9], [10], model-based meth-\n",
      "ods [11], [12], and learning-based methods [13] are unable\n",
      "to understand the semantic information of the GUI page\n",
      "thus could not conduct the trace planning effectively.\n",
      "----------\n",
      "Liu et\n",
      "al.\n",
      "----------\n",
      "[14] formulates the test input generation of mobile GUI\n",
      "testing problem as a Q&A task, which asks LLM to chat\n",
      "with the mobile apps by passing the GUI page information\n",
      "to LLM to elicit testing scripts (i.e., GUI operation), and\n",
      "executing them to keep passing the app feedback to LLM, it-\n",
      "erating the whole process.\n",
      "----------\n",
      "The proposed GPTDroid extracts\n",
      "the static context of the GUI page and the dynamic context\n",
      "of the iterative testing process, and designs prompts for in-\n",
      "putting this information to LLM which enables the LLM to\n",
      "better understand the GUI page as well as the whole testing\n",
      "process.\n",
      "----------\n",
      "It also introduces a functionality-aware memory\n",
      "prompting mechanism that equips the LLM with the abil-\n",
      "ity to retain testing knowledge of the whole process and\n",
      "conduct long-term, functionality-based reasoning to guide\n",
      "exploration.\n",
      "----------\n",
      "Similarly, Zimmermann et al.\n",
      "----------\n",
      "utilize the LLM to10\n",
      "interpret natural language test cases and programmatically\n",
      "navigate through the application under test [54].\n",
      "----------\n",
      "Yu et al.\n",
      "----------\n",
      "[61] investigate the LLM’s capabilities in the\n",
      "mobile app test script generation and migration task, in-\n",
      "cluding the scenario-based test generation, and the cross-\n",
      "platform/app test migration.\n",
      "----------\n",
      "Test input generation for DL libraries.\n",
      "----------\n",
      "The input for\n",
      "testing DL libraries is DL programs, and the difficulty\n",
      "in generating the diversified input DL programs is that\n",
      "they need to satisfy both the input language (e.g., Python)\n",
      "syntax/semantics and the API input/shape constraints for\n",
      "tensor computations.\n",
      "----------\n",
      "Traditional techniques with API-level\n",
      "fuzzing [141], [142] or model-level fuzzing [143], [144]\n",
      "suffer from the following limitations: 1) lack of diverse API\n",
      "sequence thus cannot reveal bugs caused by chained API\n",
      "sequences; 2) cannot generate arbitrary code thus cannot\n",
      "explore the huge search space that exists when using the DL\n",
      "libraries.\n",
      "----------\n",
      "Since LLMs can include numerous code snippets\n",
      "invoking DL library APIs in their training corpora, they\n",
      "can implicitly learn both language syntax/semantics and\n",
      "intricate API constraints for valid DL program generation.\n",
      "----------\n",
      "Taken in this sense, Deng et al.\n",
      "----------\n",
      "[59] used both generative\n",
      "and infilling LLMs to generate and mutate valid/diverse\n",
      "input DL programs for fuzzing DL libraries.\n",
      "----------\n",
      "In detail, it first\n",
      "uses a generative LLM (CodeX) to generate a set of seed\n",
      "programs (i.e., code snippets that use the target DL APIs).\n",
      "----------\n",
      "Then it replaces part of the seed program with masked\n",
      "tokens using different mutation operators and leverages the\n",
      "ability of infilling LLM (InCoder) to perform code infilling\n",
      "to generate new code that replaces the masked tokens.\n",
      "----------\n",
      "Their\n",
      "follow-up study [58] goes a step further to prime LLMs to\n",
      "synthesize unusual programs for the fuzzing DL libraries.\n",
      "----------\n",
      "It is built on the well-known hypothesis that historical\n",
      "bug-triggering programs may include rare/valuable code\n",
      "ingredients important for bug finding and show improved\n",
      "bug detection performance.\n",
      "----------\n",
      "Test input generation for other types of software.There\n",
      "are also dozens of studies that address testing tasks in vari-\n",
      "ous other domains, due to space limitations, we will present\n",
      "a selection of representative studies in these domains.\n",
      "----------\n",
      "Finding bugs in a commercial cyber-physical system\n",
      "(CPS) development tool such as Simulink is even more\n",
      "challenging.\n",
      "----------\n",
      "Given the complexity of the Simulink language,\n",
      "generating valid Simulink model files for testing is an\n",
      "ambitious task for traditional machine learning or deep\n",
      "learning techniques.\n",
      "----------\n",
      "Shrestha et al.\n",
      "----------\n",
      "[51] employs a small set\n",
      "of Simulink-specific training data to fine-tune the LLM for\n",
      "generating Simulink models.\n",
      "----------\n",
      "Results show that it can create\n",
      "Simulink models quite similar to the open-source models,\n",
      "and can find a super-set of the bugs traditional fuzzing\n",
      "approaches found.\n",
      "----------\n",
      "Sun et al.\n",
      "----------\n",
      "[63] utilize LLM to generate test formulas for\n",
      "fuzzing SMT solvers.\n",
      "----------\n",
      "It retrains the LLMs on a large corpus\n",
      "of SMT formulas to enable them to acquire SMT-specific\n",
      "domain knowledge.\n",
      "----------\n",
      "Then it further fine-tunes the LLMs\n",
      "on historical bug-triggering formulas, which are known\n",
      "to involve structures that are more likely to trigger bugs\n",
      "and solver-specific behaviors.\n",
      "----------\n",
      "The LLM-based compiler\n",
      "fuzzer proposed by Yang et al.\n",
      "----------\n",
      "[69] adopts a dual-model\n",
      "framework: (1) an analysis LLM examines the low-level\n",
      "optimization source code and produces requirements on the\n",
      "high-level test programs that can trigger the optimization;\n",
      "(2) a generation LLM produces test programs based on the\n",
      "summarized requirements.\n",
      "----------\n",
      "Ye et al.\n",
      "----------\n",
      "[48] utilize the LLM\n",
      "for generating the JavaScript programs and then use the\n",
      "well-structured ECMAScript specifications to automatically\n",
      "generate test data along with the test programs, after that\n",
      "they apply differential testing to expose bugs.\n",
      "----------\n",
      "4.3.2 Input Generation in Terms of Testing Techniques\n",
      "By utilizing system test inputs generated by LLMs, the col-\n",
      "lected studies aim to enhance traditional testing techniques\n",
      "and make them more effective.\n",
      "----------\n",
      "Among these techniques,\n",
      "fuzz testing is the most commonly involved one.\n",
      "----------\n",
      "Fuzz test-\n",
      "ing, as a general concept, revolves around generating in-\n",
      "valid, unexpected, or random data as inputs to evaluate the\n",
      "behavior of software.\n",
      "----------\n",
      "LLMs play a crucial role in improv-\n",
      "ing traditional fuzz testing by facilitating the generation of\n",
      "diverse and realistic input data.\n",
      "----------\n",
      "This enables fuzz testing to\n",
      "uncover potential bugs in the software by subjecting it to a\n",
      "wide range of input scenarios.\n",
      "----------\n",
      "In addition to fuzz testing,\n",
      "LLMs also contribute to enhancing other testing techniques,\n",
      "which will be discussed in detail later.\n",
      "----------\n",
      "Universal fuzzing framework.\n",
      "----------\n",
      "Xia et al.\n",
      "----------\n",
      "[67] present\n",
      "Fuzz4All that can target many different input languages\n",
      "and many different features of these languages.\n",
      "----------\n",
      "The key\n",
      "idea behind it is to leverage LLMs as an input generation\n",
      "and mutation engine, which enables the approach to\n",
      "produce diverse and realistic inputs for any practically\n",
      "relevant language.\n",
      "----------\n",
      "To realize this potential, they present\n",
      "a novel auto-prompting technique, which creates LLM\n",
      "prompts that are well-suited for fuzzing, and a novel\n",
      "LLM-powered fuzzing loop, which iteratively updates the\n",
      "prompt to create new fuzzing inputs.\n",
      "----------\n",
      "They experiment\n",
      "with six different languages (C, C++, Go, SMT2, Java and\n",
      "Python) as inputs and demonstrate higher coverage than\n",
      "existing language-specific fuzzers.\n",
      "----------\n",
      "Hu et al.\n",
      "----------\n",
      "[52] propose a\n",
      "greybox fuzzer augmented by the LLM, which picks a seed\n",
      "in the fuzzer’s seed pool and prompts the LLM to produce\n",
      "the mutated seeds that might trigger a new code region\n",
      "of the software.\n",
      "----------\n",
      "They experiment with three categories of\n",
      "input formats, i.e., formatted data files (e.g., json, xml),\n",
      "source code in different programming languages (e.g., JS,\n",
      "SQL, C), text with no explicit syntax rules (e.g., HTTP\n",
      "response, md5 checksum).\n",
      "----------\n",
      "In addition, effective fuzzing\n",
      "relies on the effective fuzz driver, and Zhang et al.\n",
      "----------\n",
      "[66]\n",
      "utilize LLMs on the fuzz driver generation, in which five\n",
      "query strategies are designed and analyzed from basic to\n",
      "enhanced.\n",
      "----------\n",
      "Fuzzing techniques for specific software.\n",
      "----------\n",
      "There are\n",
      "studies that focus on the fuzzing techniques tailored to\n",
      "specific software, e.g., the deep learning library [58], [59],\n",
      "compiler [69], SMT solvers [63], input widget of mobile app\n",
      "[65], cyber-physical system [51], etc.\n",
      "----------\n",
      "One key focus of these\n",
      "fuzzing techniques is to generate diverse test inputs so as\n",
      "to achieve higher coverage.\n",
      "----------\n",
      "This is commonly achieved\n",
      "by combining the mutation technique with LLM-based\n",
      "generation, where the former produces various candidates\n",
      "while the latter is responsible for generating the executable\n",
      "test inputs [59], [63].\n",
      "----------\n",
      "Another focus of these fuzzing\n",
      "techniques is to generate the risky test inputs that can\n",
      "trigger bugs earlier.\n",
      "----------\n",
      "To achieve this, a common practice is to11\n",
      "collect the historical bug-triggering programs to fine-tune\n",
      "the LLM [63] or treat them as the demonstrations when\n",
      "querying the LLM [58], [65].\n",
      "----------\n",
      "Other testing techniques.\n",
      "----------\n",
      "There are studies that utilize\n",
      "LLMs for enhancing GUI testing for generating meaningful\n",
      "text input [49] and functionality-oriented exploration traces\n",
      "[14], which has been introduced in Test input generation for\n",
      "mobile apps part of Section 4.3.1.\n",
      "----------\n",
      "Besides, Deng et al.\n",
      "----------\n",
      "[62] leverage the LLMs to carry out\n",
      "penetration testing tasks automatically.\n",
      "----------\n",
      "It involves setting a\n",
      "penetration testing goal for the LLM, soliciting it for the\n",
      "appropriate operation to execute, implementing it in the\n",
      "testing environment, and feeding the test outputs back to\n",
      "the LLM for next-step reasoning.\n",
      "----------\n",
      "4.3.3 Input Generation in Terms of Input and Output\n",
      "Other output format of test generation.\n",
      "----------\n",
      "Although most\n",
      "works use LLM to generate test cases directly, there are also\n",
      "some works generating indirect inputs like testing code, test\n",
      "scenarios, metamorphic relations, etc.\n",
      "----------\n",
      "Liu et al.\n",
      "----------\n",
      "[65] pro-\n",
      "pose InputBlaster which leverages the LLM to automati-\n",
      "cally generate unusual text inputs for fuzzing the text input\n",
      "widgets in mobile apps.\n",
      "----------\n",
      "It formulates the unusual inputs\n",
      "generation problem as a task of producing a set of test gen-\n",
      "erators, each of which can yield a batch of unusual text\n",
      "inputs under the same mutation rule.\n",
      "----------\n",
      "In detail, InputBlaster\n",
      "leverages LLM to produce the test generators together with\n",
      "the mutation rules serving as the reasoning chain and uti-\n",
      "lizes the in-context learning schema to demonstrate the LLM\n",
      "with examples for boosting the performance.\n",
      "----------\n",
      "Deng et al.\n",
      "----------\n",
      "[64] use LLM to extract key information related to the test\n",
      "scenario from a traffic rule, and represent the extracted in-\n",
      "formation in a test scenario schema, then synthesize the\n",
      "corresponding scenario scripts to construct the test scenario.\n",
      "----------\n",
      "Luu et al.\n",
      "----------\n",
      "[56] examine the effectiveness of LLM in generat-\n",
      "ing metamorphic relations (MRs) for metamorphic testing.\n",
      "----------\n",
      "Their results show that ChatGPT can be used to advance\n",
      "software testing intelligence by proposing MRs candidates\n",
      "that can be later adapted for implementing tests, but human\n",
      "intelligence should still inevitably be involved to justify and\n",
      "rectify their correctness.\n",
      "----------\n",
      "Other input format of test generation.\n",
      "----------\n",
      "The aforemen-\n",
      "tioned studies primarily take the source code or the software\n",
      "as the input of LLM, yet there are also studies that take\n",
      "natural language description as the input for test generation.\n",
      "----------\n",
      "Mathur et al.\n",
      "----------\n",
      "[53] propose to generate test cases from the\n",
      "natural language described requirements.\n",
      "----------\n",
      "Ackerman et al.\n",
      "----------\n",
      "[60] generate the instances from natural language described\n",
      "requirements recursively to serve as the seed examples for a\n",
      "mutation fuzzer.\n",
      "----------\n",
      "4.4 Bug Analysis\n",
      "This category involves analyzing and categorizing the iden-\n",
      "tified software bugs to enhance understanding of the bug,\n",
      "and facilitate subsequent debug and bug repair.\n",
      "----------\n",
      "Mukher-\n",
      "jee et al.\n",
      "----------\n",
      "[73] generate relevant answers to follow-up ques-\n",
      "tions for deficient bug reports to facilitate bug triage.\n",
      "----------\n",
      "Su et\n",
      "al.\n",
      "----------\n",
      "[76] transform the bug-component triaging into a multi-\n",
      "classification task and a generation task with LLM, then\n",
      "ensemble the prediction results from them to improve the\n",
      "performance of bug-component triaging further.\n",
      "----------\n",
      "Zhang et\n",
      "al.\n",
      "----------\n",
      "[72] first leverage the LLM under the zero-shot setting\n",
      "to get essential information on bug reports, then use the\n",
      "essential information as the input to detect duplicate bug re-\n",
      "ports.\n",
      "----------\n",
      "Mahbub et al.\n",
      "----------\n",
      "[74] proposes to explain software bugs\n",
      "with LLM, which generates natural language explanations\n",
      "for software bugs by learning from a large corpus of bug-fix\n",
      "commits.\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "[70] target to automatically generate\n",
      "the bug title from the descriptions of the bug, which aims\n",
      "to help developers write issue titles and facilitate the bug\n",
      "triaging and follow-up fixing process.\n",
      "----------\n",
      "4.5 Debug\n",
      "This category refers to the process of identifying and locat-\n",
      "ing the cause of a software problem (i.e., bug).\n",
      "----------\n",
      "It involves\n",
      "analyzing the code, tracing the execution flow, collecting\n",
      "error information to understand the root cause of the issue,\n",
      "and fixing the issue.\n",
      "----------\n",
      "Some studies concentrate on the com-\n",
      "prehensive debug process, while others delve into specific\n",
      "sub-activities within the process.\n",
      "----------\n",
      "Overall debug framework.\n",
      "----------\n",
      "Bui et al.\n",
      "----------\n",
      "[77] proposes a uni-\n",
      "fied Detect-Localize-Repair framework based on the LLM\n",
      "for debugging, which first determines whether a given code\n",
      "snippet is buggy or not, then identifies the buggy lines, and\n",
      "translates the buggy code to its fixed version.\n",
      "----------\n",
      "Kang et al.\n",
      "----------\n",
      "[83] proposes automated scientific debugging, a technique\n",
      "that given buggy code and a bug-revealing test, prompts\n",
      "LLMs to automatically generate hypotheses, uses debuggers\n",
      "to actively interact with buggy code, and thus automati-\n",
      "cally reaches conclusions prior to patch generation.\n",
      "----------\n",
      "Chen\n",
      "et al.\n",
      "----------\n",
      "[88] demonstrate that self-debugging can teach the\n",
      "LLM to perform rubber duck debugging; i.e., without any\n",
      "human feedback on the code correctness or error messages,\n",
      "the model is able to identify its mistakes by investigating the\n",
      "execution results and explaining the generated code in nat-\n",
      "ural language.\n",
      "----------\n",
      "Cao et al.\n",
      "----------\n",
      "[89] conducts a study of LLM’s de-\n",
      "bugging ability for deep learning programs, including fault\n",
      "detection, fault localization and program repair.\n",
      "----------\n",
      "Bug localization.\n",
      "----------\n",
      "Wu et al.\n",
      "----------\n",
      "[85] compare the two LLMs\n",
      "(ChatGPT and GPT-4) with the existing fault localization\n",
      "techniques, and investigate the consistency of LLMs in fault\n",
      "localization, as well as how prompt engineering and the\n",
      "length of code context affect the results.\n",
      "----------\n",
      "Kang et al.\n",
      "----------\n",
      "[79]\n",
      "propose AutoFL, an automated fault localization technique\n",
      "that only requires a single failing test, and during its fault\n",
      "localization process, it also generates an explanation about\n",
      "why the given test fails.\n",
      "----------\n",
      "Yang et al.\n",
      "----------\n",
      "[84] propose LLMAO to\n",
      "overcome the left-to-right nature of LLMs by fine-tuning a\n",
      "small set of bidirectional adapter layers on top of the rep-\n",
      "resentations learned by LLMs, which can locate buggy lines\n",
      "of code without any test coverage information.\n",
      "----------\n",
      "Tu et al.\n",
      "----------\n",
      "[86]\n",
      "propose LLM4CBI to tame LLMs to generate effective test\n",
      "programs for finding suspicious files.\n",
      "----------\n",
      "Bug reproduction.\n",
      "----------\n",
      "There are also studies focusing on a\n",
      "sub-phase of the debugging process.\n",
      "----------\n",
      "For example, Kang et\n",
      "al.\n",
      "----------\n",
      "[78] and Plein et al.\n",
      "----------\n",
      "[81] respectively propose the frame-\n",
      "work to harness the LLM to reproduce bugs, and suggest\n",
      "bug reproducing test cases to the developer for facilitating\n",
      "debugging.\n",
      "----------\n",
      "Li et al.\n",
      "----------\n",
      "[87] focus on a similar aspect of finding\n",
      "the failure-inducing test cases whose test input can trigger12\n",
      "the software’s fault.\n",
      "----------\n",
      "It synergistically combines LLM and\n",
      "differential testing to do that.\n",
      "----------\n",
      "There are also studies focusing on the bug reproduc-\n",
      "tion of mobile apps to produce the replay script.\n",
      "----------\n",
      "Feng et\n",
      "al.\n",
      "----------\n",
      "[75] propose AdbGPT, a new lightweight approach to\n",
      "automatically reproduce the bugs from bug reports through\n",
      "prompt engineering, without any training and hard-coding\n",
      "effort.\n",
      "----------\n",
      "It leverages few-shot learning and chain-of-thought\n",
      "reasoning to elicit human knowledge and logical reasoning\n",
      "from LLMs to accomplish the bug replay in a manner similar\n",
      "to a developer.\n",
      "----------\n",
      "Huang et al.\n",
      "----------\n",
      "[71] propose CrashTranslator to\n",
      "automatically reproduce bugs directly from the stack trace.\n",
      "----------\n",
      "It accomplishes this by leveraging the LLM to predict the\n",
      "exploration steps for triggering the crash, and designing a\n",
      "reinforcement learning based technique to mitigate the in-\n",
      "accurate prediction and guide the search holistically.\n",
      "----------\n",
      "Taeb et\n",
      "al.\n",
      "----------\n",
      "[55] convert the manual accessibility test instructions into\n",
      "replayable, navigable videos by using LLM and UI element\n",
      "detection models, which can also help reveal accessibility\n",
      "issues.\n",
      "----------\n",
      "Error explanation.\n",
      "----------\n",
      "Taylor et al.\n",
      "----------\n",
      "[82] integrates the LLM\n",
      "into the Debugging C Compiler to generate unique, novice-\n",
      "focused explanations tailored to each error.\n",
      "----------\n",
      "Widjojo et al.\n",
      "----------\n",
      "[80] study the effectiveness of Stack Overflow and LLMs at\n",
      "explaining compiler errors.\n",
      "----------\n",
      "4.6 Program Repair\n",
      "This category denotes the task of fixing the identified\n",
      "software bugs.\n",
      "----------\n",
      "The high frequency of repair-related studies\n",
      "can be attributed to the close relationship between this\n",
      "task and the source code.\n",
      "----------\n",
      "With their advanced natural\n",
      "language processing and understanding capabilities, LLM\n",
      "are well-equipped to process and analyze source code,\n",
      "making them an ideal tool for performing code-related\n",
      "tasks such as fixing bugs.\n",
      "----------\n",
      "There have been template-based [145], heuristic-based\n",
      "[146], and constraint-based [147], [148] automatic program\n",
      "repair techniques.\n",
      "----------\n",
      "And with the development of deep\n",
      "learning techniques in the past few years, there have been\n",
      "several studies employing deep learning techniques for\n",
      "program repair.\n",
      "----------\n",
      "They typically adopt deep learning models\n",
      "to take a buggy software program as input and generate a\n",
      "patched program.\n",
      "----------\n",
      "Based on the training data, they would\n",
      "build a neural network model that learns the relations\n",
      "between the buggy code and the corresponding fixed code.\n",
      "----------\n",
      "Nevertheless, these techniques still fail to fix a large portion\n",
      "of bugs, and they typically have to generate hundreds to\n",
      "thousands of candidate patches and take hours to validate\n",
      "these patches to fix enough bugs.\n",
      "----------\n",
      "Furthermore, the deep\n",
      "learning based program repair models need to be trained\n",
      "with huge amounts of labeled training data (typically\n",
      "pairs of buggy and fixed code), which is time- and effort-\n",
      "consuming to collect the high-quality dataset.\n",
      "----------\n",
      "Subsequently,\n",
      "with the popularity and demonstrated capability of the\n",
      "LLMs, researchers begin to explore the LLMs for program\n",
      "repair.\n",
      "----------\n",
      "Patch single-line bugs.\n",
      "----------\n",
      "In the early era of program re-\n",
      "pair, the focus was mainly on addressing defects related to\n",
      "single-line code errors, which are relatively simple and did\n",
      "not require the repair of complex program logic.\n",
      "----------\n",
      "Lajk ´o et\n",
      "al.\n",
      "----------\n",
      "[95] propose to fine-tune the LLM with JavaScript code\n",
      "snippets to serve as the purpose for the JavaScript program\n",
      "repair.\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "[116] employs program slicing to extract\n",
      "contextual information directly related to the given buggy\n",
      "statement as repair ingredients from the corresponding pro-\n",
      "gram dependence graph, which makes the fine-tuning more\n",
      "focused on the buggy code.\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "[121] propose a\n",
      "stage-wise framework STEAM for patching single-line bugs,\n",
      "which simulates the interactive behavior of multiple pro-\n",
      "grammers involved in bug management, e.g., bug reporting,\n",
      "bug diagnosis, patch generation, and patch verification.\n",
      "----------\n",
      "Since most real-world bugs would involve multiple lines\n",
      "of code, and later studies explore these more complex situa-\n",
      "tions (although some of them can also patch the single-line\n",
      "bugs).\n",
      "----------\n",
      "Patch multiple-lines bugs.\n",
      "----------\n",
      "The studies in this category\n",
      "would input a buggy function to the LLM, and the goal is to\n",
      "output the patched function, which might involve complex\n",
      "semantic understanding, code hunk modification, as well\n",
      "as program refactoring.\n",
      "----------\n",
      "Earlier studies typically employ the\n",
      "fine-tuning strategy to enable the LLM to better understand\n",
      "the code semantics.\n",
      "----------\n",
      "Fu et al.\n",
      "----------\n",
      "[123] fine-tune the LLM by\n",
      "employing BPE tokenization to handle Out-Of-Vocabulary\n",
      "(OOV) issues which makes the approach generate new to-\n",
      "kens that never appear in a training function but are newly\n",
      "introduced in the repair.\n",
      "----------\n",
      "Wang et.\n",
      "----------\n",
      "al.\n",
      "----------\n",
      "[120] train the LLM\n",
      "based on both buggy input and retrieved bug-fix examples\n",
      "which are retrieved in terms of the lexical and semantical\n",
      "similarities.\n",
      "----------\n",
      "The aforementioned studies (including the ones\n",
      "in patching single-line bugs) would predict the fixed pro-\n",
      "grams directly, and Hu et al.\n",
      "----------\n",
      "[92] utilize a different setup\n",
      "that predicts the scripts that can fix the bugs when executed\n",
      "with the delete and insert grammar.\n",
      "----------\n",
      "For example, it predicts\n",
      "whether an original line of code should be deleted, and what\n",
      "content should be inserted.\n",
      "----------\n",
      "Nevertheless, fine-tuning may face limitations in terms\n",
      "of its reliance on abundant high-quality labeled data,\n",
      "significant computational resources, and the possibility of\n",
      "overfitting.\n",
      "----------\n",
      "To approach the program repair problem more\n",
      "effectively, later studies focus on how to design an effective\n",
      "prompt for program repair.\n",
      "----------\n",
      "Several studies empirically\n",
      "investigate the effectiveness of prompt variants of the latest\n",
      "LLMs for program repair under different repair settings\n",
      "and commonly-used benchmarks (which will be explored\n",
      "in depth later), while other studies focus on proposing\n",
      "new techniques.\n",
      "----------\n",
      "Ribeiro et al.\n",
      "----------\n",
      "[109] take advantage of\n",
      "LLM to conduct the code completion in a buggy line for\n",
      "patch generation, and elaborate on how to circumvent the\n",
      "open-ended nature of code generation to appropriately\n",
      "fit the new code in the original program.\n",
      "----------\n",
      "Xia et al.\n",
      "----------\n",
      "[115]\n",
      "propose the conversation-driven program repair approach\n",
      "that interleaves patch generation with instant feedback\n",
      "to perform the repair in a conversational style.\n",
      "----------\n",
      "They first\n",
      "feed the LLM with relevant test failure information to start\n",
      "with, and then learns from both failures and successes\n",
      "of earlier patching attempts of the same bug for more\n",
      "powerful repair.\n",
      "----------\n",
      "For earlier patches that failed to pass\n",
      "all tests, they combine the incorrect patches with their\n",
      "corresponding relevant test failure information to construct\n",
      "a new prompt for the LLM to generate the next patch,\n",
      "in order to avoid making the same mistakes.\n",
      "----------\n",
      "For earlier13\n",
      "TABLE 4: Performance of program repair\n",
      "Dataset % Correct patches LLM Paper\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs,\n",
      "HumanEval-Java\n",
      "22/40 Jave bugs (QuixBugs dataset, with InCoder-6B, correct\n",
      "code infilling setting)\n",
      "PLBART, CodeT5, CodeGen, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 10 LLMs in total)\n",
      "[113]\n",
      "QuixBugs 23/40 Python bugs, 14/40 Java bugs (complete function genera-\n",
      "tion setting)\n",
      "Codex-12B [100]\n",
      "Defects4J v1.2, Defects4J\n",
      "v2.0, QuixBugs, Many-\n",
      "Bugs\n",
      "39/40 Python bugs, 34/40 Java bugs (QuixBugs dataset, with\n",
      "Codex-12B, correct code infilling setting); 37/40 Python bugs,\n",
      "32/40 Java bugs (QuixBugs dataset, with Codex-12B, complete\n",
      "function generation setting)\n",
      "Codex, GPT-Neo, CodeT5, In-\n",
      "Coder (each with variant pa-\n",
      "rameters, 9 LLMs in total)\n",
      "[93]\n",
      "QuixBugs 31/40 Python bugs (completion function generation setting) ChatGPT-175B [96]\n",
      "DL programs from Stack-\n",
      "Overflow\n",
      "16/72 Python bugs (complete function generation setting) ChatGPT-175B [89]\n",
      "Note that, for studies with multiple datasets or LLMs, we only present the best performance or in the most commonly utilized dataset.\n",
      "----------\n",
      "patches that passed all the tests (i.e., plausible patches),\n",
      "they further ask the LLM to generate alternative variations\n",
      "of the original plausible patches.\n",
      "----------\n",
      "This can further build on\n",
      "and learn from earlier successes to generate more plausible\n",
      "patches to increase the chance of having correct patches.\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "[94] propose a similar approach design by\n",
      "leveraging multimodal prompts (e.g., natural language\n",
      "description, error message, input-output-based test cases),\n",
      "iterative querying, test-case-based few-shot selection to\n",
      "produce repairs.\n",
      "----------\n",
      "Moon et al.\n",
      "----------\n",
      "[102] propose for bug fixing\n",
      "with feedback.\n",
      "----------\n",
      "It consists of a critic model to generate\n",
      "feedback, an editor to edit codes based on the feedback,\n",
      "and a feedback selector to choose the best possible feedback\n",
      "from the critic.\n",
      "----------\n",
      "Wei et.\n",
      "----------\n",
      "al.\n",
      "----------\n",
      "[103] propose Repilot to copilot the AI “copi-\n",
      "lots” (i.e., LLMs) by synthesizing more valid patches during\n",
      "the repair process.\n",
      "----------\n",
      "Its key insight is that many LLMs pro-\n",
      "duce outputs autoregressively (i.e., token by token), and by\n",
      "resembling human writing programs, the repair can be sig-\n",
      "nificantly boosted and guided through a completion engine.\n",
      "----------\n",
      "Brownlee et al.\n",
      "----------\n",
      "[105] propose to use the LLM as mutation\n",
      "operators for the search-based techniques of program repair.\n",
      "----------\n",
      "Repair with static code analyzer.\n",
      "----------\n",
      "Most of the program\n",
      "repair studies would suppose the bug has been detected,\n",
      "while Jin et al.\n",
      "----------\n",
      "[114] propose a program repair framework\n",
      "paired with a static analyzer to first detect the bugs, and\n",
      "then fix them.\n",
      "----------\n",
      "In detail, the static analyzer first detects an\n",
      "error (e.g., null pointer dereference) and the context infor-\n",
      "mation provided by the static analyzer will be sent into the\n",
      "LLM for querying the patch for this specific error.\n",
      "----------\n",
      "Wadhwa\n",
      "et al.\n",
      "----------\n",
      "[110] focus on a similar task, and additionally employ\n",
      "an LLM as the ranker to assess the likelihood of acceptance\n",
      "of generated patches which can effectively catch plausible\n",
      "but incorrect fixes and reduce developer burden.\n",
      "----------\n",
      "Repair for specific bugs.\n",
      "----------\n",
      "The aforementioned studies\n",
      "all consider the buggy code as the input for the automatic\n",
      "program repair, while other studies conduct program re-\n",
      "pairing in terms of other types of bug descriptions, specific\n",
      "types of bugs, etc.\n",
      "----------\n",
      "Fakhoury et al.\n",
      "----------\n",
      "[122] focus on program\n",
      "repair from natural language issue descriptions, i.e., gen-\n",
      "erating the patch with the bug and fix-related information\n",
      "described in the issue reports.\n",
      "----------\n",
      "Garg et al.\n",
      "----------\n",
      "[119] aim at re-\n",
      "pairing performance issues, in which they first retrieve a\n",
      "prompt instruction from a pre-constructed knowledge-base\n",
      "of previous performance bug fixes and then generate a re-\n",
      "pair prompt using the retrieved instruction.\n",
      "----------\n",
      "There are stud-\n",
      "ies focusing on the bug fixing of Rust programs [108] or\n",
      "OCaml programs (an industrial-strength programming lan-\n",
      "guage) [111].\n",
      "----------\n",
      "Empirical study about program repair.There are several\n",
      "studies related to the empirical or experimental evaluation\n",
      "of the various LLMs on program repair, and we summa-\n",
      "rize the performance in Table 4.\n",
      "----------\n",
      "Jiang et al.\n",
      "----------\n",
      "[113], Xia et al.\n",
      "----------\n",
      "[93], and Zhang et.\n",
      "----------\n",
      "al.\n",
      "----------\n",
      "[118] respectively conduct compre-\n",
      "hensive experimental evaluations with various LLMs and\n",
      "on different automated program repair benchmarks, while\n",
      "other researchers [89], [96], [98], [100] focus on a specific\n",
      "LLM and on one dataset, e.g., QuixBugs.\n",
      "----------\n",
      "In addition, Gao\n",
      "et al.\n",
      "----------\n",
      "[124] empirically investigate the impact of in-context\n",
      "demonstrations for bug fixing, including the selection, or-\n",
      "der, and number of demonstration examples.\n",
      "----------\n",
      "Prenner et al.\n",
      "----------\n",
      "[117] empirically study how the local context (i.e., code that\n",
      "comes before or after the bug location) affects the repair per-\n",
      "formance.\n",
      "----------\n",
      "Horv ´ath et al.\n",
      "----------\n",
      "[99] empirically study the impact\n",
      "of program representation and model architecture on the\n",
      "repair performance.\n",
      "----------\n",
      "There are two commonly-used repair settings when us-\n",
      "ing LLMs to generate patches: 1) complete function gen-\n",
      "eration (i.e., generating the entire patch function), 2) cor-\n",
      "rect code infilling (i.e., filling in a chunk of code given the\n",
      "prefix and suffix), and different studies might utilize differ-\n",
      "ent settings which are marked in Table 4.\n",
      "----------\n",
      "The commonly-\n",
      "used datasets are QuixBugs, Defects4J, etc.\n",
      "----------\n",
      "These datasets\n",
      "only involve the fundamental functionalities such as sorting\n",
      "algorithms, each program’s average number of lines rang-\n",
      "ing from 13 to 22, implementing one functionality, and in-\n",
      "volving few dependencies.\n",
      "----------\n",
      "To tackle this, Cao et al.\n",
      "----------\n",
      "[89]\n",
      "conducts an empirical study on a more complex dataset\n",
      "with DL programs collected from StackOverflow.\n",
      "----------\n",
      "Every pro-\n",
      "gram contains about 46 lines of code on average, imple-\n",
      "menting several functionalities including data preprocess-\n",
      "ing, DL model construction, model training, and evaluation.\n",
      "----------\n",
      "And the dataset involves more than 6 dependencies for each\n",
      "program, including TensorFlow, Keras, and Pytorch.\n",
      "----------\n",
      "Their\n",
      "results demonstrate a much lower rate of correct patches\n",
      "than in other datasets, which again reveals the potential\n",
      "difficulty of this task.\n",
      "----------\n",
      "Similarly, Haque et al.\n",
      "----------\n",
      "[106] introduce\n",
      "a dataset comprising of buggy code submissions and their\n",
      "corresponding fixes collected from online judge platforms,\n",
      "in which it offers an extensive collection of unit tests to\n",
      "enable the evaluations about the correctness of fixes and fur-\n",
      "ther information regarding time, memory constraints, and\n",
      "acceptance based on a verdict.14\n",
      "ChatGPT, 36\n",
      "25%\n",
      "Codex, 23\n",
      "16%\n",
      "CodeT5, 18\n",
      "13% GPT-4, 14\n",
      "10%\n",
      "GPT-3, 7\n",
      "5%\n",
      "CodeGen, 64%\n",
      "InCoder, 54%\n",
      "PLBART, 54%\n",
      "T5, 5\n",
      "4%\n",
      "CodeGPT, 4\n",
      "3%\n",
      "GPT-2, 4\n",
      "3%\n",
      "BART, 3\n",
      "2%\n",
      "StarCoder, 3\n",
      "2%\n",
      "UniXCoder, 2\n",
      "1%\n",
      "Others, 7\n",
      "5%\n",
      "Fig.\n",
      "----------\n",
      "6: LLMs used in the collected papers\n",
      "5 A NALYSIS FROM LLM PERSPECTIVE\n",
      "This section discusses the analysis based on the viewpoints\n",
      "of LLM, specifically, it’s unfolded from the viewpoints of\n",
      "utilized LLMs, types of prompt engineering, input of the\n",
      "LLMs, as well as the accompanied techniques when utilizing\n",
      "LLM.\n",
      "----------\n",
      "5.1 LLM Models\n",
      "As shown in Figure 6, the most commonly utilized LLM\n",
      "in software testing tasks is ChatGPT, which was released\n",
      "on Nov. 2022 by OpenAI.\n",
      "----------\n",
      "It is trained on a large corpus\n",
      "of natural language text data, and primarily designed for\n",
      "natural language processing and conversation.\n",
      "----------\n",
      "ChatGPT is\n",
      "the most widely recognized and popular LLM up until now,\n",
      "known for its exceptional performance across various tasks.\n",
      "----------\n",
      "Therefore, it comes as no surprise that it ranks in the top\n",
      "position in terms of our collected studies.\n",
      "----------\n",
      "Codex, an LLM based on GPT-3, is the second most com-\n",
      "monly used LLM in our collected studies.\n",
      "----------\n",
      "It is trained on a\n",
      "massive code corpus containing examples from many pro-\n",
      "gramming languages such as JavaScript, Python, C/C++,\n",
      "and Java.\n",
      "----------\n",
      "Codex was released on Sep. 2021 by OpenAI and\n",
      "powers GitHub Copilot– an AI pair programmer that gener-\n",
      "ates whole code snippets, given a natural language descrip-\n",
      "tion as a prompt.\n",
      "----------\n",
      "Since a large portion of our collected stud-\n",
      "ies involve the source code (e.g., repair, unit test case gen-\n",
      "eration), it is not surprising that researchers choose Codex\n",
      "as the LLM in assisting them in accomplishing the coding-\n",
      "related tasks.\n",
      "----------\n",
      "The third-ranked LLM is CodeT5, which is an open-\n",
      "sourced LLM developed by salesforce 3.\n",
      "----------\n",
      "Thanks to its open\n",
      "source, researchers can easily conduct the pre-training and\n",
      "fine-tuning with domain-specific data to achieve better\n",
      "performance.\n",
      "----------\n",
      "Similarly, CodeGen is also open-sourced and\n",
      "ranked relatively higher.\n",
      "----------\n",
      "Besides, for CodeT5 and CodeGen,\n",
      "there are more than half of the related studies involve the\n",
      "empirical evaluations (which employ multiple LLMs), e.g.,\n",
      "program repair [112], [113], unit test case generation [39].\n",
      "----------\n",
      "3. https://blog.salesforceairesearch.com/codet5/\n",
      "There are already 14 studies that utilize GPT-4, ranking\n",
      "at the fourth place, which is launched on March 2023.\n",
      "----------\n",
      "Sev-\n",
      "eral studies directly utilize this state-of-the-art LLM of Ope-\n",
      "nAI, since it demonstrates excellent performance across a\n",
      "wide range of generation and reasoning tasks.\n",
      "----------\n",
      "For example,\n",
      "Xie et al.\n",
      "----------\n",
      "utilize GPT-4 to generate fuzzing inputs [67], while\n",
      "Vikram et al.\n",
      "----------\n",
      "employ it to generate property-based tests with\n",
      "the assistance of API documentation [34].\n",
      "----------\n",
      "In addition, some\n",
      "studies conduct experiments using both GPT-4 and Chat-\n",
      "GPT or other LLMs to provide a more comprehensive evalu-\n",
      "ation of these models’ performance.\n",
      "----------\n",
      "In their proposed LLM-\n",
      "empowered automatic penetration testing technique, Deng\n",
      "et al.\n",
      "----------\n",
      "find that GPT-4 surpasses ChatGPT and LaMDA from\n",
      "Google [62].\n",
      "----------\n",
      "Similarly, Zhang et al.\n",
      "----------\n",
      "find that GPT-4 shows\n",
      "its performance superiority over ChatGPT when generat-\n",
      "ing the fuzz drivers with both the basic query strategies\n",
      "and enhanced query strategies [66].\n",
      "----------\n",
      "Furthermore, GPT-4, as\n",
      "a multi-modal LLM, sets itself apart from the other men-\n",
      "tioned LLMs by showcasing additional capabilities such as\n",
      "generating image narratives and answering questions based\n",
      "on images [149].\n",
      "----------\n",
      "Yet we have not come across any studies\n",
      "that explore the utilization of GPT-4’s image-related features\n",
      "(e.g., UI screenshots, programming screencasts) in software\n",
      "testing tasks.\n",
      "----------\n",
      "5.2 Types of Prompt Engineering\n",
      "As shown in Figure 7, among our collected studies, 38\n",
      "studies utilize the LLMs through pre-training or fine-\n",
      "tuning schema, while 64 studies employ the prompt\n",
      "engineering to communicate with LLMs to steer its\n",
      "behavior for desired outcomes without updating the model\n",
      "weights.\n",
      "----------\n",
      "When using the early LLMs, their performances\n",
      "might not be as impressive, so researchers often use\n",
      "pre-training or fine-tuning techniques to adjust the models\n",
      "for specific domains and tasks in order to improve their\n",
      "performance.\n",
      "----------\n",
      "Then with the upgrading of LLM technology,\n",
      "especially with the introduction of GPT-3 and later\n",
      "LLMs, the knowledge contained within the models and\n",
      "their understanding/inference capability has increased\n",
      "significantly.\n",
      "----------\n",
      "Therefore, researchers will typically rely on\n",
      "prompt engineering to consider how to design appropriate\n",
      "prompts to stimulate the model’s knowledge.\n",
      "----------\n",
      "Among the 64 studies with prompt engineering, 51 stud-\n",
      "ies involve zero-shot learning, and 25 studies involve few-\n",
      "shot learning (a study may involve multiple types).\n",
      "----------\n",
      "There\n",
      "are also studies involving the chain-of-though (7 studies),\n",
      "self-consistency (1 study), and automatic prompt (1 study).\n",
      "----------\n",
      "Zero-shot learning is to simply feed the task text to the\n",
      "model and ask for results.\n",
      "----------\n",
      "Many of the collected studies em-\n",
      "ploy the Codex, CodeT5, and CodeGen (as shown in Section\n",
      "5.1), which is already trained on source code.\n",
      "----------\n",
      "Hence, for the\n",
      "tasks dealing with source code like unit test case generation\n",
      "and program repair as demonstrated in previous sections,\n",
      "directly querying the LLM with prompts is the common\n",
      "practice.\n",
      "----------\n",
      "There are generally two types of manners of zero-\n",
      "shot learning, i.e., with and without instructions.\n",
      "----------\n",
      "For exam-\n",
      "ple, Xie et al.\n",
      "----------\n",
      "[36] would provide the LLMs with the instruc-\n",
      "tions as “please help me generate a JUnit test for a specific\n",
      "Java method ...” to facilitate the unit test case generation.\n",
      "----------\n",
      "In contrast, Siddiq et al.\n",
      "----------\n",
      "[39] only provide the code header15\n",
      "Fig.\n",
      "----------\n",
      "7: Distribution about how LLM is used (Note that, a study can involve multiple types of prompt engineering)\n",
      "of the unit test case (e.g., “class $ {className}${suffix}Test\n",
      "{”), and the LLMs would carry out the unit test case gener-\n",
      "ation automatically.\n",
      "----------\n",
      "Generally speaking, prompts with clear\n",
      "instructions will yield more accurate results, while prompts\n",
      "without instructions are typically suitable for very specific\n",
      "situations.\n",
      "----------\n",
      "Few-shot learning presents a set of high-quality demon-\n",
      "strations, each consisting of both input and desired output,\n",
      "on the target task.\n",
      "----------\n",
      "As the model first sees the examples,\n",
      "it can better understand human intention and criteria for\n",
      "what kinds of answers are wanted, which is especially im-\n",
      "portant for tasks that are not so straightforward or intuitive\n",
      "to the LLM.\n",
      "----------\n",
      "For example, when conducting the automatic\n",
      "test generation from general bug reports, Kang et al.\n",
      "----------\n",
      "[78]\n",
      "provide examples of bug reports (questions) and the corre-\n",
      "sponding bug reproducing tests (answers) to the LLM, and\n",
      "their results show that two examples can achieve the highest\n",
      "performance than no examples or other number of exam-\n",
      "ples.\n",
      "----------\n",
      "Another example of test assertion generation, Nashid\n",
      "et al.\n",
      "----------\n",
      "[47] provide demonstrations of the focal method, the\n",
      "test method containing an <AssertPlaceholder>, and the ex-\n",
      "pected assertion, which enables the LLMs to better under-\n",
      "stand the task.\n",
      "----------\n",
      "Chain-of-thought (CoT) prompting generates a\n",
      "sequence of short sentences to describe reasoning logics\n",
      "step by step (also known as reasoning chains or rationales)\n",
      "to the LLMs for generating the final answer.\n",
      "----------\n",
      "For example,\n",
      "for program repair from the natural language issue\n",
      "descriptions [122], given the buggy code and issue report,\n",
      "the authors first ask the LLM to localize the bug, and then\n",
      "they ask it to explain why the localized lines are buggy,\n",
      "finally, they ask the LLM to fix the bug.\n",
      "----------\n",
      "Another example is\n",
      "for generating unusual programs for fuzzing deep learning\n",
      "libraries, Deng et al.\n",
      "----------\n",
      "[58] first generate a possible “bug” (bug\n",
      "description) before generating the actual “bug-triggering”\n",
      "code snippet that invokes the target API.\n",
      "----------\n",
      "The predicted\n",
      "bug description provides an additional hint to the LLM,\n",
      "indicating that the generated code should try to cover\n",
      "specific potential buggy behavior.\n",
      "----------\n",
      "Self-consistency involves evaluating the coherence and\n",
      "consistency of the LLM’s responses on the same input in\n",
      "different contexts.\n",
      "----------\n",
      "There is one study with this prompt\n",
      "type, and it is about debugging.\n",
      "----------\n",
      "Kang et al.\n",
      "----------\n",
      "[83] employ a\n",
      "hypothesize-observe-conclude loop, which first generates\n",
      "a hypothesis about what the bug is and constructs an\n",
      "experiment to verify, using an LLM, then decide whether\n",
      "the hypothesis is correct based on the experiment result\n",
      "(with a debugger or code execution) using an LLM, after\n",
      "that, depending on the conclusion, it either starts with a\n",
      "new hypothesis or opts to terminate the debugging process\n",
      "and generate a fix.\n",
      "----------\n",
      "Automatic prompt aims to automatically generate and\n",
      "select the appropriate instruction for the LLMs, instead of\n",
      "requiring the user to manually engineer a prompt.\n",
      "----------\n",
      "Xia et\n",
      "al.\n",
      "----------\n",
      "[67] introduce an auto-prompting step that automatically\n",
      "distils all user-provided inputs into a concise and effective\n",
      "prompt for fuzzing.\n",
      "----------\n",
      "Specifically, they first generate a list of\n",
      "candidate prompts by incorporating the user inputs and\n",
      "auto prompting instruction while setting the LLM at high\n",
      "temperature, then a small-scale fuzzing experiment is con-\n",
      "ducted to evaluate each candidate prompt, and the best one\n",
      "is selected.\n",
      "----------\n",
      "Note that there are fourteen studies that apply the it-\n",
      "erative prompt design when using zero-shot or few-shot\n",
      "learning, in which the approach continuously refines the\n",
      "prompts with the running information of the testing task,\n",
      "e.g., the test failure information.\n",
      "----------\n",
      "For example, for program\n",
      "repair, Xia et al.\n",
      "----------\n",
      "[115] interleave patch generation with test\n",
      "validation feedback to prompt future generation iteratively.\n",
      "----------\n",
      "In detail, they incorporate various information from a failing\n",
      "test including its name, the relevant code line(s) triggering\n",
      "the test failure, and the error message produced in the next\n",
      "round of prompting which can help the model understand\n",
      "the failure reason and provide guidance towards generating\n",
      "the correct fix.\n",
      "----------\n",
      "Another example is for mobile GUI testing,\n",
      "Liu et al.\n",
      "----------\n",
      "[14] iteratively query the LLM about the operation\n",
      "(e.g., click a button, enter a text) to be conducted in the\n",
      "mobile app, and at each iteration, they would provide the\n",
      "LLM with current context information like which GUI pages\n",
      "and widgets have just explored.\n",
      "----------\n",
      "Mapping between testing tasks and how LLMs are\n",
      "used.\n",
      "----------\n",
      "Figure 8 demonstrates the mapping between the test-\n",
      "ing tasks (mentioned in Section 4) and how LLMs are used\n",
      "(as introduced in this subsection).\n",
      "----------\n",
      "The unit test case gen-\n",
      "eration and program repair share similar patterns of com-\n",
      "municating with the LLMs, since both tasks are closely re-\n",
      "lated to the source code.\n",
      "----------\n",
      "Typically, researchers utilize pre-\n",
      "training and/or fine-tuning and zero-shot learning methods\n",
      "for these two tasks.\n",
      "----------\n",
      "Zero-shot learning is suitable because\n",
      "these tasks are relatively straightforward and can be easily\n",
      "understood by LLMs.\n",
      "----------\n",
      "Moreover, since the training data for\n",
      "these two tasks can be automatically collected from source\n",
      "code repositories, pre-training and/or fine-tuning methods16\n",
      "Fig.\n",
      "----------\n",
      "8: Mapping between testing tasks and how LLMs are\n",
      "used\n",
      "Code, 78\n",
      "68%\n",
      "Bug description, 1210%\n",
      "Error information, 7\n",
      "6%\n",
      "View hierarchy file of UI, 6\n",
      "5%\n",
      "Others, 12\n",
      "10%\n",
      "Fig.\n",
      "----------\n",
      "9: Input of LLM\n",
      "are widely employed for these two tasks, which can enhance\n",
      "LLMs’ understanding of domain-specific knowledge.\n",
      "----------\n",
      "In comparison, for system test input generation, zero-\n",
      "shot learning and few-shot learning methods are commonly\n",
      "used.\n",
      "----------\n",
      "This might be because this task often involves gener-\n",
      "ating specific types of inputs, and demonstrations in few-\n",
      "shot learning can assist the LLMs in better understanding\n",
      "what should be generated.\n",
      "----------\n",
      "Besides, for this task, the uti-\n",
      "lization of pre-training and/or fine-tuning methods are not\n",
      "as widespread as in unit test case generation and program\n",
      "repair.\n",
      "----------\n",
      "This might be attributed to the fact that training data\n",
      "for system testing varies across different software and is\n",
      "relatively challenging to collect automatically.\n",
      "----------\n",
      "5.3 Input of LLM\n",
      "We also find that different testing tasks or software under\n",
      "test might involve diversified input when querying the\n",
      "LLM, as demonstrated in Figure 9.\n",
      "----------\n",
      "The most commonly utilized input is the source code\n",
      "since a large portion of collected studies relate to program\n",
      "repair or unit test case generation whose input are source\n",
      "code.\n",
      "----------\n",
      "For unit test case generation, typical code-related in-\n",
      "formation would be (i) the complete focal method, including\n",
      "the signature and body; (ii) the name of the focal class (i.e.,\n",
      "the class that the focal method belongs to); (iii) the field in\n",
      "the focal class; and (iv) the signatures of all methods defined\n",
      "in the focal class [7], [26].\n",
      "----------\n",
      "For program repair, there can be\n",
      "different setups and involve different inputs, including (i)\n",
      "inputting a buggy function with the goal of outputting the\n",
      "patched function, (ii) inputting the buggy location with the\n",
      "goal of generating the correct replacement code (can be a\n",
      "single line change) given the prefix and suffix of the buggy\n",
      "function [93].\n",
      "----------\n",
      "Besides, there can be variations for the buggy\n",
      "location input, i.e., (i) does not contain the buggy lines (but\n",
      "the bug location is still known), (ii) give the buggy lines as\n",
      "lines of comments.\n",
      "----------\n",
      "There are also 12 studies taking the bug description as\n",
      "input for the LLM.\n",
      "----------\n",
      "For example, Kang et al.\n",
      "----------\n",
      "[78] take the\n",
      "bug description as input when querying LLM and let the\n",
      "LLM generate the bug-reproducing test cases.\n",
      "----------\n",
      "Fakhoury et\n",
      "al.\n",
      "----------\n",
      "[122] input the natural language descriptions of bugs to\n",
      "the LLM, and generate the correct code fixes.\n",
      "----------\n",
      "There are 7 studies that would provide the intermedi-\n",
      "ate error information , e.g., test failure information, to the\n",
      "LLM, and would conduct the iterative prompt (as described\n",
      "in Section 5.2) to enrich the context provided to the LLM.\n",
      "----------\n",
      "These studies are related to the unit test case generation\n",
      "and program repair, since in these scenarios, the running\n",
      "information can be acquired easily.\n",
      "----------\n",
      "When testing mobile apps, since the utilized LLM could\n",
      "not understand the image of the GUI page, the view hierar-\n",
      "chy file which represents the details of the GUI page usually\n",
      "acts as the input to LLMs.\n",
      "----------\n",
      "Nevertheless, with the emergence\n",
      "of GPT-4 which is a multimodal model and accepts both\n",
      "image and text inputs for model input, the GUI screenshots\n",
      "might be directly utilized for LLM’s input.\n",
      "----------\n",
      "5.4 Incorporating Other Techniques with LLM\n",
      "There are divided opinions on whether LLM has reached\n",
      "an all-powerful status that requires no other techniques.\n",
      "----------\n",
      "As\n",
      "shown in Figure 10, among our collected studies, 67 of them\n",
      "utilize LLMs to address the entire testing task, while 35 stud-\n",
      "ies incorporate additional techniques.\n",
      "----------\n",
      "These techniques in-\n",
      "clude mutation testing, differential testing, syntactic check-\n",
      "ing, program analysis, statistical analysis, etc.\n",
      "----------\n",
      ".\n",
      "----------\n",
      "The reason why researchers still choose to combine\n",
      "LLMs with other techniques might be because, despite\n",
      "exhibiting enormous potential in various tasks, LLMs still\n",
      "possess limitations such as comprehending code semantics\n",
      "and handling complex program structures.\n",
      "----------\n",
      "Therefore,\n",
      "combining LLMs with other techniques optimizes their\n",
      "strengths and weaknesses to achieve better outcomes in\n",
      "specific scenarios.\n",
      "----------\n",
      "In addition, it is important to note that\n",
      "while LLMs are capable of generating correct code, they\n",
      "may not necessarily produce sufficient test cases to check\n",
      "for edge cases or rare scenarios.\n",
      "----------\n",
      "This is where mutation\n",
      "and other testing techniques come into play, as they allow\n",
      "for the generation of more diverse and complex code that\n",
      "can better simulate real-world scenarios.\n",
      "----------\n",
      "Taken in this\n",
      "sense, a testing approach can incorporate a combination\n",
      "of different techniques, including both LLMs and other\n",
      "testing strategies, to ensure comprehensive coverage and\n",
      "effectiveness.\n",
      "----------\n",
      "LLM + statistical analysis.\n",
      "----------\n",
      "As LLMs can often generate\n",
      "a multitude of outputs, manually sifting through and iden-\n",
      "tifying the correct output can be overwhelmingly laborious.\n",
      "----------\n",
      "As such, researchers have turned to statistical analysis tech-\n",
      "niques like ranking and clustering [28], [45], [78], [93], [116]17\n",
      "Fig.\n",
      "----------\n",
      "10: Distribution about other techniques incorporated with LLMs (Note that, a study can involve multiple types)\n",
      "to efficiently filter through LLM’s outputs and ultimately\n",
      "obtain more accurate results.\n",
      "----------\n",
      "LLM + program analysis.\n",
      "----------\n",
      "When utilizing LLMs to\n",
      "accomplish tasks such as generating unit test cases and\n",
      "repairing software code, it is important to consider that\n",
      "software code inherently possesses structural information,\n",
      "which may not be fully understood by LLMs.\n",
      "----------\n",
      "Hence,\n",
      "researchers often utilize program analysis techniques,\n",
      "including code abstract syntax trees (ASTs) [74], to\n",
      "represent the structure of code more effectively and increase\n",
      "the LLM’s ability to comprehend the code accurately.\n",
      "----------\n",
      "Researchers also perform the structure-based subsetting\n",
      "of code lines to narrow the focus for LLM [94], or extract\n",
      "additional code context from other code files [7], to enable\n",
      "the models to focus on the most task-relevant information\n",
      "in the codebase and lead to more accurate predictions.\n",
      "----------\n",
      "LLM + mutation testing.\n",
      "----------\n",
      "It is mainly targeting at gener-\n",
      "ating more diversified test inputs.\n",
      "----------\n",
      "For example, Deng et al.\n",
      "----------\n",
      "[59] first use LLM to generate the seed programs (e.g., code\n",
      "snippets using a target DL API) for fuzzing deep learning\n",
      "libraries.\n",
      "----------\n",
      "To enrich the pool of these test programs, they\n",
      "replace parts of the seed program with masked tokens using\n",
      "mutation operators (e.g., replaces the API call arguments\n",
      "with the span token) to produce masked inputs, and again\n",
      "utilize the LLMs to perform code infilling to generate new\n",
      "code that replaces the masked tokens.\n",
      "----------\n",
      "LLM + syntactic checking.\n",
      "----------\n",
      "Although LLMs have shown\n",
      "remarkable performance in various natural language pro-\n",
      "cessing tasks, the generated code from these models can\n",
      "sometimes be syntactically incorrect, leading to potential er-\n",
      "rors and reduced usability.\n",
      "----------\n",
      "Therefore, researchers have pro-\n",
      "posed to leverage syntax checking to identify and correct\n",
      "errors in the generated code.\n",
      "----------\n",
      "For example, in their work for\n",
      "unit test case generation, Alagarsamy et al.\n",
      "----------\n",
      "[29] addition-\n",
      "ally introduce a verification method to check and repair the\n",
      "naming consistency (i.e., revising the test method name to\n",
      "be consistent with the focal method name) and the test sig-\n",
      "natures (i.e., adding missing keywords like public, void, or\n",
      "@test annotations).\n",
      "----------\n",
      "Xie et al.\n",
      "----------\n",
      "[36] also validates the generated\n",
      "unit test case and employs rule-based repair to fix syntactic\n",
      "and simple compile errors.\n",
      "----------\n",
      "LLM + differential testing.\n",
      "----------\n",
      "Differential testing is well-\n",
      "suited to find semantic or logic bugs that do not exhibit\n",
      "explicit erroneous behaviors like crashes or assertion\n",
      "failures.\n",
      "----------\n",
      "In this category of our collected studies, the LLM\n",
      "is mainly responsible for generating valid and diversified\n",
      "inputs, while the differential testing helps to determine\n",
      "whether there is a triggered bug based on the software’s\n",
      "output.\n",
      "----------\n",
      "For example, Ye et al.\n",
      "----------\n",
      "[48] first uses LLM to\n",
      "produce random JavaScript programs, and leverages the\n",
      "language specification document to generate test data, then\n",
      "conduct the differential testing on JavaScript engines such\n",
      "as JavaScriptCore, ChakraCore, SpiderMonkey, QuickJS,\n",
      "etc.\n",
      "----------\n",
      "There are also studies utilizing the LLMs to generate\n",
      "test inputs and then conduct differential testing for fuzzing\n",
      "DL libraries [58], [59] and SAT solvers [63].\n",
      "----------\n",
      "Li et al.\n",
      "----------\n",
      "[87]\n",
      "employs the LLM in finding the failure-inducing test cases.\n",
      "----------\n",
      "In detail, given a program under test, they first request the\n",
      "LLM to infer the intention of the program, then request the\n",
      "LLM to generate programs that have the same intention,\n",
      "which are alternative implementations of the program, and\n",
      "are likely free of the program’s bug.\n",
      "----------\n",
      "Then they perform\n",
      "the differential testing with the program under test and the\n",
      "generated programs to find the failure-inducing test cases.\n",
      "----------\n",
      "6 C HALLENGES AND OPPORTUNITIES\n",
      "Based on the above analysis from the viewpoints of soft-\n",
      "ware testing and LLM, we summarize the challenges and\n",
      "opportunities when conducting software testing with LLM.\n",
      "----------\n",
      "6.1 Challenges\n",
      "As indicated by this survey, software testing with LLMs\n",
      "has undergone significant growth in the past two years.\n",
      "----------\n",
      "However, it is still in its early stages of development, and\n",
      "numerous challenges and open questions need to be ad-\n",
      "dressed.\n",
      "----------\n",
      "6.1.1 Challenges for Achieving High Coverage\n",
      "Exploring the diverse behaviors of the software under test\n",
      "to achieve high coverage is always a significant concern\n",
      "in software testing.\n",
      "----------\n",
      "In this context, test generation differs\n",
      "from code generation, as code generation primarily focuses\n",
      "on producing a single, correct code snippet, whereas soft-\n",
      "ware testing requires generating diverse test inputs to en-\n",
      "sure better coverage of the software.\n",
      "----------\n",
      "Although setting a high\n",
      "temperature can facilitate the LLMs in generating different\n",
      "outputs, it remains challenging for LLMs to directly achieve\n",
      "the required diversity.\n",
      "----------\n",
      "For example, for unit test case gen-\n",
      "eration, in SF110 dataset, the line coverage is merely 2%\n",
      "and the branch coverage is merely 1% [39].\n",
      "----------\n",
      "For system test\n",
      "input generation, in terms of fuzzing DL libraries, the API\n",
      "coverage for TensorFlow is reported to be 66% (2215/3316)\n",
      "[59].18\n",
      "From our collected studies, we observe that the\n",
      "researchers often utilize mutation testing together with the\n",
      "LLMs to generate more diversified outputs.\n",
      "----------\n",
      "For example,\n",
      "when fuzzing a DL library, instead of directly generating\n",
      "the code snippet with LLM, Deng et al.\n",
      "----------\n",
      "[59] replace parts\n",
      "of the selected seed (code generated by LLM) with masked\n",
      "tokens using different mutation operators to produce\n",
      "masked inputs.\n",
      "----------\n",
      "They then leverage the LLM to perform\n",
      "code infilling to generate new code that replaces the masked\n",
      "tokens, which can significantly increase the diversity of the\n",
      "generated tests.\n",
      "----------\n",
      "Liu et al.\n",
      "----------\n",
      "[65] leverage LLM to produce the\n",
      "test generators (each of which can yield a batch of unusual\n",
      "text inputs under the same mutation rule) together with the\n",
      "mutation rules for text-oriented fuzzing, which reduces the\n",
      "human effort required for designing mutation rules.\n",
      "----------\n",
      "A potential research direction could involve utilizing\n",
      "testing-specific data to train or fine-tune a specialized LLM\n",
      "that is specifically designed to understand the nature of\n",
      "testing.\n",
      "----------\n",
      "By doing so, the LLM can inherently acknowledge\n",
      "the requirements of testing and autonomously generate\n",
      "diverse outputs.\n",
      "----------\n",
      "6.1.2 Challenges in Test Oracle Problem\n",
      "The oracle problem has been a longstanding challenge in\n",
      "various testing applications, e.g., testing machine learning\n",
      "systems [150] and testing deep learning libraries [59].\n",
      "----------\n",
      "To\n",
      "alleviate the oracle problem to the overall testing activities,\n",
      "a common practice in our collected studies is to transform it\n",
      "into a more easily derived form, often by utilizing differen-\n",
      "tial testing [63] or focusing on only identifying crash bugs\n",
      "[14].\n",
      "----------\n",
      "There are successful applications of differential testing\n",
      "with LLMs, as shown in Figure 10.\n",
      "----------\n",
      "For instance, when\n",
      "testing the SMT solvers, Sun et al.\n",
      "----------\n",
      "adopt differential testing\n",
      "which involves comparing the results of multiple SMT\n",
      "solvers (i.e., Z3, cvc5, and Bitwuzla) on the same generated\n",
      "test formulas by LLM [63].\n",
      "----------\n",
      "However, this approach is\n",
      "limited to systems where counterpart software or running\n",
      "environment can easily be found, potentially restricting\n",
      "its applicability.\n",
      "----------\n",
      "Moreover, to mitigate the oracle problem,\n",
      "other studies only focus on the crash bugs which are easily\n",
      "observed automatically.\n",
      "----------\n",
      "This is particularly the case for\n",
      "mobile applications testing, in which the LLMs guide the\n",
      "testing in exploring more diversified pages, conducting\n",
      "more complex operational actions, and covering more\n",
      "meaningful operational sequences [14].\n",
      "----------\n",
      "However, this\n",
      "significantly restricts the potential of utilizing the LLMs for\n",
      "uncovering various types of software bugs.\n",
      "----------\n",
      "Exploring the use of LLMs to derive other types of\n",
      "test oracles represents an interesting and valuable research\n",
      "direction.\n",
      "----------\n",
      "Specifically, metamorphic testing is also widely\n",
      "used in software testing practices to help mitigate the oracle\n",
      "problem, yet in most cases, defining metamorphic relations\n",
      "relies on human ingenuity.\n",
      "----------\n",
      "Luu et al.\n",
      "----------\n",
      "[56] have examined the\n",
      "effectiveness of LLM in generating metamorphic relations,\n",
      "yet they only experiment with straightforward prompts by\n",
      "directly querying ChatGPT.\n",
      "----------\n",
      "Further exploration, potentially\n",
      "incorporating human-computer interaction or domain\n",
      "knowledge, is highly encouraged.\n",
      "----------\n",
      "Another promising\n",
      "avenue is exploring the capability of LLMs to automatically\n",
      "generate test cases based on metamorphic relations,\n",
      "covering a wide range of inputs.\n",
      "----------\n",
      "The advancement of multi-model LLMs like GPT-4 may\n",
      "open up possibilities for exploring their ability to detect\n",
      "bugs in software user interfaces and assist in deriving test\n",
      "oracles.\n",
      "----------\n",
      "By leveraging the image understanding and reason-\n",
      "ing capabilities of these models, one can investigate their\n",
      "potential to automatically identify inconsistencies, errors, or\n",
      "usability issues in user interfaces.\n",
      "----------\n",
      "6.1.3 Challenges for Rigorous Evaluations\n",
      "The lack of benchmark datasets and the potential data leak-\n",
      "age issues associated with LLM-based techniques present\n",
      "challenges in conducting rigorous evaluations and compre-\n",
      "hensive comparisons of proposed methods.\n",
      "----------\n",
      "For program repair, there are only two well-known and\n",
      "commonly-used benchmarks, i.e., Defect4J and QuixBugs,\n",
      "as demonstrated in Table 4.\n",
      "----------\n",
      "Furthermore, these datasets are\n",
      "not specially designed for testing the LLMs.\n",
      "----------\n",
      "For example, as\n",
      "reported by Xia et al.\n",
      "----------\n",
      "[93], 39 out of 40 Python bugs in the\n",
      "QuixBugs dataset can be fixed by Codex, yet in real-world\n",
      "practice, the successful fix rate can be nowhere near as high.\n",
      "----------\n",
      "For unit test case generation, there are no widely recognized\n",
      "benchmarks, and different studies would utilize different\n",
      "datasets for performance evaluation, as demonstrated in Ta-\n",
      "ble 3.\n",
      "----------\n",
      "This indicates the need to build more specialized and\n",
      "diversified benchmarks.\n",
      "----------\n",
      "Furthermore, the LLMs may have seen the widely-used\n",
      "benchmarks in their pre-training data, i.e., data leakage\n",
      "issues.\n",
      "----------\n",
      "Jiang et al.\n",
      "----------\n",
      "[113] check the CodeSearchNet and\n",
      "BigQuery, which are the data sources of common LLMs,\n",
      "and the results show that four repositories used by the\n",
      "Defect4J benchmark are also in CodeSearchNet, and the\n",
      "whole Defects4J repository is included by BigQuery.\n",
      "----------\n",
      "Therefore, it is very likely that existing program repair\n",
      "benchmarks are seen by the LLMs during pre-training.\n",
      "----------\n",
      "This\n",
      "data leakage issue has also been investigated in machine\n",
      "learning-related studies.\n",
      "----------\n",
      "For example, Tu et al.\n",
      "----------\n",
      "[151] focus\n",
      "on the data leakage in issue tracking data, and results show\n",
      "that information leaked from the “future” makes prediction\n",
      "models misleadingly optimistic.\n",
      "----------\n",
      "This reminds us that the\n",
      "performance of LLMs on software testing tasks may not be\n",
      "as good as reported in previous studies.\n",
      "----------\n",
      "It also suggests\n",
      "that we need more specialized datasets that are not seen by\n",
      "LLMs to serve as benchmarks.\n",
      "----------\n",
      "One way is to collect it from\n",
      "specialized sources, e.g., user-generated content from niche\n",
      "online communities.\n",
      "----------\n",
      "6.1.4 Challenges in Real-world Application of LLMs in Soft-\n",
      "ware Testing\n",
      "As we mentioned in Section 5.2, in the early days of us-\n",
      "ing LLMs, pre-training and fine-tuning are commonly used\n",
      "practice, considering the model parameters are relatively\n",
      "few resulting in weaker model capabilities (e.g., T5).\n",
      "----------\n",
      "As time\n",
      "progressed, the number of model parameters increased sig-\n",
      "nificantly, leading to the emergence of models with greater\n",
      "capabilities (e.g., ChatGPT).\n",
      "----------\n",
      "And in recent studies, prompt\n",
      "engineering has become a common approach.\n",
      "----------\n",
      "However, due\n",
      "to concerns regarding data privacy, when considering real-\n",
      "world practice, most software organizations tend to avoid19\n",
      "using commercial LLMs and would prefer to adopt open-\n",
      "source ones with training or fine-tuning using organization-\n",
      "specific data.\n",
      "----------\n",
      "Furthermore, some companies also consider\n",
      "the current limitations in terms of computational power or\n",
      "pay close attention to energy consumption, they tend to\n",
      "fine-tune medium-sized models.\n",
      "----------\n",
      "It is quite challenging for\n",
      "these models to achieve similar performance to what our\n",
      "collected papers have reported.\n",
      "----------\n",
      "For instance, in the widely-\n",
      "used QuixBugs dataset, it has been reported that 39 out of\n",
      "40 Python bugs and 34 out of 40 Java bugs can be automat-\n",
      "ically fixed [93].\n",
      "----------\n",
      "However, when it comes to DL programs\n",
      "collected from Stack Overflow, which represent real-world\n",
      "coding practice, only 16 out of 72 Python bugs can be auto-\n",
      "matically fixed [89].\n",
      "----------\n",
      "Recent research has highlighted the importance of high-\n",
      "quality training data in improving the performance of mod-\n",
      "els for code-related tasks [152], yet manually building high-\n",
      "quality organization-specific datasets for training or fine-\n",
      "tuning is time-consuming and labor-intensive.\n",
      "----------\n",
      "To address\n",
      "this, one is encouraged to utilize the automated techniques\n",
      "of mining software repositories to build the datasets, for\n",
      "example, techniques like key information extraction tech-\n",
      "niques from Stack Overflow [153] offer potential solutions\n",
      "for automatically gathering relevant data.\n",
      "----------\n",
      "In addition, exploring the methodology for better fine-\n",
      "tuning the LLMs with software-specific data is worth con-\n",
      "sidering because software-specific data differs from natural\n",
      "language data as it contains more structural information,\n",
      "such as data flow and control flow.\n",
      "----------\n",
      "Previous research on\n",
      "code representations has shown the benefits of incorporat-\n",
      "ing data flow, which captures the semantic-level structure\n",
      "of code and represents the relationship between variables in\n",
      "terms of “whether-value-comes-from” [154].\n",
      "----------\n",
      "These insights\n",
      "can provide valuable guidance for effectively fine-tuning\n",
      "LLMs with software-specific data.\n",
      "----------\n",
      "6.2 Opportunities\n",
      "There are also many research opportunities in software test-\n",
      "ing with LLMs, which can greatly benefit developers, users,\n",
      "and the research community.\n",
      "----------\n",
      "While not necessarily chal-\n",
      "lenges, these opportunities contribute to advancements in\n",
      "software testing, benefiting practitioners and the wider re-\n",
      "search community.\n",
      "----------\n",
      "6.2.1 Exploring LLMs in the Early Stage of Testing\n",
      "As shown in Figure 4, LLMs have not been used in the early\n",
      "stage of testing, e.g., test requirements, and test planning.\n",
      "----------\n",
      "There might be two main reasons behind that.\n",
      "----------\n",
      "The first is\n",
      "the subjectivity in early-stage testing tasks.\n",
      "----------\n",
      "Many tasks in\n",
      "the early stages of testing, such as requirements gathering,\n",
      "test plan creation, and design reviews, may involve subjec-\n",
      "tive assessments that require significant input from human\n",
      "experts.\n",
      "----------\n",
      "This could make it less suitable for LLMs that rely\n",
      "heavily on data-driven approaches.\n",
      "----------\n",
      "The second might be the\n",
      "lack of open-sourced data in the early stages.\n",
      "----------\n",
      "Unlike in later\n",
      "stages of testing, there may be limited data available online\n",
      "during early-stage activities.\n",
      "----------\n",
      "This could mean that LLMs\n",
      "may not have seen much of this type of data, and therefore\n",
      "may not perform well on these tasks.\n",
      "----------\n",
      "Adopting a human-computer interaction schema for\n",
      "tackling early-stage testing tasks would harness the domain-\n",
      "specific knowledge of human developers and leverage the\n",
      "general knowledge embedded in LLMs.\n",
      "----------\n",
      "Additionally, it is\n",
      "highly encouraged for software development companies\n",
      "to record and provide access to early-stage testing data,\n",
      "allowing for improved training and performance of LLMs\n",
      "in these critical testing activities.\n",
      "----------\n",
      "6.2.2 Exploring LLMs in Other Testing Phases\n",
      "We have analyzed the distribution of testing phases for the\n",
      "collected studies.\n",
      "----------\n",
      "As shown in Fig 11, we can observe that\n",
      "LLMs are most commonly used in unit testing, followed by\n",
      "system testing.\n",
      "----------\n",
      "However, there is still no research on the use\n",
      "of LLMs in integration testing and acceptance testing.\n",
      "----------\n",
      "/uni00000013/uni00000018/uni00000014/uni00000013/uni00000014/uni00000018/uni00000015/uni00000013/uni00000015/uni00000018\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni00000038/uni00000051/uni0000004c/uni00000057/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni0000002c/uni00000051/uni00000057/uni00000048/uni0000004a/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000036/uni0000005c/uni00000056/uni00000057/uni00000048/uni00000050/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n",
      "/uni00000024/uni00000046/uni00000046/uni00000048/uni00000053/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057/uni00000037/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000033/uni0000004b/uni00000044/uni00000056/uni00000048/uni00000056\n",
      "/uni00000015/uni00000017\n",
      "/uni00000013\n",
      "/uni00000015/uni00000015\n",
      "/uni00000013\n",
      "Fig.\n",
      "----------\n",
      "11: Distribution of testing phases (note that we omit the\n",
      "studies which do not explicitly specify the testing phases,\n",
      "e.g., program repair)\n",
      "For integration testing, it involves testing the interfaces\n",
      "between different software modules.\n",
      "----------\n",
      "In some software or-\n",
      "ganizations, integration testing might be merged with unit\n",
      "testing, which can be a possible reason why LLM is rarely\n",
      "utilized in integration testing.\n",
      "----------\n",
      "Another reason might be that\n",
      "the size and complexity of the input data in this circum-\n",
      "stance may exceed the capacity of the LLM to process and\n",
      "analyze (e.g., the source code of all involved software mod-\n",
      "ules), which can lead to errors or unreliable results.\n",
      "----------\n",
      "To tackle\n",
      "this, a potential reference can be found in Section 4.1, where\n",
      "Xie et al.\n",
      "----------\n",
      "[36] design a method to organize the necessary\n",
      "information into the pre-defined maximum prompt token\n",
      "limit of the LLM.\n",
      "----------\n",
      "Furthermore, integration testing requires\n",
      "diversified data to be generated to sufficiently test the in-\n",
      "terface among multiple modules.\n",
      "----------\n",
      "As mentioned in Section\n",
      "4.3, previous work has demonstrated the LLM’s capability\n",
      "in generating diversified test input for system testing, in\n",
      "conjunction with mutation testing techniques [48], [59].\n",
      "----------\n",
      "And\n",
      "these can provide insights about generating the diversified\n",
      "interface data for integration testing.\n",
      "----------\n",
      "Acceptance testing is usually conducted by business an-\n",
      "alysts or end-users to validate the system’s functionality\n",
      "and usability, which requires more non-technical language\n",
      "and domain-specific knowledge, thus making it challenging\n",
      "to apply LLM effectively.\n",
      "----------\n",
      "Since acceptance testing involves\n",
      "humans, it is well-suited for the use of human-in-the-loop\n",
      "schema with LLMs.\n",
      "----------\n",
      "This has been studied in traditional\n",
      "machine learning [155], but has not yet been explored with\n",
      "LLMs.\n",
      "----------\n",
      "Specifically, the LLMs can be responsible for auto-\n",
      "matically generating test cases, evaluating test coverage, etc,\n",
      "while human testers are responsible for checking the pro-\n",
      "gram’s behavior and verifying test oracle.20\n",
      "6.2.3 Exploring LLMs for More Types of Software\n",
      "We analyze what types of software have been explored in\n",
      "the collected studies, as shown in Figure 5.\n",
      "----------\n",
      "Note that, since\n",
      "a large portion of studies are focused on unit testing or\n",
      "program repair, they are conducted on publicly available\n",
      "datasets and do not involve specific software types.\n",
      "----------\n",
      "From the analysis in Section 4.3, the LLM can generate\n",
      "not only the source code for testing DL libraries but also\n",
      "the textual input for testing mobile apps, even the models\n",
      "for testing CPS.\n",
      "----------\n",
      "Overall, the LLM provides a flexible and\n",
      "powerful framework for generating test inputs for a wide\n",
      "range of applications.\n",
      "----------\n",
      "Its versatility would make it useful\n",
      "for testing the software in other domains.\n",
      "----------\n",
      "From one point of view, some proposed techniques can\n",
      "be applied to other types of software.\n",
      "----------\n",
      "For example, in the\n",
      "paper proposed for testing deep learning libraries [58], since\n",
      "it proposes techniques for generating diversified, compli-\n",
      "cated, and human-like DL programs, the authors state that\n",
      "the approach can be easily extended to test software systems\n",
      "from other application domains, e.g., interpreters, database\n",
      "systems, and other popular libraries.\n",
      "----------\n",
      "More than that, there\n",
      "are already studies that focus on universal fuzzing tech-\n",
      "niques [52], [67] which are designed to be adaptable and\n",
      "applicable to different types of test inputs and software.\n",
      "----------\n",
      "From another point of view, other types of software can\n",
      "also benefit from the capabilities of LLMs to design the test-\n",
      "ing techniques that are better suited to their specific do-\n",
      "main and characteristics.\n",
      "----------\n",
      "For instance, the metaverse, with\n",
      "its immersive virtual environments and complex interac-\n",
      "tions, presents unique challenges for software testing.\n",
      "----------\n",
      "LLMs\n",
      "can be leveraged to generate diverse and realistic inputs that\n",
      "mimic user behavior and interactions within the metaverse,\n",
      "which are never explored.\n",
      "----------\n",
      "6.2.4 Exploring LLMs for Non-functional Testing\n",
      "In our collected studies, LLMs are primarily used for func-\n",
      "tional testing, and no practice in performance testing, usabil-\n",
      "ity testing or others.\n",
      "----------\n",
      "One possible reason for the prevalence\n",
      "of LLM-based solutions in functional testing is that they\n",
      "can convert functional testing problems into code gener-\n",
      "ation or natural language generation problems [14], [59],\n",
      "which LLMs are particularly adept at solving.\n",
      "----------\n",
      "On the other hand, performance testing and usability\n",
      "testing may require more specialized models that are de-\n",
      "signed to detect and analyze specific types of data, handle\n",
      "complex statistical analyses, or determine the buggy criteria.\n",
      "----------\n",
      "Moreover, there have been dozens of performance testing\n",
      "tools (e.g., LoadRunner [156]) that can generate a workload\n",
      "that simulates real-world usage scenarios and achieve rela-\n",
      "tively satisfactory performance.\n",
      "----------\n",
      "The potential opportunities might let the LLM integrate\n",
      "the performance testing tools and acts like the LangChain\n",
      "[157], to better simulate different types of workloads based\n",
      "on real user behavior.\n",
      "----------\n",
      "Furthermore, the LLMs can identify\n",
      "the parameter combinations and values that have the high-\n",
      "est potential to trigger performance problems.\n",
      "----------\n",
      "It is essen-\n",
      "tially a way to rank and prioritize different parameter set-\n",
      "tings based on their impact on performance and improve\n",
      "the efficiency of performance testing.\n",
      "----------\n",
      "6.2.5 Exploring Advanced Prompt Engineering\n",
      "There are a total of 11 commonly used prompt engineering\n",
      "techniques as listed in a popular prompt engineering guide\n",
      "[158], as shown in Figure 12.\n",
      "----------\n",
      "Currently, in our collected\n",
      "studies, only the first five techniques are being utilized.\n",
      "----------\n",
      "The\n",
      "more advanced techniques have not been employed yet, and\n",
      "can be explored in the future for prompt design.\n",
      "----------\n",
      "/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013\n",
      "/uni00000033/uni00000044/uni00000053/uni00000048/uni00000055/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057\n",
      "/uni0000003d/uni00000048/uni00000055/uni00000052/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000029/uni00000048/uni0000005a/uni00000010/uni00000056/uni0000004b/uni00000052/uni00000057/uni00000003/uni0000004f/uni00000048/uni00000044/uni00000055/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000026/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni00000036/uni00000048/uni0000004f/uni00000049/uni00000010/uni00000046/uni00000052/uni00000051/uni00000056/uni0000004c/uni00000056/uni00000057/uni00000048/uni00000051/uni00000046/uni0000005c\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni0000002a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni00000057/uni00000048/uni00000003/uni0000004e/uni00000051/uni00000052/uni0000005a/uni0000004f/uni00000048/uni00000047/uni0000004a/uni00000048/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000037/uni00000055/uni00000048/uni00000048/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057/uni00000056\n",
      "/uni00000024/uni00000046/uni00000057/uni0000004c/uni00000059/uni00000048/uni00000010/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000027/uni0000004c/uni00000055/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000056/uni00000057/uni0000004c/uni00000050/uni00000058/uni0000004f/uni00000058/uni00000056/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000035/uni00000048/uni00000024/uni00000046/uni00000057/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000050/uni00000052/uni00000047/uni00000044/uni0000004f/uni00000003/uni00000046/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000010/uni00000052/uni00000049/uni00000010/uni00000057/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n",
      "/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000003/uni00000053/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057\n",
      "/uni00000024/uni00000058/uni00000057/uni00000052/uni00000050/uni00000044/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000055/uni00000048/uni00000044/uni00000056/uni00000052/uni00000051/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000044/uni00000051/uni00000047/uni00000003/uni00000057/uni00000052/uni00000052/uni0000004f/uni00000010/uni00000058/uni00000056/uni00000048\n",
      "/uni00000033/uni00000055/uni00000052/uni00000050/uni00000053/uni00000057/uni00000003/uni00000028/uni00000051/uni0000004a/uni0000004c/uni00000051/uni00000048/uni00000048/uni00000055/uni0000004c/uni00000051/uni0000004a\n",
      "/uni00000018/uni00000014\n",
      "/uni00000015/uni00000018\n",
      "/uni0000001a\n",
      "/uni00000014\n",
      "/uni00000014\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "/uni00000013\n",
      "Fig.\n",
      "----------\n",
      "12: List of advanced prompt engineering practices and\n",
      "those utilized in the collected papers\n",
      "For instance, multimodal chain of thought prompting in-\n",
      "volves using diverse sensory and cognitive cues to stimulate\n",
      "thinking and creativity in LLMs [159].\n",
      "----------\n",
      "By providing images\n",
      "(e.g., GUI screenshots) or audio recordings related to the\n",
      "software under test can help the LLM better understand\n",
      "the software’s context and potential issues.\n",
      "----------\n",
      "Besides, try to\n",
      "prompt the LLM to imagine itself in different roles, such\n",
      "as a developer, user, or quality assurance specialist.\n",
      "----------\n",
      "This\n",
      "perspective-shifting exercise enables the LLM to approach\n",
      "software testing from multiple viewpoints and uncover dif-\n",
      "ferent aspects that might require attention or investigation.\n",
      "----------\n",
      "Graph prompting [160] involves the representation of\n",
      "information using graphs or visual structures to facilitate\n",
      "understanding and problem-solving.\n",
      "----------\n",
      "Graph prompting can\n",
      "be a natural match with software engineering, consider\n",
      "it involves various dependencies, control flow, data flow,\n",
      "state transitions, or other relevant graph structure.\n",
      "----------\n",
      "Graph\n",
      "prompting can be beneficial in analyzing this structural\n",
      "information, and enabling the LLMs to comprehend the\n",
      "software under test effectively.\n",
      "----------\n",
      "For instance, testers can use\n",
      "graph prompts to visualize test coverage, identify untested\n",
      "areas or paths, and ensure adequate test execution.\n",
      "----------\n",
      "6.2.6 Incorporating LLMs with Traditional Techniques\n",
      "There is currently no clear consensus on the extent to which\n",
      "LLMs can solve software testing problems.\n",
      "----------\n",
      "From the analy-\n",
      "sis in Section 5.4, we have seen some promising results from\n",
      "studies that have combined LLMs with traditional software\n",
      "testing techniques.\n",
      "----------\n",
      "This implies the LLMs are not the sole\n",
      "silver bullet for software testing.\n",
      "----------\n",
      "Considering the availabil-\n",
      "ity of many mature software testing techniques and tools,\n",
      "and the limited capabilities of LLMs, it is necessary to ex-\n",
      "plore other better ways to combine LLMs with traditional\n",
      "testing or program analysis techniques and tools for better\n",
      "software testing.21\n",
      "Based on the collected studies, the LLMs have been suc-\n",
      "cessfully utilized together with various techniques such as\n",
      "differential testing (e.g., [63]), mutation testing (e.g., [59]),\n",
      "program analysis (e.g., [104], as shown in Figure 10.\n",
      "----------\n",
      "From\n",
      "one perspective, future studies can explore improved in-\n",
      "tegration of these traditional techniques with LLMs.\n",
      "----------\n",
      "Take\n",
      "mutation testing as an example, current practices mainly\n",
      "rely on the human-designed mutation rules to mutate the\n",
      "candidate tests, and let the LLMs re-generate new tests [38],\n",
      "[59], [67], while Liu et al.\n",
      "----------\n",
      "directly utilize the LLMs for pro-\n",
      "ducing the mutation rules alongside the mutated tests [65].\n",
      "----------\n",
      "Further explorations in this direction are of great interest.\n",
      "----------\n",
      "From another point of view, more traditional techniques\n",
      "can be incorporated in LLMs for software testing.\n",
      "----------\n",
      "For in-\n",
      "stance, besides the aforementioned traditional techniques,\n",
      "the LLMs have been combined with formal verification for\n",
      "self-healing software detection in the field of software se-\n",
      "curity [161].\n",
      "----------\n",
      "More attempts are encouraged.\n",
      "----------\n",
      "Moreover, con-\n",
      "sidering the existence of numerous mature software testing\n",
      "tools, one can explore the integration of LLMs with these\n",
      "tools, allowing them to act as a “LangChain” to better ex-\n",
      "plore the potential of these tools.\n",
      "----------\n",
      "7 R ELATED WORK\n",
      "The systematic literature review is a crucial manner for gain-\n",
      "ing insights into the current trends and future directions\n",
      "within a particular field.\n",
      "----------\n",
      "It enables us to understand and\n",
      "stay updated on the developments in that domain.\n",
      "----------\n",
      "Wang et al.\n",
      "----------\n",
      "surveyed the machine learning and deep\n",
      "learning techniques for software engineering [162].\n",
      "----------\n",
      "Yang et\n",
      "al.\n",
      "----------\n",
      "and Watson et al.\n",
      "----------\n",
      "respectively carried out surveys about\n",
      "the use of deep learning in software engineering domain\n",
      "[163], [164].\n",
      "----------\n",
      "Bajammal et al.\n",
      "----------\n",
      "surveyed the utilization of com-\n",
      "puter vision techniques to improve software engineering\n",
      "tasks [165].\n",
      "----------\n",
      "Zhang et al.\n",
      "----------\n",
      "provided a survey of techniques\n",
      "for testing machine learning systems [150]\n",
      "With the advancements of artificial intelligence and\n",
      "LLMs, researchers also conduct systematic literature\n",
      "reviews about LLMs, and their applications in various\n",
      "fields (e.g., software engineering).\n",
      "----------\n",
      "Zhao et al.\n",
      "----------\n",
      "[17] reviewed\n",
      "recent advances in LLMs by providing an overview of their\n",
      "background, key findings, and mainstream techniques.\n",
      "----------\n",
      "They focused on four major aspects of LLMs, namely\n",
      "pre-training, adaptation tuning, utilization, and capacity\n",
      "evaluation.\n",
      "----------\n",
      "Additionally, they summarized the available\n",
      "resources for developing LLMs and discuss the remaining\n",
      "issues for future directions.\n",
      "----------\n",
      "Hou et al.\n",
      "----------\n",
      "conducted a\n",
      "systematic literature review on using LLMs for software\n",
      "engineering, with a particular focus on understanding\n",
      "how LLMs can be exploited to optimize processes and\n",
      "outcomes [166].\n",
      "----------\n",
      "Fan et al.\n",
      "----------\n",
      "conducted a survey of LLMs for\n",
      "software engineering, and set out open research challenges\n",
      "for the application of LLMs to technical problems faced by\n",
      "software engineers [167].\n",
      "----------\n",
      "Zan et al.\n",
      "----------\n",
      "conducted a survey of\n",
      "existing LLMs for NL2Code task (i.e., generating code from\n",
      "a natural language description), and reviewed benchmarks\n",
      "and metrics [168].\n",
      "----------\n",
      "While these studies either targeted the broader software\n",
      "engineering domain (with a limited focus on software test-\n",
      "ing tasks) or focused on other software development tasks\n",
      "(excluding software testing), this paper specifically focuses\n",
      "on the use of LLMs for software testing.\n",
      "----------\n",
      "It surveys related\n",
      "studies, summarizes key challenges and potential opportu-\n",
      "nities, and serves as a roadmap for future research in this\n",
      "area.\n",
      "----------\n",
      "8 C ONCLUSION\n",
      "This paper provides a comprehensive review of the use\n",
      "of LLMs in software testing.\n",
      "----------\n",
      "We have analyzed relevant\n",
      "studies that have utilized LLMs in software testing from\n",
      "both the software testing and LLMs perspectives.\n",
      "----------\n",
      "This paper\n",
      "also highlights the challenges and potential opportunities\n",
      "in this direction.\n",
      "----------\n",
      "Results of this review demonstrate that\n",
      "LLMs have been successfully applied in a wide range\n",
      "of testing tasks, including unit test case generation, test\n",
      "oracle generation, system test input generation, program\n",
      "debugging, and program repair.\n",
      "----------\n",
      "However, challenges still\n",
      "exist in achieving high testing coverage, addressing the\n",
      "test oracle problem, conducting rigorous evaluations, and\n",
      "applying LLMs in real-world scenarios.\n",
      "----------\n",
      "Additionally, it is\n",
      "observed that LLMs are commonly used in only a subset of\n",
      "the entire testing lifecycle, for example, they are primarily\n",
      "utilized in the middle and later stages of testing, only\n",
      "serving the unit and system testing phases, and only for\n",
      "functional testing.\n",
      "----------\n",
      "This highlights the research opportunities\n",
      "for exploring the uncovered areas.\n",
      "----------\n",
      "Regarding how the LLMs\n",
      "are utilized, we find that various pre-training/fine-tuning\n",
      "and prompt engineering methods have been developed\n",
      "to enhance the capabilities of LLMs in addressing testing\n",
      "tasks.\n",
      "----------\n",
      "However, more advanced techniques in prompt\n",
      "design have yet to be explored and can be an avenue for\n",
      "future research.\n",
      "----------\n",
      "It can serve as a roadmap for future research in this area,\n",
      "identifying gaps in our current understanding of the use of\n",
      "LLMs in software testing and highlighting potential avenues\n",
      "for exploration.\n",
      "----------\n",
      "We believe that the insights provided in this\n",
      "paper will be valuable to both researchers and practition-\n",
      "ers in the field of software engineering, assisting them in\n",
      "leveraging LLMs to improve software testing practices and\n",
      "ultimately enhance the quality and reliability of software\n",
      "systems.\n",
      "----------\n",
      "REFERENCES\n",
      "[1] G. J. Myers, The art of software testing (2.\n",
      "----------\n",
      "ed.)\n",
      "----------\n",
      ".\n",
      "----------\n",
      "Wiley,\n",
      "2004.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[2] M. Pezz `e and M. Young, Software testing and analysis - process,\n",
      "principles and techniques.\n",
      "----------\n",
      "Wiley, 2007.\n",
      "----------\n",
      "[3] M. Harman and P .\n",
      "----------\n",
      "McMinn, “A theoretical and empirical study\n",
      "of search-based testing: Local, global, and hybrid search,” vol.\n",
      "----------\n",
      "36,\n",
      "no.\n",
      "----------\n",
      "2, 2010, pp.\n",
      "----------\n",
      "226–247.\n",
      "----------\n",
      "[4] P .\n",
      "----------\n",
      "Delgado-P ´erez, A. Ram ´ırez, K. J. Valle-G ´omez, I. Medina-\n",
      "Bulo, and J. R. Romero, “Interevo-tr: Interactive evolutionary\n",
      "test generation with readability assessment,” IEEE Trans.\n",
      "----------\n",
      "Software\n",
      "Eng., vol.\n",
      "----------\n",
      "49, no.\n",
      "----------\n",
      "4, pp.\n",
      "----------\n",
      "2580–2596, 2023.\n",
      "----------\n",
      "[5] X. Xiao, S. Li, T. Xie, and N. Tillmann, “Characteristic studies\n",
      "of loop problems for structural test generation via symbolic\n",
      "execution,” in 2013 28th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2013, Silicon Valley, CA, USA,\n",
      "November 11-15, 2013 , E. Denney, T. Bultan, and A. Zeller, Eds.\n",
      "----------\n",
      "IEEE, 2013, pp.\n",
      "----------\n",
      "246–256.\n",
      "----------\n",
      "[6] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball, “Feedback-\n",
      "directed random test generation,” in 29th International Conference\n",
      "on Software Engineering (ICSE 2007), Minneapolis, MN, USA, May\n",
      "20-26, 2007.\n",
      "----------\n",
      "IEEE Computer Society, 2007, pp.\n",
      "----------\n",
      "75–84.22\n",
      "[7] Z. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, and X. Peng,\n",
      "“No more manual tests?\n",
      "----------\n",
      "evaluating and improving chatgpt for\n",
      "unit test generation,” arXiv preprint arXiv:2305.04207, 2023.\n",
      "----------\n",
      "[8] Y. Tang, Z. Liu, Z. Zhou, and X. Luo, “Chatgpt vs SBST:\n",
      "A comparative assessment of unit test suite generation,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2307.00588, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2307.00588\n",
      "[9] A.\n",
      "----------\n",
      "Developers, “Ui/application exerciser monkey,” 2012.\n",
      "----------\n",
      "[10] Y. Li, Z. Yang, Y. Guo, and X. Chen, “Droidbot: a lightweight ui-\n",
      "guided test input generator for android,” in ICSE.\n",
      "----------\n",
      "IEEE, 2017.\n",
      "----------\n",
      "[11] T. Su, G. Meng, Y. Chen, K. Wu, W. Yang, Y. Yao, G. Pu, Y. Liu, and\n",
      "Z. Su, “Guided, stochastic model-based gui testing of android\n",
      "apps,” in Proceedings of the 2017 11th Joint Meeting on Foundations\n",
      "of Software Engineering, 2017, pp.\n",
      "----------\n",
      "245–256.\n",
      "----------\n",
      "[12] Z. Dong, M. B ¨ohme, L. Cojocaru, and A. Roychoudhury, “Time-\n",
      "travel testing of android apps,” in ICSE.\n",
      "----------\n",
      "IEEE, 2020.\n",
      "----------\n",
      "[13] M. Pan, A. Huang, G. Wang, T. Zhang, and X. Li, “Reinforcement\n",
      "learning based curiosity-driven testing of android applications,”\n",
      "in Proceedings of the 29th ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2020, pp.\n",
      "----------\n",
      "153–164.\n",
      "----------\n",
      "[14] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che, D. Wang,\n",
      "and Q. Wang, “Make LLM a testing expert: Bringing human-\n",
      "like interaction to mobile GUI testing via functionality-aware\n",
      "decisions,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.15780, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15780\n",
      "[15] T. Su, J. Wang, and Z. Su, “Benchmarking automated GUI testing\n",
      "for android against real-world bugs,” in ESEC/FSE ’21: 29th ACM\n",
      "Joint European Software Engineering Conference and Symposium on\n",
      "the Foundations of Software Engineering, Athens, Greece, August 23-\n",
      "28, 2021.\n",
      "----------\n",
      "ACM, 2021, pp.\n",
      "----------\n",
      "119–130.\n",
      "----------\n",
      "[16] M. Shanahan, “Talking about large language models,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2212.03551, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2212.03551\n",
      "[17] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou,\n",
      "Y. Min, B. Zhang, J. Zhang, Z. Dong, Y.\n",
      "----------\n",
      "Du, C. Yang,\n",
      "Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu,\n",
      "P .\n",
      "----------\n",
      "Liu, J. Nie, and J. Wen, “A survey of large language\n",
      "models,” CoRR, vol.\n",
      "----------\n",
      "abs/2303.18223, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2303.18223\n",
      "[18] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and\n",
      "Y. Iwasawa, “Large language models are zero-\n",
      "shot reasoners,” in NeurIPS, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html\n",
      "[19] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter,\n",
      "F. Xia, E. H. Chi, Q. V .\n",
      "----------\n",
      "Le, and D. Zhou,\n",
      "“Chain-of-thought prompting elicits reasoning in large\n",
      "language models,” in NeurIPS, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Avail-\n",
      "able: http://papers.nips.cc/paper files/paper/2022/hash/\n",
      "9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html\n",
      "[20] J. Li, G. Li, Y. Li, and Z. Jin, “Structured chain-of-thought\n",
      "prompting for code generation,” 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://api.semanticscholar.org/CorpusID:258615421\n",
      "[21] J. Li, Y. Li, G. Li, Z. Jin, Y. Hao, and X. Hu, “Skcoder: A\n",
      "sketch-based approach for automatic code generation,” in 2023\n",
      "IEEE/ACM 45th International Conference on Software Engineering\n",
      "(ICSE), 2023, pp.\n",
      "----------\n",
      "2124–2135.\n",
      "----------\n",
      "[22] J. Li, Y. Zhao, Y. Li, G. Li, and Z. Jin, “Acecoder: Utilizing existing\n",
      "code to enhance code generation,” 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://api.semanticscholar.org/CorpusID:257901190\n",
      "[23] Y. Dong, X. Jiang, Z. Jin, and G. Li, “Self-collaboration\n",
      "code generation via chatgpt,” CoRR, vol.\n",
      "----------\n",
      "abs/2304.07590, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2304.07590\n",
      "[24] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu,\n",
      "“Unifying large language models and knowledge graphs: A\n",
      "roadmap,” CoRR, vol.\n",
      "----------\n",
      "abs/2306.08302, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2306.08302\n",
      "[25] G. J. Myers, T. Badgett, T. M. Thomas, and C. Sandler, The art of\n",
      "software testing.\n",
      "----------\n",
      "Wiley Online Library, 2004, vol.\n",
      "----------\n",
      "2.\n",
      "----------\n",
      "[26] M. Tufano, D. Drain, A. Svyatkovskiy, S. K. Deng, and N. Sun-\n",
      "daresan, “Unit test case generation with transformers and focal\n",
      "context,” arXiv preprint arXiv:2009.05617, 2020.\n",
      "----------\n",
      "[27] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou, and\n",
      "W. Chen, “Codet: Code generation with generated tests,” arXiv\n",
      "preprint arXiv:2207.10397, 2022.\n",
      "----------\n",
      "[28] S. K. Lahiri, A. Naik, G. Sakkas, P .\n",
      "----------\n",
      "Choudhury, C. von Veh,\n",
      "M. Musuvathi, J. P .\n",
      "----------\n",
      "Inala, C. Wang, and J. Gao, “Interactive\n",
      "code generation via test-driven user-intent formalization,” arXiv\n",
      "preprint arXiv:2208.05950, 2022.\n",
      "----------\n",
      "[29] S. Alagarsamy, C. Tantithamthavorn, and A. Aleti, “A3test:\n",
      "Assertion-augmented automated test case generation,” arXiv\n",
      "preprint arXiv:2302.10352, 2023.\n",
      "----------\n",
      "[30] M. Sch ¨afer, S. Nadi, A. Eghbali, and F. Tip, “An empirical eval-\n",
      "uation of using large language models for automated unit test\n",
      "generation,” IEEE Transactions on Software Engineering , pp.\n",
      "----------\n",
      "1–21,\n",
      "2023.\n",
      "----------\n",
      "[31] V .\n",
      "----------\n",
      "Guilherme and A. Vincenzi, “An initial investigation\n",
      "of chatgpt unit test generation capability,” in 8th Brazilian\n",
      "Symposium on Systematic and Automated Software Testing, SAST\n",
      "2023, Campo Grande, MS, Brazil, September 25-29, 2023 , A. L.\n",
      "Font˜ao, D. M. B. Paiva, H. Borges, M. I. Cagnin, P .\n",
      "----------\n",
      "G.\n",
      "Fernandes, V .\n",
      "----------\n",
      "Borges, S. M. Melo, V .\n",
      "----------\n",
      "H. S. Durelli, and E. D.\n",
      "Canedo, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "15–24.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3624032.3624035\n",
      "[32] S. Hashtroudi, J. Shin, H. Hemmati, and S. Wang,\n",
      "“Automated test case generation using code models and\n",
      "domain adaptation,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.08033, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2308.08033\n",
      "[33] L. Plein, W. C. Ou ´edraogo, J. Klein, and T. F. Bissyand ´e,\n",
      "“Automatic generation of test cases based on bug reports:\n",
      "a feasibility study with large language models,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.06320, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.\n",
      "----------\n",
      "48550/arXiv.2310.06320\n",
      "[34] V .\n",
      "----------\n",
      "Vikram, C. Lemieux, and R. Padhye, “Can large\n",
      "language models write good property-based tests?” CoRR,\n",
      "vol.\n",
      "----------\n",
      "abs/2307.04346, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/\n",
      "10.48550/arXiv.2307.04346\n",
      "[35] N. Rao, K. Jain, U. Alon, C. L. Goues, and V .\n",
      "----------\n",
      "J. Hellendoorn,\n",
      "“CAT-LM training language models on aligned code and\n",
      "tests,” in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "409–420.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00193\n",
      "[36] Z. Xie, Y. Chen, C. Zhi, S. Deng, and J. Yin, “Chatunitest: a\n",
      "chatgpt-based automated unit test generation tool,”arXiv preprint\n",
      "arXiv:2305.04764, 2023.\n",
      "----------\n",
      "[37] C. Lemieux, J. P .\n",
      "----------\n",
      "Inala, S. K. Lahiri, and S. Sen, “Codamosa:\n",
      "Escaping coverage plateaus in test generation with pre-trained\n",
      "large language models,” in International conference on software\n",
      "engineering (ICSE), 2023.\n",
      "----------\n",
      "[38] A. M. Dakhel, A. Nikanjam, V .\n",
      "----------\n",
      "Majdinasab, F. Khomh,\n",
      "and M. C. Desmarais, “Effective test generation using\n",
      "pre-trained large language models and mutation testing,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2308.16557, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.16557\n",
      "[39] M. L. Siddiq, J. Santos, R. H. Tanvir, N. Ulfat, F. A. Rifat, and V .\n",
      "----------\n",
      "C.\n",
      "Lopes, “Exploring the effectiveness of large language models in\n",
      "generating unit tests,” arXiv preprint arXiv:2305.00418, 2023.\n",
      "----------\n",
      "[40] Y. Zhang, W. Song, Z. Ji, D. Yao, and N. Meng, “How well does\n",
      "LLM generate security tests?” CoRR, vol.\n",
      "----------\n",
      "abs/2310.00710, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2310.00710\n",
      "[41] V .\n",
      "----------\n",
      "Li and N. Doiron, “Prompting code interpreter to write better\n",
      "unit tests on quixbugs functions,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.00483,\n",
      "2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2310.\n",
      "----------\n",
      "00483\n",
      "[42] B. Steenhoek, M. Tufano, N. Sundaresan, and A. Svyatkovskiy,\n",
      "“Reinforcement learning from automatic feedback for high-\n",
      "quality unit test generation,” 2023.\n",
      "----------\n",
      "[43] S. Bhatia, T. Gandhi, D. Kumar, and P .\n",
      "----------\n",
      "Jalote, “Unit test generation\n",
      "using generative ai : A comparative performance analysis of\n",
      "autogeneration tools,” 2023.\n",
      "----------\n",
      "[44] M. Tufano, D. Drain, A. Svyatkovskiy, and N. Sundaresan,\n",
      "“Generating accurate assert statements for unit test cases using\n",
      "pretrained transformers,” in Proceedings of the 3rd ACM/IEEE\n",
      "International Conference on Automation of Software Test , 2022, pp.\n",
      "----------\n",
      "54–64.\n",
      "----------\n",
      "[45] P .\n",
      "----------\n",
      "Nie, R. Banerjee, J. J. Li, R. J. Mooney, and M. Gligoric,\n",
      "“Learning deep semantics for test completion,” arXiv preprint\n",
      "arXiv:2302.10166, 2023.\n",
      "----------\n",
      "[46] A. Mastropaolo, N. Cooper, D. Nader-Palacio, S. Scalabrino,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Using transfer\n",
      "learning for code-related tasks,” IEEE Trans.\n",
      "----------\n",
      "Software Eng.\n",
      "----------\n",
      ",\n",
      "vol.\n",
      "----------\n",
      "49, no.\n",
      "----------\n",
      "4, pp.\n",
      "----------\n",
      "1580–1598, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/TSE.2022.318329723\n",
      "[47] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt\n",
      "selection for code-related few-shot learning,” in Proceedings of\n",
      "the 45th International Conference on Software Engineering (ICSE’23) ,\n",
      "2023.\n",
      "----------\n",
      "[48] G. Ye, Z. Tang, S. H. Tan, S. Huang, D. Fang, X.\n",
      "----------\n",
      "Sun, L. Bian,\n",
      "H. Wang, and Z. Wang, “Automated conformance testing for\n",
      "javascript engines via deep compiler fuzzing,” in Proceedings of\n",
      "the 42nd ACM SIGPLAN international conference on programming\n",
      "language design and implementation, 2021, pp.\n",
      "----------\n",
      "435–450.\n",
      "----------\n",
      "[49] Z. Liu, C. Chen, J. Wang, X. Che, Y. Huang, J. Hu, and Q. Wang,\n",
      "“Fill in the blank: Context-aware automated text input generation\n",
      "for mobile gui testing,” arXiv preprint arXiv:2212.04732, 2022.\n",
      "----------\n",
      "[50] M. R. Taesiri, F. Macklon, Y. Wang, H. Shen, and C.-P .\n",
      "----------\n",
      "Bezemer,\n",
      "“Large language models are pretty good zero-shot video game\n",
      "bug detectors,” arXiv preprint arXiv:2210.02506, 2022.\n",
      "----------\n",
      "[51] S. L. Shrestha and C. Csallner, “Slgpt: using transfer learning\n",
      "to directly generate simulink model files and find bugs in the\n",
      "simulink toolchain,” in Evaluation and Assessment in Software\n",
      "Engineering, 2021, pp.\n",
      "----------\n",
      "260–265.\n",
      "----------\n",
      "[52] J. Hu, Q. Zhang, and H. Yin, “Augmenting greybox fuzzing\n",
      "with generative AI,” CoRR, vol.\n",
      "----------\n",
      "abs/2306.06782, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2306.06782\n",
      "[53] A. Mathur, S. Pradhan, P .\n",
      "----------\n",
      "Soni, D. Patel, and R. Regunathan,\n",
      "“Automated test case generation using t5 and gpt-3,” in 2023 9th\n",
      "International Conference on Advanced Computing and Communication\n",
      "Systems (ICACCS), vol.\n",
      "----------\n",
      "1, 2023, pp.\n",
      "----------\n",
      "1986–1992.\n",
      "----------\n",
      "[54] D. Zimmermann and A. Koziolek, “Automating gui-based soft-\n",
      "ware testing with gpt-3,” in 2023 IEEE International Conference\n",
      "on Software Testing, Verification and Validation Workshops (ICSTW),\n",
      "2023, pp.\n",
      "----------\n",
      "62–65.\n",
      "----------\n",
      "[55] M. Taeb, A. Swearngin, E. Schoop, R. Cheng, Y. Jiang, and\n",
      "J. Nichols, “Axnav: Replaying accessibility tests from natural\n",
      "language,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.02424, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.02424\n",
      "[56] Q. Luu, H. Liu, and T. Y. Chen, “Can chatgpt advance software\n",
      "testing intelligence?\n",
      "----------\n",
      "an experience report on metamorphic\n",
      "testing,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.19204, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.19204\n",
      "[57] A. Khanfir, R. Degiovanni, M. Papadakis, and Y. L. Traon, “Ef-\n",
      "ficient mutation testing via pre-trained language models,” arXiv\n",
      "preprint arXiv:2301.03543, 2023.\n",
      "----------\n",
      "[58] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang,\n",
      "“Large language models are edge-case fuzzers: Testing deep\n",
      "learning libraries via fuzzgpt,” arXiv preprint arXiv:2304.02014 ,\n",
      "2023.\n",
      "----------\n",
      "[59] ——, “Large language models are zero shot fuzzers: Fuzzing\n",
      "deep learning libraries via large language models,” arXiv preprint\n",
      "arXiv:2209.11515, 2023.\n",
      "----------\n",
      "[60] J. Ackerman and G. Cybenko, “Large language models for\n",
      "fuzzing parsers (registered report),” in Proceedings of the\n",
      "2nd International Fuzzing Workshop, FUZZING 2023, Seattle,\n",
      "WA, USA, 17 July 2023 , M. B ¨ohme, Y. Noller, B. Ray, and\n",
      "L. Szekeres, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "31–38.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3605157.3605173\n",
      "[61] S. Yu, C. Fang, Y. Ling, C. Wu, and Z. Chen, “LLM for\n",
      "test script generation and migration: Challenges, capabilities,\n",
      "and opportunities,” CoRR, vol.\n",
      "----------\n",
      "abs/2309.13574, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2309.13574\n",
      "[62] G. Deng, Y. Liu, V .\n",
      "----------\n",
      "M. Vilches, P .\n",
      "----------\n",
      "Liu, Y. Li, Y. Xu,\n",
      "T. Zhang, Y. Liu, M. Pinzger, and S. Rass, “Pentestgpt:\n",
      "An llm-empowered automatic penetration testing tool,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2308.06782, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.06782\n",
      "[63] M. Sun, Y. Yang, Y. Wang, M. Wen, H. Jia, and Y. Zhou,\n",
      "“SMT solver validation empowered by large pre-trained\n",
      "language models,” in 38th IEEE/ACM International Conference on\n",
      "Automated Software Engineering, ASE 2023, Luxembourg, September\n",
      "11-15, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "1288–1300.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00180\n",
      "[64] Y. Deng, J. Yao, Z. Tu, X. Zheng, M. Zhang, and T. Zhang,\n",
      "“Target: Automated scenario generation from traffic rules\n",
      "for testing autonomous vehicles,” 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://api.semanticscholar.org/CorpusID:258588387\n",
      "[65] Z. Liu, C. Chen, J. Wang, M. Chen, B. Wu, X. Che,\n",
      "D. Wang, and Q. Wang, “Testing the limits: Unusual text inputs\n",
      "generation for mobile app crash detection with large language\n",
      "model,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.15657, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.15657\n",
      "[66] C. Zhang, M. Bai, Y. Zheng, Y. Li, X. Xie, Y. Li, W. Ma, L. Sun,\n",
      "and Y. Liu, “Understanding large language model based fuzz\n",
      "driver generation,” CoRR, vol.\n",
      "----------\n",
      "abs/2307.12469, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2307.12469\n",
      "[67] C. Xia, M. Paltenghi, J. Tian, M. Pradel, and L. Zhang,\n",
      "“Universal fuzzing via large language models,” ArXiv,\n",
      "vol.\n",
      "----------\n",
      "abs/2308.04748, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://api.\n",
      "----------\n",
      "semanticscholar.org/CorpusID:260735598\n",
      "[68] C. Tsigkanos, P .\n",
      "----------\n",
      "Rani, S. M ¨uller, and T. Kehrer, “Variable\n",
      "discovery with large language models for metamorphic testing\n",
      "of scientific software,” in Computational Science - ICCS 2023 -\n",
      "23rd International Conference, Prague, Czech Republic, July 3-5,\n",
      "2023, Proceedings, Part I , ser.\n",
      "----------\n",
      "Lecture Notes in Computer\n",
      "Science, J. Mikyska, C. de Mulatier, M. Paszynski, V .\n",
      "----------\n",
      "V .\n",
      "----------\n",
      "Krzhizhanovskaya, J. J. Dongarra, and P .\n",
      "----------\n",
      "M. A. Sloot, Eds.,\n",
      "vol.\n",
      "----------\n",
      "14073.\n",
      "----------\n",
      "Springer, 2023, pp.\n",
      "----------\n",
      "321–335.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1007/978-3-031-35995-8 23\n",
      "[69] C. Yang, Y. Deng, R. Lu, J. Yao, J. Liu, R. Jabbarvand, and\n",
      "L. Zhang, “White-box compiler fuzzing empowered by large\n",
      "language models,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.15991, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2310.15991\n",
      "[70] T. Zhang, I. C. Irsan, F. Thung, D. Han, D. Lo, and L. Jiang,\n",
      "“itiger: an automatic issue title generation tool,” in Proceedings\n",
      "of the 30th ACM Joint European Software Engineering Conference and\n",
      "Symposium on the Foundations of Software Engineering , 2022, pp.\n",
      "----------\n",
      "1637–1641.\n",
      "----------\n",
      "[71] Y. Huang, J. Wang, Z. Liu, Y. Wang, S. Wang, C. Chen,\n",
      "Y. Hu, and Q. Wang, “Crashtranslator: Automatically\n",
      "reproducing mobile application crashes directly from stack\n",
      "trace,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.07128, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.07128\n",
      "[72] T. Zhang, I. C. Irsan, F. Thung, and D. Lo, “Cupid:\n",
      "Leveraging chatgpt for more accurate duplicate bug report\n",
      "detection,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.10022, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10022\n",
      "[73] U. Mukherjee and M. M. Rahman, “Employing deep\n",
      "learning and structured information retrieval to answer\n",
      "clarification questions on bug reports,” 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://api.semanticscholar.org/CorpusID:259501524\n",
      "[74] P .\n",
      "----------\n",
      "Mahbub, O. Shuvo, and M. M. Rahman, “Explaining software\n",
      "bugs leveraging code structures in neural machine translation,”\n",
      "arXiv preprint arXiv:2212.04584, 2022.\n",
      "----------\n",
      "[75] S. Feng and C. Chen, “Prompting is all your need:\n",
      "Automated android bug replay with large language models,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2306.01987, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.01987\n",
      "[76] Y. Su, Z. Han, Z. Gao, Z. Xing, Q. Lu, and X. Xu, “Still\n",
      "confusing for bug-component triaging?\n",
      "----------\n",
      "deep feature learning\n",
      "and ensemble setting to rescue,” in 31st IEEE/ACM International\n",
      "Conference on Program Comprehension, ICPC 2023, Melbourne,\n",
      "Australia, May 15-16, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "316–327.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1109/ICPC58990.2023.00046\n",
      "[77] N. D. Bui, Y. Wang, and S. Hoi, “Detect-localize-repair: A unified\n",
      "framework for learning to debug with codet5,” arXiv preprint\n",
      "arXiv:2211.14875, 2022.\n",
      "----------\n",
      "[78] S. Kang, J. Yoon, and S. Yoo, “Large language models are few-shot\n",
      "testers: Exploring llm-based general bug reproduction,” arXiv\n",
      "preprint arXiv:2209.11515, 2022.\n",
      "----------\n",
      "[79] S. Kang, G. An, and S. Yoo, “A preliminary evaluation of\n",
      "llm-based fault localization,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.05487, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2308.05487\n",
      "[80] P .\n",
      "----------\n",
      "Widjojo and C. Treude, “Addressing compiler errors: Stack\n",
      "overflow or large language models?” CoRR, vol.\n",
      "----------\n",
      "abs/2307.10793,\n",
      "2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2307.\n",
      "----------\n",
      "10793\n",
      "[81] L. Plein and T. F. Bissyand ´e, “Can llms demystify bug\n",
      "reports?” CoRR, vol.\n",
      "----------\n",
      "abs/2310.06310, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2310.06310\n",
      "[82] A. Taylor, A. Vassar, J. Renzella, and H. A. Pearce, “Dcc\n",
      "–help: Generating context-aware compiler error explanations\n",
      "with large language models,” 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://api.semanticscholar.org/CorpusID:261076439\n",
      "[83] S. Kang, B. Chen, S. Yoo, and J.-G. Lou, “Explainable automated\n",
      "debugging via large language model-driven scientific debug-\n",
      "ging,” arXiv preprint arXiv:2304.02195, 2023.24\n",
      "[84] A.\n",
      "----------\n",
      "Z. H. Yang, R. Martins, C. L. Goues, and V .\n",
      "----------\n",
      "J.\n",
      "Hellendoorn, “Large language models for test-free fault\n",
      "localization,” CoRR, vol.\n",
      "----------\n",
      "abs/2310.01726, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2310.01726\n",
      "[85] Y. Wu, Z. Li, J. M. Zhang, M. Papadakis, M. Harman,\n",
      "and Y. Liu, “Large language models in fault localisation,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2308.15276, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2308.15276\n",
      "[86] H. Tu, Z. Zhou, H. Jiang, I. N. B. Yusuf, Y. Li, and L. Jiang,\n",
      "“LLM4CBI: taming llms to generate effective test programs\n",
      "for compiler bug isolation,” CoRR, vol.\n",
      "----------\n",
      "abs/2307.00593, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2307.00593\n",
      "[87] T.-O.\n",
      "----------\n",
      "Li, W. Zong, Y. Wang, H. Tian, Y. Wang, S.-C. Cheung,\n",
      "and J. Kramer, “Nuances are the key: Unlocking chatgpt to\n",
      "find failure-inducing tests with differential prompting,” in 2023\n",
      "38th IEEE/ACM International Conference on Automated Software\n",
      "Engineering (ASE), 2023, pp.\n",
      "----------\n",
      "14–26.\n",
      "----------\n",
      "[88] X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou, “Teaching large\n",
      "language models to self-debug,”CoRR, vol.\n",
      "----------\n",
      "abs/2304.05128, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2304.05128\n",
      "[89] J. Cao, M. Li, M. Wen, and S.-c. Cheung, “A study on prompt\n",
      "design, advantages and limitations of chatgpt for deep learning\n",
      "program repair,” arXiv preprint arXiv:2304.08191, 2023.\n",
      "----------\n",
      "[90] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt,\n",
      "“Examining zero-shot vulnerability repair with large language\n",
      "models,” in 2023 IEEE Symposium on Security and Privacy (SP) .\n",
      "----------\n",
      "IEEE Computer Society, 2022, pp.\n",
      "----------\n",
      "1–18.\n",
      "----------\n",
      "[91] Z.\n",
      "----------\n",
      "Fan, X. Gao, A. Roychoudhury, and S. H. Tan, “Automated\n",
      "repair of programs from large language models,” arXiv preprint\n",
      "arXiv:2205.10583, 2022.\n",
      "----------\n",
      "[92] Y. Hu, X. Shi, Q. Zhou, and L. Pike, “Fix bugs with trans-\n",
      "former through a neural-symbolic edit grammar,” arXiv preprint\n",
      "arXiv:2204.06643, 2022.\n",
      "----------\n",
      "[93] C. S. Xia, Y. Wei, and L. Zhang, “Practical program repair in\n",
      "the era of large pre-trained language models,” arXiv preprint\n",
      "arXiv:2210.14179, 2022.\n",
      "----------\n",
      "[94] J. Zhang, J. Cambronero, S. Gulwani, V .\n",
      "----------\n",
      "Le, R. Piskac, G. Soares,\n",
      "and G. Verbruggen, “Repairing bugs in python assignments\n",
      "using large language models,” arXiv preprint arXiv:2209.14876 ,\n",
      "2022.\n",
      "----------\n",
      "[95] M. Lajk ´o, V .\n",
      "----------\n",
      "Csuvik, and L. Vid´acs, “Towards javascript program\n",
      "repair with generative pre-trained transformer (gpt-2),” in Pro-\n",
      "ceedings of the Third International Workshop on Automated Program\n",
      "Repair, 2022, pp.\n",
      "----------\n",
      "61–68.\n",
      "----------\n",
      "[96] D. Sobania, M. Briesch, C. Hanna, and J. Petke, “An analysis of\n",
      "the automatic bug fixing performance of chatgpt,” arXiv preprint\n",
      "arXiv:2301.08653, 2023.\n",
      "----------\n",
      "[97] K. Huang, X. Meng, J. Zhang, Y. Liu, W. Wang, S. Li,\n",
      "and Y. Zhang, “An empirical study on fine-tuning large\n",
      "language models of code for automated program repair,”\n",
      "in 38th IEEE/ACM International Conference on Automated\n",
      "Software Engineering, ASE 2023, Luxembourg, September 11-\n",
      "15, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "1162–1174.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/ASE56229.2023.00181\n",
      "[98] M. C. Wuisang, M. Kurniawan, K. A. Wira Santosa, A. Agung\n",
      "Santoso Gunawan, and K. E. Saputra, “An evaluation of the\n",
      "effectiveness of openai’s chatgpt for automated python program\n",
      "bug fixing using quixbugs,” in2023 International Seminar on Appli-\n",
      "cation for Technology of Information and Communication (iSemantic) ,\n",
      "2023, pp.\n",
      "----------\n",
      "295–300.\n",
      "----------\n",
      "[99] D. Horv ´ath, V .\n",
      "----------\n",
      "Csuvik, T. Gyim ´othy, and L. Vid ´acs,\n",
      "“An extensive study on model architecture and program\n",
      "representation in the domain of learning-based automated\n",
      "program repair,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "31–38.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00013\n",
      "[100] J.\n",
      "----------\n",
      "A. Prenner, H. Babii, and R. Robbes, “Can openai’s codex fix\n",
      "bugs?\n",
      "----------\n",
      "an evaluation on quixbugs,” in Proceedings of the Third\n",
      "International Workshop on Automated Program Repair, 2022, pp.\n",
      "----------\n",
      "69–\n",
      "75.\n",
      "----------\n",
      "[101] W. Yuan, Q. Zhang, T. He, C. Fang, N. Q. V .\n",
      "----------\n",
      "Hung, X. Hao, and\n",
      "H. Yin, “Circle: continual repair across programming languages,”\n",
      "in Proceedings of the 31st ACM SIGSOFT International Symposium\n",
      "on Software Testing and Analysis, 2022, pp.\n",
      "----------\n",
      "678–690.\n",
      "----------\n",
      "[102] S. Moon, Y.\n",
      "----------\n",
      "Song, H. Chae, D. Kang, T. Kwon, K. T. iunn Ong,\n",
      "S. won Hwang, and J. Yeo, “Coffee: Boost your code llms by\n",
      "fixing bugs with feedback,” 2023.\n",
      "----------\n",
      "[103] Y. Wei, C. S. Xia, and L. Zhang, “Copiloting the copilots:\n",
      "Fusing large language models with completion engines for\n",
      "automated program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P .\n",
      "----------\n",
      "Tonella, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "172–184.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3611643.3616271\n",
      "[104] Y. Peng, S. Gao, C. Gao, Y. Huo, and M. R. Lyu, “Domain\n",
      "knowledge matters: Improving prompts with fix templates for\n",
      "repairing python type errors,” CoRR, vol.\n",
      "----------\n",
      "abs/2306.01394, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2306.01394\n",
      "[105] A. E. I. Brownlee, J. Callan, K. Even-Mendoza, A. Geiger,\n",
      "C. Hanna, J. Petke, F. Sarro, and D. Sobania, “Enhancing\n",
      "genetic improvement mutations using large language models,”\n",
      "in Search-Based Software Engineering - 15th International\n",
      "Symposium, SSBSE 2023, San Francisco, CA, USA, December\n",
      "8, 2023, Proceedings , ser.\n",
      "----------\n",
      "Lecture Notes in Computer\n",
      "Science, P .\n",
      "----------\n",
      "Arcaini, T. Yue, and E. M. Fredericks, Eds.,\n",
      "vol.\n",
      "----------\n",
      "14415.\n",
      "----------\n",
      "Springer, 2023, pp.\n",
      "----------\n",
      "153–159.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1007/978-3-031-48796-5 13\n",
      "[106] M. M. A. Haque, W. U. Ahmad, I. Lourentzou, and C. Brown,\n",
      "“Fixeval: Execution-based evaluation of program fixes for\n",
      "programming problems,” in IEEE/ACM International Workshop on\n",
      "Automated Program Repair, APR@ICSE 2023, Melbourne, Australia,\n",
      "May 16, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "11–18.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/APR59189.2023.00009\n",
      "[107] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “Fixing\n",
      "hardware security bugs with large language models,” arXiv\n",
      "preprint arXiv:2302.01215, 2023.\n",
      "----------\n",
      "[108] P .\n",
      "----------\n",
      "Deligiannis, A. Lal, N. Mehrotra, and A. Rastogi, “Fixing rust\n",
      "compilation errors using llms,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.05177, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2308.05177\n",
      "[109] F. Ribeiro, R. Abreu, and J. Saraiva, “Framing program repair\n",
      "as code completion,” in Proceedings of the Third International\n",
      "Workshop on Automated Program Repair, 2022, pp.\n",
      "----------\n",
      "38–45.\n",
      "----------\n",
      "[110] N. Wadhwa, J. Pradhan, A. Sonwane, S. P .\n",
      "----------\n",
      "Sahu, N. Natarajan,\n",
      "A. Kanade, S. Parthasarathy, and S. K. Rajamani, “Frustrated with\n",
      "code quality issues?\n",
      "----------\n",
      "llms can help!” CoRR, vol.\n",
      "----------\n",
      "abs/2309.12938,\n",
      "2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2309.\n",
      "----------\n",
      "12938\n",
      "[111] F. Ribeiro, J. N. C. de Macedo, K. Tsushima, R. Abreu,\n",
      "and J. Saraiva, “Gpt-3-powered type error debugging:\n",
      "Investigating the use of large language models for code\n",
      "repair,” in Proceedings of the 16th ACM SIGPLAN International\n",
      "Conference on Software Language Engineering, SLE 2023, Cascais,\n",
      "Portugal, October 23-24, 2023 , J. Saraiva, T. Degueule, and\n",
      "E. Scott, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "111–124.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3623476.3623522\n",
      "[112] Y. Wu, N. Jiang, H. V .\n",
      "----------\n",
      "Pham, T. Lutellier, J. Davis, L. Tan,\n",
      "P .\n",
      "----------\n",
      "Babkin, and S. Shah, “How effective are neural networks for\n",
      "fixing security vulnerabilities,” arXiv preprint arXiv:2305.18607 ,\n",
      "2023.\n",
      "----------\n",
      "[113] N. Jiang, K. Liu, T. Lutellier, and L. Tan, “Impact of code\n",
      "language models on automated program repair,” arXiv preprint\n",
      "arXiv:2302.05020, 2023.\n",
      "----------\n",
      "[114] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan,\n",
      "and A. Svyatkovskiy, “Inferfix: End-to-end program repair with\n",
      "llms,” arXiv preprint arXiv:2303.07263, 2023.\n",
      "----------\n",
      "[115] C. S. Xia and L. Zhang, “Keep the conversation going: Fixing\n",
      "162 out of 337 bugs for $0.42 each using chatgpt,” arXiv preprint\n",
      "arXiv:2304.00385, 2023.\n",
      "----------\n",
      "[116] Y. Zhang, G. Li, Z. Jin, and Y. Xing, “Neural program repair with\n",
      "program dependence analysis and effective filter mechanism,”\n",
      "arXiv preprint arXiv:2305.09315, 2023.\n",
      "----------\n",
      "[117] J.\n",
      "----------\n",
      "A. Prenner and R. Robbes, “Out of context: How important is\n",
      "local context in neural program repair?” 2023.\n",
      "----------\n",
      "[118] Q. Zhang, C. Fang, B. Yu, W. Sun, T. Zhang, and Z. Chen,\n",
      "“Pre-trained model-based automated software vulnerability\n",
      "repair: How far are we?” CoRR, vol.\n",
      "----------\n",
      "abs/2308.12533, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2308.12533\n",
      "[119] S. Garg, R. Z. Moghaddam, and N. Sundaresan, “Rapgen:\n",
      "An approach for fixing code inefficiencies in zero-shot,”25\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2306.17077, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2306.17077\n",
      "[120] W. Wang, Y. Wang, S. Joty, and S. C. H. Hoi, “Rap-\n",
      "gen: Retrieval-augmented patch generation with codet5 for\n",
      "automatic program repair,” in Proceedings of the 31st ACM Joint\n",
      "European Software Engineering Conference and Symposium on the\n",
      "Foundations of Software Engineering, ESEC/FSE 2023, San Francisco,\n",
      "CA, USA, December 3-9, 2023 , S. Chandra, K. Blincoe, and\n",
      "P .\n",
      "----------\n",
      "Tonella, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "146–158.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3611643.3616256\n",
      "[121] Y. Zhang, Z. Jin, Y. Xing, and G. Li, “STEAM: simulating\n",
      "the interactive behavior of programmers for automatic bug\n",
      "fixing,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.14460, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2308.14460\n",
      "[122] S. Fakhoury, S. Chakraborty, M. Musuvathi, and S. K. Lahiri,\n",
      "“Towards generating functionally correct code edits from natu-\n",
      "ral language issue descriptions,” arXiv preprint arXiv:2304.03816,\n",
      "2023.\n",
      "----------\n",
      "[123] M. Fu, C. Tantithamthavorn, T. Le, V .\n",
      "----------\n",
      "Nguyen, and D. Phung,\n",
      "“Vulrepair: a t5-based automated software vulnerability repair,”\n",
      "in Proceedings of the 30th ACM Joint European Software Engineering\n",
      "Conference and Symposium on the Foundations of Software Engineer-\n",
      "ing, 2022, pp.\n",
      "----------\n",
      "935–947.\n",
      "----------\n",
      "[124] S. Gao, X. Wen, C. Gao, W. Wang, H. Zhang, and\n",
      "M. R. Lyu, “What makes good in-context demonstrations\n",
      "for code intelligence tasks with llms?” in 38th IEEE/ACM\n",
      "International Conference on Automated Software Engineering, ASE\n",
      "2023, Luxembourg, September 11-15, 2023 .\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "761–\n",
      "773.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1109/ASE56229.\n",
      "----------\n",
      "2023.00109\n",
      "[125] C. Treude and H. Hata, “She elicits requirements and he\n",
      "tests: Software engineering gender bias in large language\n",
      "models,” CoRR, vol.\n",
      "----------\n",
      "abs/2303.10131, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2303.10131\n",
      "[126] R. Kocielnik, S. Prabhumoye, V .\n",
      "----------\n",
      "Zhang, R. M. Alvarez, and\n",
      "A. Anandkumar, “Autobiastest: Controllable sentence generation\n",
      "for automated and open-ended social bias testing in language\n",
      "models,” CoRR, vol.\n",
      "----------\n",
      "abs/2302.07371, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2302.07371\n",
      "[127] M. Ciniselli, L. Pascarella, and G. Bavota, “To what extent do\n",
      "deep learning-based code recommenders generate predictions\n",
      "by cloning code from the training set?” in 19th IEEE/ACM\n",
      "International Conference on Mining Software Repositories, MSR 2022,\n",
      "Pittsburgh, P A, USA, May 23-24, 2022.\n",
      "----------\n",
      "ACM, 2022, pp.\n",
      "----------\n",
      "167–178.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1145/3524842.3528440\n",
      "[128] D. Erhabor, S. Udayashankar, M. Nagappan, and S. Al-Kiswany,\n",
      "“Measuring the runtime performance of code produced with\n",
      "github copilot,” CoRR, vol.\n",
      "----------\n",
      "abs/2305.06439, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.48550/arXiv.2305.06439\n",
      "[129] R. Wang, R. Cheng, D. Ford, and T. Zimmermann, “Investigating\n",
      "and designing for trust in ai-powered code generation\n",
      "tools,” CoRR, vol.\n",
      "----------\n",
      "abs/2305.11248, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2305.11248\n",
      "[130] B. Yetistiren, I.\n",
      "----------\n",
      "¨Ozsoy, M. Ayerdem, and E. T ¨uz ¨un, “Evaluating\n",
      "the code quality of ai-assisted code generation tools: An\n",
      "empirical study on github copilot, amazon codewhisperer, and\n",
      "chatgpt,” CoRR, vol.\n",
      "----------\n",
      "abs/2304.10778, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2304.10778\n",
      "[131] C. Wohlin, “Guidelines for snowballing in systematic literature\n",
      "studies and a replication in software engineering,” in\n",
      "18th International Conference on Evaluation and Assessment\n",
      "in Software Engineering, EASE ’14, London, England, United\n",
      "Kingdom, May 13-14, 2014 , M. J. Shepperd, T. Hall, and\n",
      "I. Myrtveit, Eds.\n",
      "----------\n",
      "ACM, 2014, pp.\n",
      "----------\n",
      "38:1–38:10.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/2601248.2601268\n",
      "[132] A. Mastropaolo, S. Scalabrino, N. Cooper, D. Nader-Palacio,\n",
      "D. Poshyvanyk, R. Oliveto, and G. Bavota, “Studying the usage\n",
      "of text-to-text transfer transformer to support code-related tasks,”\n",
      "in 43rd IEEE/ACM International Conference on Software Engineering,\n",
      "ICSE 2021, Madrid, Spain, 22-30 May 2021 .\n",
      "----------\n",
      "IEEE, 2021, pp.\n",
      "----------\n",
      "336–\n",
      "347.\n",
      "----------\n",
      "[133] C. Tsigkanos, P .\n",
      "----------\n",
      "Rani, S. M ¨uller, and T. Kehrer, “Large\n",
      "language models: The next frontier for variable discovery\n",
      "within metamorphic testing?” in IEEE International Conference\n",
      "on Software Analysis, Evolution and Reengineering, SANER 2023,\n",
      "Taipa, Macao, March 21-24, 2023 , T. Zhang, X. Xia, and\n",
      "N. Novielli, Eds.\n",
      "----------\n",
      "IEEE, 2023, pp.\n",
      "----------\n",
      "678–682.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/SANER56733.2023.00070\n",
      "[134] G. J. Myers, The art of software testing (2.\n",
      "----------\n",
      "ed.)\n",
      "----------\n",
      ".\n",
      "----------\n",
      "Wiley,\n",
      "2004.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: http://eu.wiley.com/WileyCDA/\n",
      "WileyTitle/productCd-0471469122.html\n",
      "[135] P .\n",
      "----------\n",
      "Farrell-Vinay,Manage software testing.\n",
      "----------\n",
      "Auerbach Publ., 2008.\n",
      "----------\n",
      "[136] A. Mili and F. Tchier, Software testing: Concepts and operations .\n",
      "----------\n",
      "John Wiley & Sons, 2015.\n",
      "----------\n",
      "[137] S. Lukasczyk and G. Fraser, “Pynguin: Automated unit\n",
      "test generation for python,” in 44th IEEE/ACM International\n",
      "Conference on Software Engineering: Companion Proceedings,\n",
      "ICSE Companion 2022, Pittsburgh, P A, USA, May 22-24,\n",
      "2022.\n",
      "----------\n",
      "ACM/IEEE, 2022, pp.\n",
      "----------\n",
      "168–172.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3510454.3516829\n",
      "[138] E. T. Barr, M. Harman, P .\n",
      "----------\n",
      "McMinn, M. Shahbaz, and S. Yoo, “The\n",
      "oracle problem in software testing: A survey,” IEEE transactions\n",
      "on software engineering, vol.\n",
      "----------\n",
      "41, no.\n",
      "----------\n",
      "5, pp.\n",
      "----------\n",
      "507–525, 2014.\n",
      "----------\n",
      "[139] C. Watson, M. Tufano, K. Moran, G. Bavota, and D. Poshyvanyk,\n",
      "“On learning meaningful assert statements for unit test cases,”\n",
      "in ICSE ’20: 42nd International Conference on Software Engineering,\n",
      "Seoul, South Korea, 27 June - 19 July, 2020, G. Rothermel and D. Bae,\n",
      "Eds.\n",
      "----------\n",
      "ACM, 2020, pp.\n",
      "----------\n",
      "1398–1409.\n",
      "----------\n",
      "[140] Y.\n",
      "----------\n",
      "He, L. Zhang, Z. Yang, Y. Cao, K. Lian, S. Li, W. Yang, Z. Zhang,\n",
      "M. Yang, Y. Zhang, and H. Duan, “Textexerciser: Feedback-driven\n",
      "text input exercising for android applications,” in 2020 IEEE\n",
      "Symposium on Security and Privacy, SP 2020, San Francisco, CA,\n",
      "USA, May 18-21, 2020.\n",
      "----------\n",
      "IEEE, 2020, pp.\n",
      "----------\n",
      "1071–1087.\n",
      "----------\n",
      "[141] A. Wei, Y. Deng, C. Yang, and L. Zhang, “Free lunch for test-\n",
      "ing: Fuzzing deep-learning libraries from open source,” in 44th\n",
      "IEEE/ACM 44th International Conference on Software Engineering,\n",
      "ICSE 2022, Pittsburgh, P A, USA, May 25-27, 2022 .\n",
      "----------\n",
      "ACM, 2022,\n",
      "pp.\n",
      "----------\n",
      "995–1007.\n",
      "----------\n",
      "[142] D. Xie, Y. Li, M. Kim, H. V .\n",
      "----------\n",
      "Pham, L. Tan, X. Zhang, and M. W.\n",
      "Godfrey, “Docter: documentation-guided fuzzing for testing\n",
      "deep learning API functions,” in ISSTA ’22: 31st ACM SIGSOFT\n",
      "International Symposium on Software Testing and Analysis, Virtual\n",
      "Event, South Korea, July 18 - 22, 2022 , S. Ryu and Y. Smaragdakis,\n",
      "Eds.\n",
      "----------\n",
      "ACM, 2022, pp.\n",
      "----------\n",
      "176–188.\n",
      "----------\n",
      "[143] Q. Guo, X. Xie, Y. Li, X. Zhang, Y. Liu, X. Li, and C. Shen,\n",
      "“Audee: Automated testing for deep learning frameworks,” in\n",
      "35th IEEE/ACM International Conference on Automated Software\n",
      "Engineering, ASE 2020, Melbourne, Australia, September 21-25, 2020.\n",
      "----------\n",
      "IEEE, 2020, pp.\n",
      "----------\n",
      "486–498.\n",
      "----------\n",
      "[144] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning\n",
      "library testing via effective model generation,” in ESEC/FSE\n",
      "’20: 28th ACM Joint European Software Engineering Conference\n",
      "and Symposium on the Foundations of Software Engineering, Virtual\n",
      "Event, USA, November 8-13, 2020 , P .\n",
      "----------\n",
      "Devanbu, M. B. Cohen, and\n",
      "T. Zimmermann, Eds.\n",
      "----------\n",
      "ACM, 2020, pp.\n",
      "----------\n",
      "788–799.\n",
      "----------\n",
      "[145] J. Jiang, Y. Xiong, H. Zhang, Q. Gao, and X. Chen, “Shaping\n",
      "program repair space with existing patches and similar code,” in\n",
      "Proceedings of the 27th ACM SIGSOFT International Symposium on\n",
      "Software Testing and Analysis , ser.\n",
      "----------\n",
      "ISSTA 2018.\n",
      "----------\n",
      "New York, NY,\n",
      "USA: Association for Computing Machinery, 2018, p. 298–309.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1145/3213846.3213871\n",
      "[146] M. Wen, J. Chen, R. Wu, D. Hao, and S.-C. Cheung, “Context-\n",
      "aware patch generation for better automated program repair,”\n",
      "in Proceedings of the 40th International Conference on Software\n",
      "Engineering, ser.\n",
      "----------\n",
      "ICSE ’18.\n",
      "----------\n",
      "New York, NY, USA: Association\n",
      "for Computing Machinery, 2018, p. 1–11.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3180155.3180233\n",
      "[147] Y. Xiong, J. Wang, R. Yan, J. Zhang, S. Han, G. Huang, and\n",
      "L. Zhang, “Precise condition synthesis for program repair,” in\n",
      "2017 IEEE/ACM 39th International Conference on Software Engineer-\n",
      "ing (ICSE), 2017, pp.\n",
      "----------\n",
      "416–426.\n",
      "----------\n",
      "[148] J. Xuan, M. Martinez, F. DeMarco, M. Cl ´ement, S. L. Marcote,\n",
      "T. Durieux, D. Le Berre, and M. Monperrus, “Nopol: Automatic\n",
      "repair of conditional statement bugs in java programs,” IEEE\n",
      "Transactions on Software Engineering, vol.\n",
      "----------\n",
      "43, no.\n",
      "----------\n",
      "1, pp.\n",
      "----------\n",
      "34–55, 2017.\n",
      "----------\n",
      "[149] S. Song, X. Li, and S. Li, “How to bridge the gap between modal-\n",
      "ities: A comprehensive survey on multimodal large language\n",
      "model,” CoRR, vol.\n",
      "----------\n",
      "abs/2311.07594, 2023.\n",
      "----------\n",
      "[150] J. M. Zhang, M. Harman, L. Ma, and Y. Liu, “Machine learning\n",
      "testing: Survey, landscapes and horizons,” IEEE Trans.\n",
      "----------\n",
      "Software\n",
      "Eng., vol.\n",
      "----------\n",
      "48, no.\n",
      "----------\n",
      "2, pp.\n",
      "----------\n",
      "1–36, 2022.\n",
      "----------\n",
      "[151] F. Tu, J. Zhu, Q. Zheng, and M. Zhou, “Be careful of when:\n",
      "an empirical study on time-related misuse of issue tracking26\n",
      "data,” in Proceedings of the 2018 ACM Joint Meeting on European\n",
      "Software Engineering Conference and Symposium on the Foundations\n",
      "of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena\n",
      "Vista, FL, USA, November 04-09, 2018 , G. T. Leavens, A. Garcia,\n",
      "and C. S. Pasareanu, Eds.\n",
      "----------\n",
      "ACM, 2018, pp.\n",
      "----------\n",
      "307–318.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1145/3236024.3236054\n",
      "[152] Z.\n",
      "----------\n",
      "Sun, L. Li, Y. Liu, X.\n",
      "----------\n",
      "Du, and L. Li, “On the importance\n",
      "of building high-quality training datasets for neural code\n",
      "search,” in 44th IEEE/ACM 44th International Conference on\n",
      "Software Engineering, ICSE 2022, Pittsburgh, P A, USA, May\n",
      "25-27, 2022 .\n",
      "----------\n",
      "ACM, 2022, pp.\n",
      "----------\n",
      "1609–1620.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3510003.3510160\n",
      "[153] L. Shi, Z. Jiang, Y. Yang, X. Chen, Y. Zhang, F. Mu, H. Jiang, and\n",
      "Q. Wang, “ISPY: automatic issue-solution pair extraction from\n",
      "community live chats,” in 36th IEEE/ACM International Conference\n",
      "on Automated Software Engineering, ASE 2021, Melbourne, Australia,\n",
      "November 15-19, 2021 .\n",
      "----------\n",
      "IEEE, 2021, pp.\n",
      "----------\n",
      "142–154.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1109/ASE51524.2021.9678894\n",
      "[154] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu,\n",
      "L. Zhou, N. Duan, A. Svyatkovskiy, S. Fu, M. Tufano,\n",
      "S. K. Deng, C. B. Clement, D. Drain, N. Sundaresan, J. Yin,\n",
      "D. Jiang, and M. Zhou, “Graphcodebert: Pre-training code\n",
      "representations with data flow,” in 9th International Conference\n",
      "on Learning Representations, ICLR 2021, Virtual Event, Austria,\n",
      "May 3-7, 2021 .\n",
      "----------\n",
      "OpenReview.net, 2021.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://openreview.net/forum?id=jLoC4ez43PZ\n",
      "[155] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and\n",
      "J. Xiao, “Lsun: Construction of a large-scale image dataset us-\n",
      "ing deep learning with humans in the loop,” arXiv preprint\n",
      "arXiv:1506.03365, 2015.\n",
      "----------\n",
      "[156] LoadRunner, Inc., “Loadrunner,” 2023, microfocus.com.\n",
      "----------\n",
      "[157] LangChain, Inc., “Langchain,” 2023, https://docs.langchain.\n",
      "----------\n",
      "com/docs/.\n",
      "----------\n",
      "[158] Prompt engineering, “Prompt engineering guide,” 2023, https:\n",
      "//github.com/dair-ai/Prompt-Engineering-Guide.\n",
      "----------\n",
      "[159] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola,\n",
      "“Multimodal chain-of-thought reasoning in language models,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2302.00923, 2023.\n",
      "----------\n",
      "[160] Z. Liu, X. Yu, Y. Fang, and X. Zhang, “Graphprompt: Unifying\n",
      "pre-training and downstream tasks for graph neural networks,”\n",
      "in Proceedings of the ACM Web Conference 2023, WWW 2023, Austin,\n",
      "TX, USA, 30 April 2023 - 4 May 2023, Y. Ding, J. Tang, J. F. Sequeda,\n",
      "L. Aroyo, C. Castillo, and G. Houben, Eds.\n",
      "----------\n",
      "ACM, 2023, pp.\n",
      "----------\n",
      "417–\n",
      "428.\n",
      "----------\n",
      "[161] Y. Charalambous, N. Tihanyi, R. Jain, Y.\n",
      "----------\n",
      "Sun, M. A. Ferrag, and\n",
      "L. C. Cordeiro, “A new era in software security: Towards self-\n",
      "healing software via large language models and formal verifica-\n",
      "tion,” 2023.\n",
      "----------\n",
      "[162] S. Wang, L. Huang, A. Gao, J. Ge, T. Zhang, H. Feng, I. Satyarth,\n",
      "M. Li, H. Zhang, and V .\n",
      "----------\n",
      "Ng, “Machine/deep learning for\n",
      "software engineering: A systematic literature review,” IEEE\n",
      "Trans.\n",
      "----------\n",
      "Software Eng., vol.\n",
      "----------\n",
      "49, no.\n",
      "----------\n",
      "3, pp.\n",
      "----------\n",
      "1188–1231, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1109/TSE.2022.3173346\n",
      "[163] Y. Yang, X. Xia, D. Lo, and J. C. Grundy, “A survey on\n",
      "deep learning for software engineering,” ACM Comput.\n",
      "----------\n",
      "Surv.\n",
      "----------\n",
      ",\n",
      "vol.\n",
      "----------\n",
      "54, no.\n",
      "----------\n",
      "10s, pp.\n",
      "----------\n",
      "206:1–206:73, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1145/3505243\n",
      "[164] C. Watson, N. Cooper, D. Nader-Palacio, K. Moran, and\n",
      "D. Poshyvanyk, “A systematic literature review on the use of\n",
      "deep learning in software engineering research,” ACM Trans.\n",
      "----------\n",
      "Softw.\n",
      "----------\n",
      "Eng.\n",
      "----------\n",
      "Methodol., vol.\n",
      "----------\n",
      "31, no.\n",
      "----------\n",
      "2, pp.\n",
      "----------\n",
      "32:1–32:58, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.1145/3485275\n",
      "[165] M. Bajammal, A. Stocco, D. Mazinanian, and A. Mesbah,\n",
      "“A survey on the use of computer vision to improve\n",
      "software engineering tasks,” IEEE Trans.\n",
      "----------\n",
      "Software Eng.\n",
      "----------\n",
      ",\n",
      "vol.\n",
      "----------\n",
      "48, no.\n",
      "----------\n",
      "5, pp.\n",
      "----------\n",
      "1722–1742, 2022.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.1109/TSE.2020.3032986\n",
      "[166] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo,\n",
      "D. Lo, J. C. Grundy, and H. Wang, “Large language\n",
      "models for software engineering: A systematic literature\n",
      "review,” CoRR, vol.\n",
      "----------\n",
      "abs/2308.10620, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available:\n",
      "https://doi.org/10.48550/arXiv.2308.10620\n",
      "[167] A.\n",
      "----------\n",
      "Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta,\n",
      "S. Yoo, and J. M. Zhang, “Large language models\n",
      "for software engineering: Survey and open problems,”\n",
      "CoRR, vol.\n",
      "----------\n",
      "abs/2310.03533, 2023.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https:\n",
      "//doi.org/10.48550/arXiv.2310.03533\n",
      "[168] D. Zan, B. Chen, F. Zhang, D. Lu, B. Wu, B. Guan,\n",
      "Y. Wang, and J. Lou, “Large language models meet nl2code:\n",
      "A survey,” in Proceedings of the 61st Annual Meeting of\n",
      "the Association for Computational Linguistics (Volume 1: Long\n",
      "Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , A. Rogers,\n",
      "J. L. Boyd-Graber, and N. Okazaki, Eds.\n",
      "----------\n",
      "Association for\n",
      "Computational Linguistics, 2023, pp.\n",
      "----------\n",
      "7443–7464.\n",
      "----------\n",
      "[Online].\n",
      "----------\n",
      "Available: https://doi.org/10.18653/v1/2023.acl-long.41127\n",
      "TABLE 5: All details of the collected papers\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "1 Unit Test Case Generation with Transform-\n",
      "ers and Focal Context\n",
      "2021 Unit test case gener-\n",
      "ation\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[26]\n",
      "2 Codet: Code Generation with Generated\n",
      "Tests\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Pure LLM ICLR 2023\n",
      "[27]\n",
      "3 Interactive Code Generation via Test-Driven\n",
      "User-Intent Formalization\n",
      "2022 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Statistic analysis\n",
      "Arxiv\n",
      "[28]\n",
      "4 A3Test: Assertion-Augmented Automated\n",
      "Test Case Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[29]\n",
      "5 An Empirical Evaluation of Using Large\n",
      "Language Models for Automated Unit Test\n",
      "Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Others Syntactic repair Arxiv\n",
      "[30]\n",
      "6 An Initial Investigation of ChatGPT Unit\n",
      "Test Generation Capability\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM SAST 2023\n",
      "[31]\n",
      "7 Automated Test Case Generation Using\n",
      "Code Models and Domain Adaptation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeT5; LLaMA-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Syntactic repair Arxiv\n",
      "[32]\n",
      "8 Automatic Generation of Test Cases based\n",
      "on Bug Reports: a Feasibility Study with\n",
      "Large Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGPT; ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM Arxiv\n",
      "[33]\n",
      "9 Can Large Language Models Write Good\n",
      "Property-Based Tests?\n",
      "----------\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Zero-shot learning Code; Others Pure LLM Arxiv\n",
      "[34]\n",
      "10 CAT-LM Training Language Models on\n",
      "Aligned Code And Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-neox Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[35]\n",
      "11 ChatGPT vs SBST: A Comparative Assess-\n",
      "ment of Unit Test Suite Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv [8]\n",
      "12 ChatUniTest: a ChatGPT-based Automated\n",
      "Unit Test Generation Tool\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Syntactic repair Arxiv\n",
      "[36]\n",
      "13 CODAMOSA: Escaping Coverage Plateaus\n",
      "in Test Generation with Pre-trained Large\n",
      "Language Models\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Zero-shot learning Code Mutation testing;\n",
      "Program analysis\n",
      "ICSE 2023\n",
      "[37]\n",
      "14 Effective Test Generation Using Pre-trained\n",
      "Large Language Models and Mutation Test-\n",
      "ing\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Mutation testing;\n",
      "Syntactic repair\n",
      "Arxiv\n",
      "[38]\n",
      "15 Exploring the Effectiveness of Large Lan-\n",
      "guage Models in Generating Unit Tests\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "CodeGen; Codex;\n",
      "ChatGPT\n",
      "Zero-shot learning Code Syntactic repair Arxiv\n",
      "[39]\n",
      "16 How Well does LLM Generate Security\n",
      "Tests?\n",
      "----------\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[40]\n",
      "17 No More Manual Tests?\n",
      "----------\n",
      "Evaluating and Im-\n",
      "proving ChatGPT for Unit Test Generation\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv [7]\n",
      "18 Prompting Code Interpreter to Write Better\n",
      "Unit Tests on Quixbugs Functions\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "GPT-4 Few-shot learning Code Pure LLM Arxiv\n",
      "[41]\n",
      "19 Reinforcement Learning from Automatic\n",
      "Feedback for High-Quality Unit Test Gen-\n",
      "eration\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "Codex Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis,\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[42]\n",
      "20 Unit Test Generation using Generative AI: A\n",
      "Comparative Performance Analysis of Au-\n",
      "togeneration Tools\n",
      "2023 Unit test case gener-\n",
      "ation\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[43]\n",
      "21 Generating Accurate Assert Statements for\n",
      "Unit Test Cases Using Pretrained Trans-\n",
      "formers\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM AST 2022\n",
      "[44]\n",
      "22 Learning Deep Semantics for Test Comple-\n",
      "tion\n",
      "2023 Test oracle genera-\n",
      "tion\n",
      "CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[45]\n",
      "23 Using Transfer Learning for Code-Related\n",
      "Tasks\n",
      "2022 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM TSE 2022\n",
      "[46]\n",
      "24 Retrieval-Based Prompt Selection for Code-\n",
      "Related Few-Shot Learning\n",
      "2023 Test oracle gener-\n",
      "ation; Program re-\n",
      "pair\n",
      "Codex Few-shot learning Code Pure LLM ICSE 2023\n",
      "[47]28\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "25 Automated Conformance Testing for\n",
      "JavaScript Engines via Deep Compiler\n",
      "Fuzzing\n",
      "2021 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing;\n",
      "Program analysis\n",
      "PLDI 2021\n",
      "[48]\n",
      "26 Fill in the Blank: Context-aware Automated\n",
      "Text Input Generation for Mobile GUI Test-\n",
      "ing\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2023\n",
      "[49]\n",
      "27 Large Language Models are Pretty Good\n",
      "Zero-Shot Video Game Bug Detectors\n",
      "2022 System test input\n",
      "generation\n",
      "InstructGPT Chain-of-Thought;\n",
      "Zero-shot learning\n",
      "Others Pure LLM Arxiv\n",
      "[50]\n",
      "28 Slgpt: Using Transfer Learning to Directly\n",
      "Generate Simulink Model Files and Find\n",
      "Bugs in the Simulink Toolchain\n",
      "2022 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Others Formal method EASE 2021\n",
      "[51]\n",
      "29 Augmenting Greybox Fuzzing with Gener-\n",
      "ative AI\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[52]\n",
      "30 Automated Test Case Generation Using T5\n",
      "and GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3; T5 Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM ICACCS\n",
      "2023 [53]\n",
      "31 Automating GUI-based Software Testing\n",
      "with GPT-3\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Pre-training and/or\n",
      "Fine-tuning\n",
      "View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSTW\n",
      "2023 [54]\n",
      "32 AXNav: Replaying Accessibility Tests from\n",
      "Natural Language\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Chain-of-Thought View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[55]\n",
      "33 Can ChatGPT Advance Software Testing In-\n",
      "telligence?\n",
      "----------\n",
      "An Experience Report on Meta-\n",
      "morphic Testing\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning Others Pure LLM Arxiv\n",
      "[56]\n",
      "34 Efficient Mutation Testing via Pre-Trained\n",
      "Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "CodeBert Zero-shot learning Code Mutation testing Arxiv\n",
      "[57]\n",
      "35 Large Language Models are Edge-Case\n",
      "Generators:Crafting Unusual Programs for\n",
      "Fuzzing Deep Learning Libraries\n",
      "2023 System test input\n",
      "generation\n",
      "Codex Chain-of-Thought; Pre-\n",
      "training and/or Fine-\n",
      "tuning; Zero-shot learn-\n",
      "ing; Few-shot learning\n",
      "Code Differential testing ICSE 2024\n",
      "[58]\n",
      "36 Large Language Models are Zero Shot\n",
      "Fuzzers: Fuzzing Deep Learning Libraries\n",
      "via Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "Codex; InCoder Zero-shot learning Code Mutation testing;\n",
      "Differential testing\n",
      "ISSTA 2023\n",
      "[59]\n",
      "37 Large Language Models for Fuzzing Parsers\n",
      "(Registered Report)\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4 Few-shot learning NL specifica-\n",
      "tion\n",
      "Pure LLM FUZZING\n",
      "2023 [60]\n",
      "38 LLM for Test Script Generation and Migra-\n",
      "tion: Challenges, Capabilities, and Opportu-\n",
      "nities\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM Arxiv\n",
      "[61]\n",
      "39 Make LLM a Testing Expert: Bringing\n",
      "Human-like Interaction to Mobile GUI Test-\n",
      "ing via Functionality-aware Decisions\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning View hierarchy\n",
      "file of UI\n",
      "Natural language\n",
      "processing\n",
      "ICSE 2024\n",
      "[14]\n",
      "40 PentestGPT: An LLM-empowered Auto-\n",
      "matic Penetration Testing Tool\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4;\n",
      "LaMDA\n",
      "Chain-of-Thought;\n",
      "Few-shot learning\n",
      "NL specifica-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[62]\n",
      "41 SMT Solver Validation Empowered by\n",
      "Large Pre-Trained Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Differential testing ASE 2023\n",
      "[63]\n",
      "42 TARGET: Automated Scenario Generation\n",
      "from Traffic Rules for Testing Autonomous\n",
      "Vehicles\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-3 Zero-shot learning Others Scenario testing Arxiv\n",
      "[64]\n",
      "43 Testing the Limits: Unusual Text Inputs\n",
      "Generation for Mobile App Crash Detection\n",
      "with Large Language Model\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT Few-shot learning View hierarchy\n",
      "file of UI\n",
      "Pure LLM ICSE 2024\n",
      "[65]\n",
      "44 Understanding Large Language Model\n",
      "Based Fuzz Driver Generation\n",
      "2023 System test input\n",
      "generation\n",
      "ChatGPT; GPT-4 Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Others Pure LLM Arxiv\n",
      "[66]\n",
      "45 Universal Fuzzing via Large Language\n",
      "Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning; Au-\n",
      "tomatic prompt\n",
      "Code Mutation testing ICSE 2024\n",
      "[67]\n",
      "46 Variable Discovery with Large Language\n",
      "Models for Metamorphic Testing of Scien-\n",
      "tific Software\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-j Zero-shot learning Others Pure LLM SANER\n",
      "2023 [68]29\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "47 White-box Compiler Fuzzing Empowered\n",
      "by Large Language Models\n",
      "2023 System test input\n",
      "generation\n",
      "GPT-4; StarCoder Few-shot learning Code Pure LLM Arxiv\n",
      "[69]\n",
      "48 Itiger: an Automatic Issue Title Generation\n",
      "Tool\n",
      "2022 Bug analysis BART Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Pure LLM FSE 2022\n",
      "[70]\n",
      "49 CrashTranslator: Automatically Reproduc-\n",
      "ing Mobile Application Crashes Directly\n",
      "from Stack Trace\n",
      "2023 Bug analysis ChatGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Reinforcement\n",
      "learning\n",
      "ICSE 2024\n",
      "[71]\n",
      "50 Cupid: Leveraging ChatGPT for More Ac-\n",
      "curate Duplicate Bug Report Detection\n",
      "2023 Bug analysis ChatGPT Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[72]\n",
      "51 Employing Deep Learning and Structured\n",
      "Information Retrieval to Answer Clarifica-\n",
      "tion Questions on Bug Reports\n",
      "2023 Bug analysis CodeT5 Zero-shot learning Bug description Statistic analysis Arxiv\n",
      "[73]\n",
      "52 Explaining Software Bugs Leveraging Code\n",
      "Structures in Neural Machine Translation\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2023\n",
      "[74]\n",
      "53 Prompting Is All Your Need: Automated\n",
      "Android Bug Replay with Large Language\n",
      "Models\n",
      "2023 Bug analysis ChatGPT Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Bug description Pure LLM ICSE 2024\n",
      "[75]\n",
      "54 Still Confusing for Bug-Component Triag-\n",
      "ing?\n",
      "----------\n",
      "Deep Feature Learning and Ensemble\n",
      "Setting to Rescue\n",
      "2023 Bug analysis CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Bug description Statistic analysis ICPC 2023\n",
      "[76]\n",
      "55 Detect-Localize-Repair: A Unified Frame-\n",
      "work for Learning to Debug with CodeT5\n",
      "2022 Debug CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM EMNLP\n",
      "2022 [77]\n",
      "56 Large Language Models are Few-shot\n",
      "Testers: Exploring LLM-based General Bug\n",
      "Reproduction\n",
      "2022 Debug Codex Few-shot learning Bug description Program analysis;\n",
      "Statistic analysis\n",
      "ICSE 2023\n",
      "[78]\n",
      "57 A Preliminary Evaluation of LLM-Based\n",
      "Fault Localization\n",
      "2023 Debug ChatGPT Few-shot learning Code Pure LLM Arxiv\n",
      "[79]\n",
      "58 Addressing Compiler Errors: Stack Over-\n",
      "flow or Large Language Models?\n",
      "----------\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Error informa-\n",
      "tion\n",
      "Pure LLM Arxiv\n",
      "[80]\n",
      "59 Can LLMs Demystify Bug Reports?\n",
      "----------\n",
      "2023 Debug ChatGPT Zero-shot learning Bug description Pure LLM Arxiv\n",
      "[81]\n",
      "60 Dcc –help: Generating Context-Aware Com-\n",
      "piler Error Explanations with Large Lan-\n",
      "guage Models\n",
      "2023 Debug ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM SIGCSE\n",
      "2024 [82]\n",
      "61 Explainable Automated Debugging via\n",
      "Large Language Model-driven Scientific De-\n",
      "bugging\n",
      "2023 Debug CodeGen; Codex;\n",
      "ChatGPT\n",
      "Self-consistency; Zero-\n",
      "shot learning\n",
      "Code Pure LLM Arxiv\n",
      "[83]\n",
      "62 Large Language Models for Test-Free Fault\n",
      "Localization\n",
      "2023 Debug CodeGen Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[84]\n",
      "63 Large Language Models in Fault Localisa-\n",
      "tion\n",
      "2023 Debug ChatGPT; GPT-4 Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[85]\n",
      "64 LLM4CBI: Taming LLMs to Generate Effec-\n",
      "tive Test Programs for Compiler Bug Isola-\n",
      "tion\n",
      "2023 Debug ChatGPT Zero-shot learning Code Mutation testing;\n",
      "Reinforcement\n",
      "learning\n",
      "Arxiv\n",
      "[86]\n",
      "65 Nuances are the Key: Unlocking ChatGPT\n",
      "to Find Failure-Inducing Tests with Differ-\n",
      "ential Prompting\n",
      "2023 Debug ChatGPT Zero-shot learning Code Differential testing ASE 2023\n",
      "[87]\n",
      "66 Teaching Large Language Models to Self-\n",
      "Debug\n",
      "2023 Debug Codex; ChatGPT;\n",
      "GPT-4; StarCoder\n",
      "Few-shot learning Code Pure LLM Arxiv\n",
      "[88]\n",
      "67 A study on Prompt Design, Advantages and\n",
      "Limitations of ChatGPT for Deep Learning\n",
      "Program Repair\n",
      "2023 Debug; Program re-\n",
      "pair\n",
      "ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[89]\n",
      "68 Examining Zero-Shot Vulnerability Repair\n",
      "with Large Language Models\n",
      "2021 Program repair Codex Zero-shot learning Code; Bug de-\n",
      "scription\n",
      "Pure LLM SP 2023\n",
      "[90]\n",
      "69 Automated Repair of Programs from Large\n",
      "Language Models\n",
      "2022 Program repair Codex Zero-shot learning Code Pure LLM ICSE 2023\n",
      "[91]\n",
      "70 Fix Bugs with Transformer through a\n",
      "Neural-Symbolic Edit Grammar\n",
      "2022 Program repair CodeGPT Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[92]\n",
      "71 Practical Program Repair in the Era of Large\n",
      "Pre-trained Language Models\n",
      "2022 Program repair GPT-3; Codex;\n",
      "CodeT5; InCoder\n",
      "Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Statistic analysis ICSE 2023\n",
      "[93]30\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "72 Repairing Bugs in Python Assignments Us-\n",
      "ing Large Language Models\n",
      "2022 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Error in-\n",
      "formation\n",
      "Program analysis Arxiv\n",
      "[94]\n",
      "73 Towards JavaScript Program Repair with\n",
      "Generative Pre-trained Transformer (GPT-2)\n",
      "2022 Program repair GPT-2 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2022\n",
      "[95]\n",
      "74 An Analysis of the Automatic Bug Fixing\n",
      "Performance of ChatGPT\n",
      "2023 Program repair ChatGPT Zero-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM APR 2023\n",
      "[96]\n",
      "75 An Empirical Study on Fine-Tuning Large\n",
      "Language Models of Code for Automated\n",
      "Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "UniXCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ASE 2023\n",
      "[97]\n",
      "76 An Evaluation of the Effectiveness of Ope-\n",
      "nAI’s ChatGPT for Automated Python Pro-\n",
      "gram Bug Fixing using QuixBugs\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM iSemantic\n",
      "2023 [98]\n",
      "77 An Extensive Study on Model Architecture\n",
      "and Program Representation in the Domain\n",
      "of Learning-based Automated Program Re-\n",
      "pair\n",
      "2023 Program repair T5; CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[99]\n",
      "78 Can OpenAI’s Codex Fix Bugs?\n",
      "----------\n",
      "An Evalua-\n",
      "tion on QuixBugs\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code Pure LLM APR 2022\n",
      "[100]\n",
      "79 CIRCLE: Continual Repair Across Program-\n",
      "ming Languages\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ISSTA 2022\n",
      "[101]\n",
      "80 Coffee: Boost Your Code LLMs by Fixing\n",
      "Bugs with Feedback\n",
      "2023 Program repair CodeLLAMA Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM Arxiv\n",
      "[102]\n",
      "81 Copiloting the Copilots: Fusing Large Lan-\n",
      "guage Models with Completion Engines for\n",
      "Automated Program Repair\n",
      "2023 Program repair CodeT5; InCoder Zero-shot learning Code Statistic analysis FSE 2023\n",
      "[103]\n",
      "82 Domain Knowledge Matters: Improving\n",
      "Prompts with Fix Templates for Repairing\n",
      "Python Type Errors\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Program analysis ICSE 2024\n",
      "[104]\n",
      "83 Enhancing Genetic Improvement Mutations\n",
      "Using Large Language Models\n",
      "2023 Program repair GPT-4 Zero-shot learning Code Pure LLM SSBSE 2023\n",
      "[105]\n",
      "84 FixEval: Execution-based Evaluation of Pro-\n",
      "gram Fixes for Programming Problems\n",
      "2023 Program repair CodeT5; PLBART Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM APR 2023\n",
      "[106]\n",
      "85 Fixing Hardware Security Bugs with Large\n",
      "Language Models\n",
      "2023 Program repair Codex; CodeGen Few-shot learning;\n",
      "Zero-shot learning\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[107]\n",
      "86 Fixing Rust Compilation Errors using LLMs 2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[108]\n",
      "87 Framing Program Repair as Code Comple-\n",
      "tion\n",
      "2023 Program repair CodeGPT Zero-shot learning Code Pure LLM ICSE 2022\n",
      "[109]\n",
      "88 Frustrated with Code Quality Issues?\n",
      "----------\n",
      "LLMs\n",
      "can Help!\n",
      "----------\n",
      "2023 Program repair ChatGPT; GPT-4 Zero-shot learning Code Pure LLM Arxiv\n",
      "[110]\n",
      "89 GPT-3-Powered Type Error Debugging: In-\n",
      "vestigating the Use of Large Language Mod-\n",
      "els for Code Repair\n",
      "2023 Program repair GPT-3 Zero-shot learning Code Program analysis SLE 2023\n",
      "[111]\n",
      "90 How Effective Are Neural Networks for Fix-\n",
      "ing Security Vulnerabilities\n",
      "2023 Program repair Codex; CodeGen;\n",
      "CodeT5; PLBART;\n",
      "InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ISSTA 2023\n",
      "[112]\n",
      "91 Impact of Code Language Models on Auto-\n",
      "mated Program Repair\n",
      "2023 Program repair PLBART; CodeT5;\n",
      "CodeGen; InCoder\n",
      "Pre-training and/or\n",
      "Fine-tuning; Zero-shot\n",
      "learning\n",
      "Code Pure LLM ICSE 2023\n",
      "[113]\n",
      "92 Inferfix: End-to-end Program Repair with\n",
      "LLMs\n",
      "2023 Program repair Codex Few-shot learning; Pre-\n",
      "training and/or Fine-\n",
      "tuning\n",
      "Code Pure LLM FSE 2023\n",
      "[114]\n",
      "93 Keep the Conversation Going: Fixing 162\n",
      "out of 337 bugs for $0.42 each using Chat-\n",
      "GPT\n",
      "2023 Program repair ChatGPT Few-shot learning Code; Error in-\n",
      "formation\n",
      "Pure LLM Arxiv\n",
      "[115]\n",
      "94 Neural Program Repair with Program De-\n",
      "pendence Analysis and Effective Filter\n",
      "Mechanism\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis Arxiv\n",
      "[116]31\n",
      "ID Paper title Year Topic Involved LLM How LLM is used Input to LLM How LLM inte-\n",
      "grated\n",
      "Venue Ref\n",
      "95 Out of Context: How important is Local\n",
      "Context in Neural Program Repair?\n",
      "----------\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM ICSE 2024\n",
      "[117]\n",
      "96 Pre-trained Model-based Automated Soft-\n",
      "ware Vulnerability Repair: How Far are We?\n",
      "----------\n",
      "2023 Program repair CodeT5; UniX-\n",
      "Coder; CodeGPT\n",
      "Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM IEEE TDSC\n",
      "[118]\n",
      "97 RAPGen: An Approach for Fixing Code In-\n",
      "efficiencies in Zero-Shot\n",
      "2023 Program repair Codex Few-shot learning;\n",
      "Chain-of-Thought\n",
      "Code Pure LLM Arxiv\n",
      "[119]\n",
      "98 RAP-Gen: Retrieval-Augmented Patch Gen-\n",
      "eration with CodeT5 for Automatic Pro-\n",
      "gram Repair\n",
      "2023 Program repair CodeT5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Statistic analysis FSE 2023\n",
      "[120]\n",
      "99 STEAM: Simulating the InTeractive BEhav-\n",
      "ior of ProgrAMmers for Automatic Bug Fix-\n",
      "ing\n",
      "2023 Program repair ChatGPT Zero-shot learning Code Pure LLM Arxiv\n",
      "[121]\n",
      "100 Towards Generating Functionally Correct\n",
      "Code Edits from Natural Language Issue\n",
      "Descriptions\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning;\n",
      "Zero-shot learning;\n",
      "Chain-of-Thought\n",
      "Code; Bug de-\n",
      "scription\n",
      "Pure LLM Arxiv\n",
      "[122]\n",
      "101 VulRepair: a T5-based Automated Software\n",
      "Vulnerability Repair\n",
      "2023 Program repair T5 Pre-training and/or\n",
      "Fine-tuning\n",
      "Code Pure LLM FSE 2022\n",
      "[123]\n",
      "102 What Makes Good In-Context Demonstra-\n",
      "tions for Code Intelligence Tasks with\n",
      "LLMs?\n",
      "----------\n",
      "2023 Program repair Codex; ChatGPT Few-shot learning Code Pure LLM ASE 2023\n",
      "[124]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i in sent_tokenize(text):\n",
    "\tprint(i)\n",
    "\tprint('-'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
